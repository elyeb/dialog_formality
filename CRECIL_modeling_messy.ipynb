{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4583ed57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager\n",
    "import re\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "#import pickle5 as pickle\n",
    "import pickle\n",
    "import numpy as np\n",
    "import collections\n",
    "import jieba\n",
    "from collections import Counter\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.naive_bayes import GaussianNB, CategoricalNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics  import f1_score,accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import  RandomForestClassifier\n",
    "import fasttext\n",
    "import fasttext.util\n",
    "import jieba #tokenized = list(jieba.cut((line)))\n",
    "#ft = fasttext.load_model('../fastText/cc.zh.300.bin')\n",
    "import sklearn_crfsuite\n",
    "\n",
    "#from sklearn_crfsuite import scorers\n",
    "import numpy as np\n",
    "#from sklearn_crfsuite import metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0a815a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fasttext.util.reduce_model(ft, 100)\n",
    "print(ft.get_dimension())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51457d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.6.8 :: Anaconda, Inc.\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b0648c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev.json  shuffle_data.py  test.json  train_1.json  train.json\r\n"
     ]
    }
   ],
   "source": [
    "%ls ../CRECIL/Final_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76f69aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../CRECIL/Final_Data/train.json','rb') as infile:\n",
    "    train_df = json.loads(infile.read())\n",
    "    \n",
    "#override\n",
    "\"\"\"\n",
    "with open('../CRECIL/Final_Data/train_1.json','rb') as infile:\n",
    "    train_df= pickle.load(infile)\n",
    "\"\"\"\n",
    "with open('../CRECIL/Final_Data/train_1.pickle','rb') as infile:\n",
    "    train_df= pickle.load(infile)\n",
    "    \n",
    "with open('../CRECIL/Final_Data/dev.json','rb') as infile:\n",
    "    dev_df = json.loads(infile.read())\n",
    "    \n",
    "# save version with extra field for tokenized/prepped dialogues\n",
    "with open('../CRECIL/Final_Data/dev_1.pickle','rb') as infile:\n",
    "    dev_df= pickle.load(infile)\n",
    "    \n",
    "with open('../CRECIL/Final_Data/test.json','rb') as infile:\n",
    "    test_df = json.loads(infile.read())\n",
    "    \n",
    "with open('../CRECIL/Final_Data/test_1.pickle','rb') as infile:\n",
    "    test_df= pickle.load(infile)\n",
    "    \n",
    "#data load\n",
    "with open('../CRECIL/My_home_data/partition1.pickle','rb') as infile:\n",
    "    partition1 = pickle.load(infile)\n",
    "    \n",
    "with open('rid_to_rel.pickle','rb') as infile:\n",
    "    rid_to_rel = pickle.load(infile)\n",
    "\n",
    "with open('rel_to_rid.pickle','rb') as infile:\n",
    "    rel_to_rid = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b12188f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_blank_relations(annotations:list) -> list:\n",
    "    \"\"\"\n",
    "    Take the labels and clear out the gold-standard relations, \n",
    "    to be filled with predictions by model\n",
    "    \"\"\"\n",
    "    pred_list =[]\n",
    "    \n",
    "    for item in annotations:\n",
    "        copy = item.copy()\n",
    "        copy['r'] = []\n",
    "        copy['rid'] = []\n",
    "        pred_list.append(copy)\n",
    "    \n",
    "    return pred_list\n",
    "\n",
    "\n",
    "def ch_tokenizer(input_str:str):\n",
    "    #tokenize sentence and return as list\n",
    "    tokenized = list(jieba.cut(input_str))\n",
    "    return tokenized\n",
    "\n",
    "def get_num_speakers(transcript:list)-> int:\n",
    "    \"\"\"\n",
    "    return number of speakers in scene\n",
    "    \"\"\"\n",
    "    ch_set = set()\n",
    "    for line in transcript:\n",
    "        ch_set.add(re.findall('S.*(?=:)',line)[0])\n",
    "    \n",
    "    total = len(ch_set)\n",
    "    return total\n",
    "\n",
    "def dummy_tokenize(phrase): #pass tokenized text version\n",
    "    return phrase\n",
    "\n",
    "class results:\n",
    "    \"\"\"\n",
    "    Make an object of the results so that I can get accurate numbers and confusion \n",
    "    matrices while sorting for labels.\n",
    "    \"\"\"\n",
    "    def __init__(self,y_test, y_pred):\n",
    "        self.y_test = y_test\n",
    "        self.y_pred = y_pred\n",
    "        self.labels = sorted(list(set(y_test)))\n",
    "        self.cm = pd.DataFrame(np.zeros(shape=(len(self.labels),len(self.labels)+1))) #initialize to empty\n",
    "        self.cm[0]=self.labels\n",
    "        self.cm.columns = ['pred']+self.labels\n",
    "        self.accuracy = 0\n",
    "        self.correct = 0\n",
    "        self.incorrect = 0\n",
    "        self.label_metrics = dict()\n",
    "        \n",
    "        for lab in self.labels:\n",
    "            self.label_metrics[lab] = dict()\n",
    "            self.label_metrics[lab]['F1'] = 0.0\n",
    "            self.label_metrics[lab]['Recall'] = 0.0\n",
    "            self.label_metrics[lab]['Accuracy'] = 0.0\n",
    "            self.label_metrics[lab]['TP'] = 0\n",
    "            self.label_metrics[lab]['TN'] = 0\n",
    "            self.label_metrics[lab]['FP'] = 0\n",
    "            self.label_metrics[lab]['FN'] = 0\n",
    "            self.label_metrics[lab]['cm'] = pd.DataFrame(np.zeros(shape=(2,3)),\\\n",
    "                                                         columns=['']+['Test P','Test N']) #initialize to empty\n",
    "            self.label_metrics[lab]['cm'][0] = ['Pred P','Pred N']\n",
    "        \n",
    "        for i in range(0,len(y_test)):\n",
    "            \n",
    "            #update CM\n",
    "            self.cm.loc[ self.cm['pred'] == y_pred[i], y_test[i]] +=1\n",
    "            \n",
    "            if y_pred[i]==y_test[i]:\n",
    "                self.correct +=1\n",
    "                self.label_metrics[y_test[i]]['TP'] +=1\n",
    "                for lab in self.labels:\n",
    "                    if lab != y_test[i]:\n",
    "                        self.label_metrics[lab]['TN'] +=1 #all other incorrect labels were not selected\n",
    "            else:\n",
    "                self.incorrect +=1\n",
    "                self.label_metrics[y_test[i]]['FN'] += 1 #true label was not selected\n",
    "                self.label_metrics[y_pred[i]]['FP'] +=1 #a wrong label was selected\n",
    "                \n",
    "                \n",
    "        self.accuracy = self.correct/(self.correct+self.incorrect)\n",
    "        for lab in self.labels:\n",
    "            \n",
    "            try:\n",
    "                self.label_metrics[lab]['Precision'] = self.label_metrics[lab]['TP']/(self.label_metrics[lab]['TP']+self.label_metrics[lab]['FP'])\n",
    "                self.label_metrics[lab]['Recall'] = self.label_metrics[lab]['TP']/(self.label_metrics[lab]['TP']+self.label_metrics[lab]['FN'])\n",
    "                self.label_metrics[lab]['F1'] = self.label_metrics[lab]['TP']/(self.label_metrics[lab]['TP']+(0.5)*(self.label_metrics[lab]['FP']+self.label_metrics[lab]['FN']))      \n",
    "                \n",
    "            except:\n",
    "                self.label_metrics[lab]['Precision'] = 0\n",
    "                self.label_metrics[lab]['Recall'] = 0\n",
    "                self.label_metrics[lab]['F1'] = 0\n",
    "    def cm(self):\n",
    "        \"\"\"\n",
    "        show cm\n",
    "        \"\"\"\n",
    "        return(self.cm)\n",
    "    \n",
    "    def metric(self):\n",
    "        \n",
    "        \n",
    "        print(f\"Overall accuracy = {self.accuracy}\")\n",
    "        \n",
    "        for lab in self.labels:\n",
    "            print(f\"{lab}: {len([item for item in y_test if item==lab])} total\")\n",
    "            print(f\"   F1={self.label_metrics[lab]['F1']}\")\n",
    "            print(f\"   Precision={self.label_metrics[lab]['Precision']}\")\n",
    "            print(f\"   Recall={self.label_metrics[lab]['Recall']}\")\n",
    "\n",
    "        pass\n",
    "\n",
    "\n",
    "def jb_tokenize(line:str)-> list:\n",
    "    return list(jieba.cut((line)))\n",
    "\n",
    "\n",
    "def retrieve_s_lines(speaker:str,dialog:str)-> list:\n",
    "    lines =[]\n",
    "    \n",
    "    for line in dialog:\n",
    "        if line[0]==speaker:\n",
    "            lines.append(line[1])\n",
    "    return lines\n",
    "\n",
    "\n",
    "\n",
    "def retrieve_mentions(ch:str,dialog:str)-> list:\n",
    "    lines =[]\n",
    "    \n",
    "    for line in dialog:\n",
    "        if bool(re.search(ch,line[1])):\n",
    "            lines.append(line[1])\n",
    "    return lines\n",
    "\n",
    "def get_avg_embeddings(array:list)-> dict:\n",
    "    \"\"\"Input array is list of sentences, output is a dictionary with the \n",
    "    average embeddings of those sentences.\n",
    "    \"\"\"\n",
    "    \n",
    "    embeddings = []\n",
    "    for item in array:\n",
    "        embeddings.append(ft.get_sentence_vector(item))\n",
    "    avg_embeddings = np.mean(embeddings, axis=0)\n",
    "    \n",
    "    return avg_embeddings\n",
    "\n",
    "def embeddings_to_features(array:list)-> dict:\n",
    "    \n",
    "    features = {}\n",
    "    for iv,value in enumerate(array):\n",
    "        features['v{}'.format(iv)]=value\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4709d2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_unlist = [item[0] for item in y_test]\n",
    "y_test_unlist = [item[0] for item in y_test_predict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "afcd0cc0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['per:relative',\n",
       " 'per:spouse',\n",
       " 'per:parents',\n",
       " 'per:alternate_name',\n",
       " 'per:parents',\n",
       " 'per:relative',\n",
       " 'per:relative',\n",
       " 'per:siblings',\n",
       " 'per:relative',\n",
       " 'per:relative',\n",
       " 'per:relative',\n",
       " 'per:alternate_name',\n",
       " 'per:spouse',\n",
       " 'per:siblings',\n",
       " 'per:parents',\n",
       " 'per:spouse',\n",
       " 'per:parents',\n",
       " 'per:siblings',\n",
       " 'per:children',\n",
       " 'per:relative',\n",
       " 'per:children',\n",
       " 'per:children',\n",
       " 'per:alternate_name',\n",
       " 'per:relative',\n",
       " 'per:alternate_name',\n",
       " 'per:relative',\n",
       " 'per:spouse',\n",
       " 'per:parents',\n",
       " 'per:parents',\n",
       " 'per:relative',\n",
       " 'per:children',\n",
       " 'per:relative',\n",
       " 'per:children',\n",
       " 'per:alternate_name',\n",
       " 'per:children',\n",
       " 'per:relative',\n",
       " 'per:relative',\n",
       " 'per:alternate_name',\n",
       " 'per:siblings',\n",
       " 'per:relative',\n",
       " 'per:relative',\n",
       " 'per:relative',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'per:children',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'per:alternate_name',\n",
       " 'unanswerable',\n",
       " 'per:parents',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'per:parents',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'per:alternate_name',\n",
       " 'per:children',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'per:friends',\n",
       " 'per:classmate',\n",
       " 'per:alternate_name',\n",
       " 'per:friends',\n",
       " 'per:classmate',\n",
       " 'per:friends',\n",
       " 'per:classmate',\n",
       " 'per:friends',\n",
       " 'per:classmate',\n",
       " 'per:alternate_name',\n",
       " 'per:alternate_name',\n",
       " 'per:friends',\n",
       " 'per:classmate',\n",
       " 'per:friends',\n",
       " 'per:classmate',\n",
       " 'per:friends',\n",
       " 'per:classmate',\n",
       " 'per:alternate_name',\n",
       " 'per:friends',\n",
       " 'per:classmate',\n",
       " 'per:children',\n",
       " 'per:children',\n",
       " 'per:grandchildren',\n",
       " 'per:friends',\n",
       " 'per:acquaintance',\n",
       " 'unanswerable',\n",
       " 'per:children',\n",
       " 'per:alternate_name',\n",
       " 'per:children',\n",
       " 'per:parents',\n",
       " 'per:spouse',\n",
       " 'per:children',\n",
       " 'per:acquaintance',\n",
       " 'unanswerable',\n",
       " 'per:spouse',\n",
       " 'per:parents',\n",
       " 'per:alternate_name',\n",
       " 'per:parents',\n",
       " 'per:spouse',\n",
       " 'per:children-in-law',\n",
       " 'per:acquaintance',\n",
       " 'unanswerable',\n",
       " 'per:alternate_name',\n",
       " 'per:parents',\n",
       " 'per:spouse',\n",
       " 'per:grandparents',\n",
       " 'per:parents',\n",
       " 'per:parents-in-law',\n",
       " 'per:acquaintance',\n",
       " 'unanswerable',\n",
       " 'per:parents-in-law',\n",
       " 'per:grandparents',\n",
       " 'per:parents',\n",
       " 'per:friends',\n",
       " 'per:acquaintance',\n",
       " 'per:acquaintance',\n",
       " 'per:acquaintance',\n",
       " 'unanswerable',\n",
       " 'per:acquaintance',\n",
       " 'per:friends',\n",
       " 'per:acquaintance',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'per:parents',\n",
       " 'per:spouse',\n",
       " 'per:alternate_name',\n",
       " 'per:children-in-law',\n",
       " 'per:acquaintance',\n",
       " 'unanswerable',\n",
       " 'per:parents',\n",
       " 'per:spouse',\n",
       " 'per:alternate_name',\n",
       " 'per:children',\n",
       " 'per:children',\n",
       " 'per:grandchildren',\n",
       " 'per:friends',\n",
       " 'per:acquaintance',\n",
       " 'unanswerable',\n",
       " 'per:children',\n",
       " 'per:children',\n",
       " 'per:parents',\n",
       " 'per:alternate_name',\n",
       " 'per:spouse',\n",
       " 'per:children',\n",
       " 'per:acquaintance',\n",
       " 'unanswerable',\n",
       " 'per:spouse',\n",
       " 'per:parents',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'per:parents',\n",
       " 'unanswerable',\n",
       " 'per:parents-in-law',\n",
       " 'per:grandparents',\n",
       " 'per:parents',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'per:grandparents',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'per:alternate_name',\n",
       " 'unanswerable',\n",
       " 'per:nurse',\n",
       " 'unanswerable',\n",
       " 'per:nurse',\n",
       " 'unanswerable',\n",
       " 'per:nurse',\n",
       " 'per:nurse',\n",
       " 'unanswerable',\n",
       " 'per:alternate_name',\n",
       " 'unanswerable',\n",
       " 'per:nurse',\n",
       " 'per:children',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'per:spouse',\n",
       " 'per:parents',\n",
       " 'per:siblings',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'per:parents',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'per:children-in-law',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'per:spouse',\n",
       " 'unanswerable',\n",
       " 'per:parents',\n",
       " 'per:relative',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'per:parents',\n",
       " 'per:grandchildren',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'per:children',\n",
       " 'unanswerable',\n",
       " 'per:children',\n",
       " 'per:relative',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'per:alternate_name',\n",
       " 'per:children',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'per:siblings',\n",
       " 'unanswerable',\n",
       " 'per:relative',\n",
       " 'per:relative',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'per:relative',\n",
       " 'per:nurse',\n",
       " 'unanswerable',\n",
       " 'per:alternate_name',\n",
       " 'per:nurse',\n",
       " 'unanswerable',\n",
       " 'per:nurse',\n",
       " 'per:nurse',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'per:nurse',\n",
       " 'unanswerable',\n",
       " 'per:alternate_name',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'per:grandchildren',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'per:children',\n",
       " 'unanswerable',\n",
       " 'per:children',\n",
       " 'per:alternate_name',\n",
       " 'per:relative',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'per:parents-in-law',\n",
       " 'per:parents',\n",
       " 'per:grandparents',\n",
       " 'per:grandparents',\n",
       " 'per:children-in-law',\n",
       " 'per:spouse',\n",
       " 'per:parents',\n",
       " 'per:parents',\n",
       " 'per:children',\n",
       " 'per:spouse',\n",
       " 'per:parents',\n",
       " 'per:parents',\n",
       " 'per:grandchildren',\n",
       " 'per:children',\n",
       " 'per:children',\n",
       " 'per:alternate_name',\n",
       " 'per:grandchildren',\n",
       " 'per:children',\n",
       " 'per:children',\n",
       " 'per:alternate_name',\n",
       " 'per:relative',\n",
       " 'per:dates',\n",
       " 'per:relative',\n",
       " 'per:dates',\n",
       " 'per:relative',\n",
       " 'per:relative',\n",
       " 'per:dates',\n",
       " 'per:alternate_name',\n",
       " 'per:siblings',\n",
       " 'per:relative',\n",
       " 'per:dates',\n",
       " 'per:alternate_name',\n",
       " 'per:siblings',\n",
       " 'per:relative',\n",
       " 'per:siblings',\n",
       " 'per:siblings',\n",
       " 'per:spouse',\n",
       " 'per:spouse',\n",
       " 'per:children-in-law',\n",
       " 'per:spouse',\n",
       " 'per:neighbor',\n",
       " 'per:spouse',\n",
       " 'per:parents-in-law',\n",
       " 'per:parents',\n",
       " 'per:neighbor',\n",
       " 'per:friends',\n",
       " 'per:colleague',\n",
       " 'per:parents',\n",
       " 'per:spouse',\n",
       " 'per:children',\n",
       " 'per:neighbor',\n",
       " 'per:alternate_name',\n",
       " 'per:neighbor',\n",
       " 'per:neighbor',\n",
       " 'per:friends',\n",
       " 'per:colleague',\n",
       " 'per:neighbor',\n",
       " 'per:neighbor',\n",
       " 'per:spouse',\n",
       " 'per:children',\n",
       " 'per:alternate_name',\n",
       " 'per:neighbor',\n",
       " 'per:siblings',\n",
       " 'per:siblings',\n",
       " 'per:children',\n",
       " 'per:spouse',\n",
       " 'per:parents',\n",
       " 'unanswerable',\n",
       " 'per:alternate_name',\n",
       " 'per:siblings',\n",
       " 'per:siblings',\n",
       " 'per:spouse',\n",
       " 'per:parents',\n",
       " 'unanswerable',\n",
       " 'per:siblings',\n",
       " 'per:siblings',\n",
       " 'per:children',\n",
       " 'per:relative',\n",
       " 'per:relative',\n",
       " 'per:subordinate',\n",
       " 'per:boss',\n",
       " 'per:siblings',\n",
       " 'per:siblings',\n",
       " 'per:alternate_name',\n",
       " 'per:relative',\n",
       " 'per:relative',\n",
       " 'per:subordinate',\n",
       " 'per:boss',\n",
       " 'per:siblings',\n",
       " 'per:siblings',\n",
       " 'per:children',\n",
       " 'per:relative',\n",
       " 'per:relative',\n",
       " 'unanswerable',\n",
       " 'per:siblings',\n",
       " 'per:alternate_name',\n",
       " 'per:siblings',\n",
       " 'per:relative',\n",
       " 'per:relative',\n",
       " 'unanswerable',\n",
       " 'per:parents',\n",
       " 'per:parents',\n",
       " 'per:parents',\n",
       " 'per:parents-in-law',\n",
       " 'per:grandparents',\n",
       " 'unanswerable',\n",
       " 'per:parents',\n",
       " 'per:parents',\n",
       " 'per:parents',\n",
       " 'per:parents-in-law',\n",
       " 'per:grandparents',\n",
       " 'unanswerable',\n",
       " 'per:spouse',\n",
       " 'per:relative',\n",
       " 'per:relative',\n",
       " 'per:children-in-law',\n",
       " 'per:parents',\n",
       " 'unanswerable',\n",
       " 'per:spouse',\n",
       " 'per:relative',\n",
       " 'per:relative',\n",
       " 'per:alternate_name',\n",
       " 'per:parents',\n",
       " 'unanswerable',\n",
       " 'per:children',\n",
       " 'per:relative',\n",
       " 'per:relative',\n",
       " 'per:grandchildren',\n",
       " 'per:children',\n",
       " 'unanswerable',\n",
       " 'per:children',\n",
       " 'per:relative',\n",
       " 'per:relative',\n",
       " 'per:children',\n",
       " 'per:alternate_name',\n",
       " 'unanswerable',\n",
       " 'per:nurse',\n",
       " 'per:nurse',\n",
       " 'per:subordinate',\n",
       " 'per:boss',\n",
       " 'per:nurse',\n",
       " 'per:nurse',\n",
       " 'per:nurse',\n",
       " 'per:nurse',\n",
       " 'per:nurse',\n",
       " 'per:nurse',\n",
       " 'per:nurse',\n",
       " 'per:subordinate',\n",
       " 'per:boss',\n",
       " 'per:nurse',\n",
       " 'per:nurse',\n",
       " 'per:alternate_name',\n",
       " 'per:alternate_name',\n",
       " 'per:siblings',\n",
       " 'per:siblings',\n",
       " 'per:children',\n",
       " 'per:spouse',\n",
       " 'per:parents',\n",
       " 'unanswerable',\n",
       " 'per:siblings',\n",
       " 'per:siblings',\n",
       " 'per:spouse',\n",
       " 'per:parents',\n",
       " 'unanswerable',\n",
       " 'per:siblings',\n",
       " 'per:siblings',\n",
       " 'per:alternate_name',\n",
       " 'per:children',\n",
       " 'per:relative',\n",
       " 'per:relative',\n",
       " 'unanswerable',\n",
       " 'per:siblings',\n",
       " 'per:siblings',\n",
       " 'per:relative',\n",
       " 'per:relative',\n",
       " 'unanswerable',\n",
       " 'per:siblings',\n",
       " 'per:alternate_name',\n",
       " 'per:siblings',\n",
       " 'per:children',\n",
       " 'per:relative',\n",
       " 'per:relative',\n",
       " 'per:subordinate',\n",
       " 'per:boss',\n",
       " 'per:siblings',\n",
       " 'per:siblings',\n",
       " 'per:relative',\n",
       " 'per:relative',\n",
       " 'per:subordinate',\n",
       " 'per:boss',\n",
       " 'per:spouse',\n",
       " 'per:relative',\n",
       " 'per:relative',\n",
       " 'per:children-in-law',\n",
       " 'per:alternate_name',\n",
       " 'per:parents',\n",
       " 'unanswerable',\n",
       " 'per:spouse',\n",
       " 'per:relative',\n",
       " 'per:relative',\n",
       " 'per:parents',\n",
       " 'unanswerable',\n",
       " 'per:children',\n",
       " 'per:relative',\n",
       " 'per:relative',\n",
       " 'per:grandchildren',\n",
       " 'per:children',\n",
       " 'per:alternate_name',\n",
       " 'unanswerable',\n",
       " 'per:children',\n",
       " 'per:relative',\n",
       " 'per:relative',\n",
       " 'per:children',\n",
       " 'unanswerable',\n",
       " 'per:nurse',\n",
       " 'per:nurse',\n",
       " 'per:subordinate',\n",
       " 'per:boss',\n",
       " 'per:nurse',\n",
       " 'per:nurse',\n",
       " 'per:nurse',\n",
       " 'per:nurse',\n",
       " 'per:alternate_name',\n",
       " 'per:nurse',\n",
       " 'per:nurse',\n",
       " 'per:nurse',\n",
       " 'per:subordinate',\n",
       " 'per:boss',\n",
       " 'per:nurse',\n",
       " 'per:nurse',\n",
       " 'per:parents',\n",
       " 'per:parents-in-law',\n",
       " 'per:parents',\n",
       " 'unanswerable',\n",
       " 'per:parents-in-law',\n",
       " 'per:children',\n",
       " 'per:spouse',\n",
       " 'per:alternate_name',\n",
       " 'unanswerable',\n",
       " 'per:spouse',\n",
       " 'per:children-in-law',\n",
       " 'per:spouse',\n",
       " 'per:spouse',\n",
       " 'unanswerable',\n",
       " 'per:alternate_name',\n",
       " 'per:children',\n",
       " 'per:alternate_name',\n",
       " 'per:spouse',\n",
       " 'unanswerable',\n",
       " 'per:spouse',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'per:children-in-law',\n",
       " 'per:spouse',\n",
       " 'per:alternate_name',\n",
       " 'per:spouse',\n",
       " 'unanswerable',\n",
       " 'per:children',\n",
       " 'per:siblings',\n",
       " 'per:siblings',\n",
       " 'per:spouse',\n",
       " 'per:parents',\n",
       " 'per:alternate_name',\n",
       " 'per:subordinate',\n",
       " 'per:neighbor',\n",
       " 'per:spouse',\n",
       " 'per:subordinate',\n",
       " 'unanswerable',\n",
       " 'per:parents',\n",
       " 'per:parents',\n",
       " 'per:parents',\n",
       " 'per:parents-in-law',\n",
       " 'per:grandparents',\n",
       " 'per:parents',\n",
       " 'unanswerable',\n",
       " 'per:neighbor',\n",
       " 'per:parents-in-law',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'per:siblings',\n",
       " 'per:children',\n",
       " 'per:siblings',\n",
       " 'per:relative',\n",
       " 'per:relative',\n",
       " 'per:siblings',\n",
       " 'unanswerable',\n",
       " 'per:neighbor',\n",
       " 'per:relative',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'per:siblings',\n",
       " 'per:children',\n",
       " 'per:siblings',\n",
       " 'per:relative',\n",
       " 'per:relative',\n",
       " 'per:siblings',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'per:relative',\n",
       " 'unanswerable',\n",
       " 'per:student',\n",
       " 'per:spouse',\n",
       " 'per:children-in-law',\n",
       " 'per:relative',\n",
       " 'per:relative',\n",
       " 'per:parents',\n",
       " 'per:spouse',\n",
       " 'unanswerable',\n",
       " 'per:neighbor',\n",
       " 'per:alternate_name',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'per:children',\n",
       " 'per:grandchildren',\n",
       " 'per:relative',\n",
       " 'per:relative',\n",
       " 'per:children',\n",
       " 'per:children',\n",
       " 'unanswerable',\n",
       " 'per:neighbor',\n",
       " 'per:children',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'per:alternate_name',\n",
       " 'per:children',\n",
       " 'per:siblings',\n",
       " 'per:siblings',\n",
       " 'per:spouse',\n",
       " 'per:parents',\n",
       " 'per:subordinate',\n",
       " 'per:neighbor',\n",
       " 'per:spouse',\n",
       " 'per:subordinate',\n",
       " 'unanswerable',\n",
       " 'per:boss',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'per:boss',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'per:alternate_name',\n",
       " 'unanswerable',\n",
       " 'per:neighbor',\n",
       " 'per:neighbor',\n",
       " 'per:neighbor',\n",
       " 'unanswerable',\n",
       " 'per:neighbor',\n",
       " 'per:neighbor',\n",
       " 'per:neighbor',\n",
       " 'unanswerable',\n",
       " 'per:neighbor',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'per:spouse',\n",
       " 'per:children-in-law',\n",
       " 'per:relative',\n",
       " 'per:relative',\n",
       " 'per:alternate_name',\n",
       " 'per:parents',\n",
       " 'per:spouse',\n",
       " 'unanswerable',\n",
       " 'per:neighbor',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'per:boss',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'per:boss',\n",
       " 'per:alternate_name',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'per:positive impression',\n",
       " 'per:teacher',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'per:nurse',\n",
       " 'per:alternate_name',\n",
       " 'unanswerable',\n",
       " 'per:neighbor',\n",
       " 'per:nurse',\n",
       " 'per:subordinate',\n",
       " 'per:boss',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'per:neighbor',\n",
       " 'per:parents',\n",
       " 'per:alternate_name',\n",
       " 'unanswerable',\n",
       " 'per:nurse',\n",
       " 'unanswerable',\n",
       " 'per:neighbor',\n",
       " 'per:nurse',\n",
       " 'per:subordinate',\n",
       " 'per:boss',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'per:neighbor',\n",
       " 'unanswerable',\n",
       " 'per:neighbor',\n",
       " 'per:neighbor',\n",
       " 'unanswerable',\n",
       " 'per:neighbor',\n",
       " 'per:friends',\n",
       " 'per:subordinate',\n",
       " 'per:boss',\n",
       " 'unanswerable',\n",
       " 'per:children',\n",
       " 'per:subordinate',\n",
       " 'per:boss',\n",
       " 'unanswerable',\n",
       " 'per:neighbor',\n",
       " 'per:friends',\n",
       " 'per:grandchildren',\n",
       " 'unanswerable',\n",
       " 'per:children',\n",
       " 'per:children',\n",
       " 'per:friends',\n",
       " 'per:acquaintance',\n",
       " 'per:friends',\n",
       " 'per:acquaintance',\n",
       " 'per:alternate_name',\n",
       " 'per:grandparents',\n",
       " 'unanswerable',\n",
       " 'per:parents-in-law',\n",
       " 'per:parents',\n",
       " 'per:acquaintance',\n",
       " 'per:acquaintance',\n",
       " 'per:grandparents',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'per:parents',\n",
       " 'per:children-in-law',\n",
       " 'unanswerable',\n",
       " 'per:spouse',\n",
       " 'per:acquaintance',\n",
       " 'per:acquaintance',\n",
       " 'per:parents',\n",
       " 'per:parents',\n",
       " 'per:children',\n",
       " 'unanswerable',\n",
       " 'per:spouse',\n",
       " 'per:acquaintance',\n",
       " 'per:acquaintance',\n",
       " 'per:parents',\n",
       " 'per:friends',\n",
       " 'per:acquaintance',\n",
       " 'unanswerable',\n",
       " 'per:acquaintance',\n",
       " 'per:acquaintance',\n",
       " 'per:alternate_name',\n",
       " 'per:friends',\n",
       " 'per:friends',\n",
       " 'per:acquaintance',\n",
       " 'unanswerable',\n",
       " 'per:acquaintance',\n",
       " 'per:acquaintance',\n",
       " 'per:alternate_name',\n",
       " 'per:friends',\n",
       " 'per:alternate_name',\n",
       " 'per:grandchildren',\n",
       " 'unanswerable',\n",
       " 'per:children',\n",
       " 'per:children',\n",
       " 'per:friends',\n",
       " 'per:acquaintance',\n",
       " 'per:friends',\n",
       " 'per:acquaintance',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'per:parents',\n",
       " 'per:parents-in-law',\n",
       " 'per:grandparents',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'per:children',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'per:spouse',\n",
       " 'per:parents',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'per:children-in-law',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'per:spouse',\n",
       " 'per:parents',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'per:grandchildren',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'per:children',\n",
       " 'per:children',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'per:alternate_name',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'per:alternate_name',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'per:neighbor',\n",
       " 'per:friends',\n",
       " 'per:colleague',\n",
       " 'per:parents-in-law',\n",
       " 'per:parents',\n",
       " 'per:alternate_name',\n",
       " 'per:siblings-in-law',\n",
       " 'unanswerable',\n",
       " 'per:neighbor',\n",
       " 'per:friends',\n",
       " 'per:colleague',\n",
       " 'per:neighbor',\n",
       " 'per:neighbor',\n",
       " 'per:neighbor',\n",
       " 'per:friends',\n",
       " 'per:colleague',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'per:children-in-law',\n",
       " 'per:neighbor',\n",
       " 'per:spouse',\n",
       " 'per:children-in-law',\n",
       " 'per:relative',\n",
       " 'unanswerable',\n",
       " 'per:children',\n",
       " 'per:neighbor',\n",
       " 'per:spouse',\n",
       " 'per:children',\n",
       " 'per:relative',\n",
       " 'unanswerable',\n",
       " 'per:alternate_name',\n",
       " 'per:neighbor',\n",
       " 'per:friends',\n",
       " 'per:colleague',\n",
       " 'per:parents-in-law',\n",
       " 'per:parents',\n",
       " 'per:siblings-in-law',\n",
       " 'unanswerable',\n",
       " 'per:siblings-in-law',\n",
       " 'unanswerable',\n",
       " 'per:relative',\n",
       " 'per:relative',\n",
       " 'per:siblings-in-law',\n",
       " 'per:grandparents',\n",
       " 'per:parents-in-law',\n",
       " 'per:parents-in-law',\n",
       " 'per:parents',\n",
       " 'per:parents',\n",
       " 'unanswerable',\n",
       " 'per:grandchildren',\n",
       " 'per:children',\n",
       " 'per:children',\n",
       " 'per:relative',\n",
       " 'per:children',\n",
       " 'unanswerable',\n",
       " 'per:children-in-law',\n",
       " 'per:parents',\n",
       " 'per:alternate_name',\n",
       " 'per:relative',\n",
       " 'per:spouse',\n",
       " 'unanswerable',\n",
       " 'per:children-in-law',\n",
       " 'per:parents',\n",
       " 'per:alternate_name',\n",
       " 'per:relative',\n",
       " 'per:spouse',\n",
       " 'unanswerable',\n",
       " 'per:children',\n",
       " 'per:relative',\n",
       " 'per:relative',\n",
       " 'per:relative',\n",
       " 'per:siblings',\n",
       " 'unanswerable',\n",
       " 'per:children',\n",
       " 'per:parents',\n",
       " 'per:spouse',\n",
       " 'per:spouse',\n",
       " 'per:siblings',\n",
       " 'unanswerable',\n",
       " 'per:nurse',\n",
       " 'per:nurse',\n",
       " 'per:nurse',\n",
       " 'per:nurse',\n",
       " 'per:nurse',\n",
       " 'per:nurse',\n",
       " 'per:subordinate',\n",
       " 'per:boss',\n",
       " 'per:relative',\n",
       " 'per:siblings',\n",
       " 'per:children',\n",
       " 'per:relative',\n",
       " 'unanswerable',\n",
       " 'per:subordinate',\n",
       " 'per:boss',\n",
       " 'per:subordinate',\n",
       " 'per:boss',\n",
       " 'per:alternate_name',\n",
       " 'per:nurse',\n",
       " 'per:subordinate',\n",
       " 'per:boss',\n",
       " 'per:nurse',\n",
       " 'per:nurse',\n",
       " 'per:nurse',\n",
       " 'per:nurse',\n",
       " 'unanswerable',\n",
       " 'per:alternate_name',\n",
       " 'per:alternate_name',\n",
       " 'per:nurse',\n",
       " 'per:subordinate',\n",
       " 'per:boss',\n",
       " 'per:relative',\n",
       " 'unanswerable',\n",
       " 'per:spouse',\n",
       " 'per:children-in-law',\n",
       " 'per:parents',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'per:relative',\n",
       " 'per:siblings',\n",
       " 'unanswerable',\n",
       " 'per:spouse',\n",
       " 'per:children',\n",
       " 'per:parents',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'per:siblings',\n",
       " 'per:parents',\n",
       " 'unanswerable',\n",
       " 'per:parents-in-law',\n",
       " 'per:parents',\n",
       " 'per:grandparents',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " 'per:parents',\n",
       " 'per:relative',\n",
       " 'unanswerable',\n",
       " 'per:children',\n",
       " 'per:children',\n",
       " 'per:grandchildren',\n",
       " 'unanswerable',\n",
       " 'unanswerable',\n",
       " ...]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_unlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e7ef8406",
   "metadata": {},
   "outputs": [],
   "source": [
    "crf_results = results(y_test_unlist,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5a2e8222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>per:acquaintance</th>\n",
       "      <th>per:alternate_name</th>\n",
       "      <th>per:boss</th>\n",
       "      <th>per:boyfriend</th>\n",
       "      <th>per:children</th>\n",
       "      <th>per:children-in-law</th>\n",
       "      <th>per:classmate</th>\n",
       "      <th>per:client</th>\n",
       "      <th>per:colleague</th>\n",
       "      <th>...</th>\n",
       "      <th>per:parents-in-law</th>\n",
       "      <th>per:positive impression</th>\n",
       "      <th>per:relative</th>\n",
       "      <th>per:siblings</th>\n",
       "      <th>per:siblings-in-law</th>\n",
       "      <th>per:spouse</th>\n",
       "      <th>per:student</th>\n",
       "      <th>per:subordinate</th>\n",
       "      <th>per:teacher</th>\n",
       "      <th>unanswerable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>per:acquaintance</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>per:alternate_name</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>per:boss</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>per:boyfriend</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>per:children</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>per:children-in-law</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>per:classmate</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>per:client</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>per:colleague</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>per:dates</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>per:ex-boyfriend</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>per:ex-girlfriend</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>per:friends</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>per:girlfriend</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>per:grandchildren</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>per:grandparents</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>per:negative impression</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>per:neighbor</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>per:nurse</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>per:parents</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>per:parents-in-law</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>per:positive impression</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>per:relative</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>per:siblings</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>per:siblings-in-law</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>per:spouse</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>per:student</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>per:subordinate</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>per:teacher</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>unanswerable</td>\n",
       "      <td>181.0</td>\n",
       "      <td>547.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>86.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1662.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows  31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       pred  per:acquaintance  per:alternate_name  per:boss  \\\n",
       "0          per:acquaintance               0.0                 0.0       0.0   \n",
       "1        per:alternate_name               0.0                 0.0       0.0   \n",
       "2                  per:boss               0.0                 0.0       0.0   \n",
       "3             per:boyfriend               0.0                 0.0       0.0   \n",
       "4              per:children               0.0                 0.0       0.0   \n",
       "5       per:children-in-law               0.0                 0.0       0.0   \n",
       "6             per:classmate               0.0                 0.0       0.0   \n",
       "7                per:client               0.0                 0.0       0.0   \n",
       "8             per:colleague               0.0                 0.0       0.0   \n",
       "9                 per:dates               0.0                 0.0       0.0   \n",
       "10         per:ex-boyfriend               0.0                 0.0       0.0   \n",
       "11        per:ex-girlfriend               0.0                 0.0       0.0   \n",
       "12              per:friends               0.0                 0.0       0.0   \n",
       "13           per:girlfriend               0.0                 0.0       0.0   \n",
       "14        per:grandchildren               0.0                 0.0       0.0   \n",
       "15         per:grandparents               0.0                 0.0       0.0   \n",
       "16  per:negative impression               0.0                 0.0       0.0   \n",
       "17             per:neighbor               0.0                 0.0       0.0   \n",
       "18                per:nurse               0.0                 0.0       0.0   \n",
       "19              per:parents               0.0                 0.0       0.0   \n",
       "20       per:parents-in-law               0.0                 0.0       0.0   \n",
       "21  per:positive impression               0.0                 0.0       0.0   \n",
       "22             per:relative               0.0                 0.0       0.0   \n",
       "23             per:siblings               0.0                 0.0       0.0   \n",
       "24      per:siblings-in-law               0.0                 0.0       0.0   \n",
       "25               per:spouse               0.0                 0.0       0.0   \n",
       "26              per:student               0.0                 0.0       0.0   \n",
       "27          per:subordinate               0.0                 0.0       0.0   \n",
       "28              per:teacher               0.0                 0.0       0.0   \n",
       "29             unanswerable             181.0               547.0      78.0   \n",
       "\n",
       "    per:boyfriend  per:children  per:children-in-law  per:classmate  \\\n",
       "0             0.0           0.0                  0.0            0.0   \n",
       "1             0.0           0.0                  0.0            0.0   \n",
       "2             0.0           0.0                  0.0            0.0   \n",
       "3             0.0           0.0                  0.0            0.0   \n",
       "4             0.0           0.0                  0.0            0.0   \n",
       "5             0.0           0.0                  0.0            0.0   \n",
       "6             0.0           0.0                  0.0            0.0   \n",
       "7             0.0           0.0                  0.0            0.0   \n",
       "8             0.0           0.0                  0.0            0.0   \n",
       "9             0.0           0.0                  0.0            0.0   \n",
       "10            0.0           0.0                  0.0            0.0   \n",
       "11            0.0           0.0                  0.0            0.0   \n",
       "12            0.0           0.0                  0.0            0.0   \n",
       "13            0.0           0.0                  0.0            0.0   \n",
       "14            0.0           0.0                  0.0            0.0   \n",
       "15            0.0           0.0                  0.0            0.0   \n",
       "16            0.0           0.0                  0.0            0.0   \n",
       "17            0.0           0.0                  0.0            0.0   \n",
       "18            0.0           0.0                  0.0            0.0   \n",
       "19            0.0           0.0                  0.0            0.0   \n",
       "20            0.0           0.0                  0.0            0.0   \n",
       "21            0.0           0.0                  0.0            0.0   \n",
       "22            0.0           0.0                  0.0            0.0   \n",
       "23            0.0           0.0                  0.0            0.0   \n",
       "24            0.0           0.0                  0.0            0.0   \n",
       "25            0.0           0.0                  0.0            0.0   \n",
       "26            0.0           0.0                  0.0            0.0   \n",
       "27            0.0           0.0                  0.0            0.0   \n",
       "28            0.0           0.0                  0.0            0.0   \n",
       "29           46.0         335.0                 86.0           34.0   \n",
       "\n",
       "    per:client  per:colleague  ...  per:parents-in-law  \\\n",
       "0          0.0            0.0  ...                 0.0   \n",
       "1          0.0            0.0  ...                 0.0   \n",
       "2          0.0            0.0  ...                 0.0   \n",
       "3          0.0            0.0  ...                 0.0   \n",
       "4          0.0            0.0  ...                 0.0   \n",
       "5          0.0            0.0  ...                 0.0   \n",
       "6          0.0            0.0  ...                 0.0   \n",
       "7          0.0            0.0  ...                 0.0   \n",
       "8          0.0            0.0  ...                 0.0   \n",
       "9          0.0            0.0  ...                 0.0   \n",
       "10         0.0            0.0  ...                 0.0   \n",
       "11         0.0            0.0  ...                 0.0   \n",
       "12         0.0            0.0  ...                 0.0   \n",
       "13         0.0            0.0  ...                 0.0   \n",
       "14         0.0            0.0  ...                 0.0   \n",
       "15         0.0            0.0  ...                 0.0   \n",
       "16         0.0            0.0  ...                 0.0   \n",
       "17         0.0            0.0  ...                 0.0   \n",
       "18         0.0            0.0  ...                 0.0   \n",
       "19         0.0            0.0  ...                 0.0   \n",
       "20         0.0            0.0  ...                 0.0   \n",
       "21         0.0            0.0  ...                 0.0   \n",
       "22         0.0            0.0  ...                 0.0   \n",
       "23         0.0            0.0  ...                 0.0   \n",
       "24         0.0            0.0  ...                 0.0   \n",
       "25         0.0            0.0  ...                 0.0   \n",
       "26         0.0            0.0  ...                 0.0   \n",
       "27         0.0            0.0  ...                 0.0   \n",
       "28         0.0            0.0  ...                 0.0   \n",
       "29        19.0           30.0  ...                86.0   \n",
       "\n",
       "    per:positive impression  per:relative  per:siblings  per:siblings-in-law  \\\n",
       "0                       0.0           0.0           0.0                  0.0   \n",
       "1                       0.0           0.0           0.0                  0.0   \n",
       "2                       0.0           0.0           0.0                  0.0   \n",
       "3                       0.0           0.0           0.0                  0.0   \n",
       "4                       0.0           0.0           0.0                  0.0   \n",
       "5                       0.0           0.0           0.0                  0.0   \n",
       "6                       0.0           0.0           0.0                  0.0   \n",
       "7                       0.0           0.0           0.0                  0.0   \n",
       "8                       0.0           0.0           0.0                  0.0   \n",
       "9                       0.0           0.0           0.0                  0.0   \n",
       "10                      0.0           0.0           0.0                  0.0   \n",
       "11                      0.0           0.0           0.0                  0.0   \n",
       "12                      0.0           0.0           0.0                  0.0   \n",
       "13                      0.0           0.0           0.0                  0.0   \n",
       "14                      0.0           0.0           0.0                  0.0   \n",
       "15                      0.0           0.0           0.0                  0.0   \n",
       "16                      0.0           0.0           0.0                  0.0   \n",
       "17                      0.0           0.0           0.0                  0.0   \n",
       "18                      0.0           0.0           0.0                  0.0   \n",
       "19                      0.0           0.0           0.0                  0.0   \n",
       "20                      0.0           0.0           0.0                  0.0   \n",
       "21                      0.0           0.0           0.0                  0.0   \n",
       "22                      0.0           0.0           0.0                  0.0   \n",
       "23                      0.0           0.0           0.0                  0.0   \n",
       "24                      0.0           0.0           0.0                  0.0   \n",
       "25                      0.0           0.0           0.0                  0.0   \n",
       "26                      0.0           0.0           0.0                  0.0   \n",
       "27                      0.0           0.0           0.0                  0.0   \n",
       "28                      0.0           0.0           0.0                  0.0   \n",
       "29                     27.0         350.0         144.0                  4.0   \n",
       "\n",
       "    per:spouse  per:student  per:subordinate  per:teacher  unanswerable  \n",
       "0          0.0          0.0              0.0          0.0           0.0  \n",
       "1          0.0          0.0              0.0          0.0           0.0  \n",
       "2          0.0          0.0              0.0          0.0           0.0  \n",
       "3          0.0          0.0              0.0          0.0           0.0  \n",
       "4          0.0          0.0              0.0          0.0           0.0  \n",
       "5          0.0          0.0              0.0          0.0           0.0  \n",
       "6          0.0          0.0              0.0          0.0           0.0  \n",
       "7          0.0          0.0              0.0          0.0           0.0  \n",
       "8          0.0          0.0              0.0          0.0           0.0  \n",
       "9          0.0          0.0              0.0          0.0           0.0  \n",
       "10         0.0          0.0              0.0          0.0           0.0  \n",
       "11         0.0          0.0              0.0          0.0           0.0  \n",
       "12         0.0          0.0              0.0          0.0           0.0  \n",
       "13         0.0          0.0              0.0          0.0           0.0  \n",
       "14         0.0          0.0              0.0          0.0           0.0  \n",
       "15         0.0          0.0              0.0          0.0           0.0  \n",
       "16         0.0          0.0              0.0          0.0           0.0  \n",
       "17         0.0          0.0              0.0          0.0           0.0  \n",
       "18         0.0          0.0              0.0          0.0           0.0  \n",
       "19         0.0          0.0              0.0          0.0           0.0  \n",
       "20         0.0          0.0              0.0          0.0           0.0  \n",
       "21         0.0          0.0              0.0          0.0           0.0  \n",
       "22         0.0          0.0              0.0          0.0           0.0  \n",
       "23         0.0          0.0              0.0          0.0           0.0  \n",
       "24         0.0          0.0              0.0          0.0           0.0  \n",
       "25         0.0          0.0              0.0          0.0           0.0  \n",
       "26         0.0          0.0              0.0          0.0           0.0  \n",
       "27         0.0          0.0              0.0          0.0           0.0  \n",
       "28         0.0          0.0              0.0          0.0           0.0  \n",
       "29       174.0          6.0             78.0          6.0        1662.0  \n",
       "\n",
       "[30 rows x 31 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf_results.cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e70d0640",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "513aa944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-1.1.5-cp36-cp36m-manylinux1_x86_64.whl (9.5 MB)\n",
      "\u001b[K     || 9.5 MB 3.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pytz>=2017.2\n",
      "  Using cached pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home2/elyeb/anaconda3/envs/python368env/lib/python3.6/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /home2/elyeb/anaconda3/envs/python368env/lib/python3.6/site-packages (from pandas) (1.19.5)\n",
      "Requirement already satisfied: six>=1.5 in /home2/elyeb/anaconda3/envs/python368env/lib/python3.6/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Installing collected packages: pytz, pandas\n",
      "Successfully installed pandas-1.1.5 pytz-2023.3\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd6a0475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save version with extra field for tokenized/prepped dialogues\n",
    "with open('../CRECIL/Final_Data/train_1.pickle','wb') as outfile:\n",
    "    pickle.dump(train_df,outfile,protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ff16fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save version with extra field for tokenized/prepped dialogues\n",
    "with open('../CRECIL/Final_Data/dev_1.pickle','wb') as outfile:\n",
    "    pickle.dump(dev_df,outfile,protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f697997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save version with extra field for tokenized/prepped dialogues\n",
    "with open('../CRECIL/Final_Data/test_1.pickle','wb') as outfile:\n",
    "    pickle.dump(test_df,outfile,protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcda2766",
   "metadata": {},
   "source": [
    "### Question 1: \n",
    "how does per:alternate_name get predicted, if we have masked names? <br/>\n",
    "**Answer**: \"The model's input consists of a dialogue and a character entity pair to be recognized\". I take this to mean that the pairs of entities within the dialogue are given, so models don't have to recreate the pairs from the dialogue itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40dc5c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rid_to_rel = Counter() #given an rid, return the relation\n",
    "rel_to_rid = dict() #given a relation, return the rid\n",
    "\n",
    "for item in train_df:\n",
    "    for rel in item[1]:\n",
    "        \n",
    "        for i in range(0,len(rel['r'])):\n",
    "            if rel['r'][i] not in rel_to_rid:\n",
    "                rel_to_rid[rel['r'][i]] = rel['rid'][i]\n",
    "            if rel['rid'][i] not in rid_to_rel:\n",
    "                rid_to_rel[rel['rid'][i]] = rel['r'][i]\n",
    "                \n",
    "rid_to_rel = collections.OrderedDict(sorted(rid_to_rel.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f30a74d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rid_to_rel.pickle','wb') as outfile:\n",
    "    pickle.dump(rid_to_rel,outfile,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('rel_to_rid.pickle','wb') as outfile:\n",
    "    pickle.dump(rel_to_rid,outfile,protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d8386f",
   "metadata": {},
   "source": [
    "Watch [this link](https://www.google.com/search?q=add+features+feature+engineering+one-hot+encoding+with+bert&oq=add+features+feature+engineering+one-hot+encoding+with+bert&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIHCAEQIRigAdIBCTExODI1ajBqN6gCALACAA&sourceid=chrome&ie=UTF-8#fpstate=ive&vld=cid:66503114,vid:NbbsVcs42jE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d383a89c",
   "metadata": {},
   "source": [
    "Analysis: make a correlation matrix among the 32 relations. Surely per:parent and per:child must occur together frequently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0bae46d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7422"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_dev = 0\n",
    "for i in range(0,len(dev_df)):\n",
    "    total_dev += len(dev_df[i][1])\n",
    "total_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b98c462f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rid_to_rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2f2a9966",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create empty data frame\n",
    "zero_data = np.zeros(shape=(len(train_df),len(rid_to_rel)))\n",
    "gt_df = pd.DataFrame(zero_data, columns=rid_to_rel.values())\n",
    "\n",
    "for i in range(0,len(train_df)):\n",
    "    for rel_item in train_df[i][1]:\n",
    "        for j in rel_item['rid']:\n",
    "            gt_df.iat[i,j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3d518658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1.0: 429, 0.0: 53})"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(gt_df['per:alternate_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d45dfcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = gt_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2ddb32f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>per:alternate_name</th>\n",
       "      <th>per:children</th>\n",
       "      <th>per:parents</th>\n",
       "      <th>per:acquaintance</th>\n",
       "      <th>per:client</th>\n",
       "      <th>per:colleague</th>\n",
       "      <th>per:ex-girlfriend</th>\n",
       "      <th>per:girlfriend</th>\n",
       "      <th>per:dates</th>\n",
       "      <th>per:ex-boyfriend</th>\n",
       "      <th>...</th>\n",
       "      <th>per:siblings</th>\n",
       "      <th>per:spouse</th>\n",
       "      <th>per:grandparents</th>\n",
       "      <th>per:grandchildren</th>\n",
       "      <th>per:teacher</th>\n",
       "      <th>per:student</th>\n",
       "      <th>per:roommate</th>\n",
       "      <th>per:relative</th>\n",
       "      <th>per:siblings-in-law</th>\n",
       "      <th>unanswerable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>per:alternate_name</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.117070</td>\n",
       "      <td>0.117070</td>\n",
       "      <td>0.055997</td>\n",
       "      <td>0.080460</td>\n",
       "      <td>0.085296</td>\n",
       "      <td>0.069229</td>\n",
       "      <td>0.078680</td>\n",
       "      <td>0.063102</td>\n",
       "      <td>0.069229</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069274</td>\n",
       "      <td>0.108441</td>\n",
       "      <td>0.092696</td>\n",
       "      <td>0.092696</td>\n",
       "      <td>0.048484</td>\n",
       "      <td>0.048484</td>\n",
       "      <td>0.016026</td>\n",
       "      <td>0.095654</td>\n",
       "      <td>0.042669</td>\n",
       "      <td>0.090971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per:children</th>\n",
       "      <td>0.117070</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.006048</td>\n",
       "      <td>-0.033970</td>\n",
       "      <td>-0.037705</td>\n",
       "      <td>-0.128090</td>\n",
       "      <td>-0.150463</td>\n",
       "      <td>-0.115819</td>\n",
       "      <td>-0.128090</td>\n",
       "      <td>...</td>\n",
       "      <td>0.268160</td>\n",
       "      <td>0.516230</td>\n",
       "      <td>0.402224</td>\n",
       "      <td>0.402224</td>\n",
       "      <td>-0.020470</td>\n",
       "      <td>-0.020470</td>\n",
       "      <td>0.027564</td>\n",
       "      <td>0.271393</td>\n",
       "      <td>0.034214</td>\n",
       "      <td>0.099455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per:parents</th>\n",
       "      <td>0.117070</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.006048</td>\n",
       "      <td>-0.033970</td>\n",
       "      <td>-0.037705</td>\n",
       "      <td>-0.128090</td>\n",
       "      <td>-0.150463</td>\n",
       "      <td>-0.115819</td>\n",
       "      <td>-0.128090</td>\n",
       "      <td>...</td>\n",
       "      <td>0.268160</td>\n",
       "      <td>0.516230</td>\n",
       "      <td>0.402224</td>\n",
       "      <td>0.402224</td>\n",
       "      <td>-0.020470</td>\n",
       "      <td>-0.020470</td>\n",
       "      <td>0.027564</td>\n",
       "      <td>0.271393</td>\n",
       "      <td>0.034214</td>\n",
       "      <td>0.099455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per:acquaintance</th>\n",
       "      <td>0.055997</td>\n",
       "      <td>-0.006048</td>\n",
       "      <td>-0.006048</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.043498</td>\n",
       "      <td>-0.021592</td>\n",
       "      <td>-0.022164</td>\n",
       "      <td>-0.013124</td>\n",
       "      <td>0.058844</td>\n",
       "      <td>-0.022164</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039423</td>\n",
       "      <td>0.093797</td>\n",
       "      <td>0.092402</td>\n",
       "      <td>0.092402</td>\n",
       "      <td>0.069985</td>\n",
       "      <td>0.069985</td>\n",
       "      <td>-0.019263</td>\n",
       "      <td>-0.043313</td>\n",
       "      <td>-0.051286</td>\n",
       "      <td>0.027149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per:client</th>\n",
       "      <td>0.080460</td>\n",
       "      <td>-0.033970</td>\n",
       "      <td>-0.033970</td>\n",
       "      <td>-0.043498</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.099027</td>\n",
       "      <td>-0.045087</td>\n",
       "      <td>-0.051243</td>\n",
       "      <td>-0.058975</td>\n",
       "      <td>-0.045087</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.081649</td>\n",
       "      <td>-0.087550</td>\n",
       "      <td>-0.056349</td>\n",
       "      <td>-0.056349</td>\n",
       "      <td>-0.031576</td>\n",
       "      <td>-0.031576</td>\n",
       "      <td>-0.010438</td>\n",
       "      <td>-0.102300</td>\n",
       "      <td>-0.027789</td>\n",
       "      <td>0.131067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per:colleague</th>\n",
       "      <td>0.085296</td>\n",
       "      <td>-0.037705</td>\n",
       "      <td>-0.037705</td>\n",
       "      <td>-0.021592</td>\n",
       "      <td>0.099027</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.048390</td>\n",
       "      <td>-0.034804</td>\n",
       "      <td>0.043607</td>\n",
       "      <td>-0.048390</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.139865</td>\n",
       "      <td>-0.025027</td>\n",
       "      <td>-0.025115</td>\n",
       "      <td>-0.025115</td>\n",
       "      <td>-0.055904</td>\n",
       "      <td>-0.055904</td>\n",
       "      <td>-0.018479</td>\n",
       "      <td>-0.099105</td>\n",
       "      <td>0.249716</td>\n",
       "      <td>0.149115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per:ex-girlfriend</th>\n",
       "      <td>0.069229</td>\n",
       "      <td>-0.128090</td>\n",
       "      <td>-0.128090</td>\n",
       "      <td>-0.022164</td>\n",
       "      <td>-0.045087</td>\n",
       "      <td>-0.048390</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.777210</td>\n",
       "      <td>0.538054</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005680</td>\n",
       "      <td>-0.064143</td>\n",
       "      <td>-0.031815</td>\n",
       "      <td>-0.031815</td>\n",
       "      <td>0.134502</td>\n",
       "      <td>0.134502</td>\n",
       "      <td>-0.008981</td>\n",
       "      <td>0.045175</td>\n",
       "      <td>-0.023910</td>\n",
       "      <td>0.112771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per:girlfriend</th>\n",
       "      <td>0.078680</td>\n",
       "      <td>-0.150463</td>\n",
       "      <td>-0.150463</td>\n",
       "      <td>-0.013124</td>\n",
       "      <td>-0.051243</td>\n",
       "      <td>-0.034804</td>\n",
       "      <td>0.777210</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.506325</td>\n",
       "      <td>0.777210</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.054955</td>\n",
       "      <td>-0.097220</td>\n",
       "      <td>-0.069105</td>\n",
       "      <td>-0.069105</td>\n",
       "      <td>0.041021</td>\n",
       "      <td>0.041021</td>\n",
       "      <td>-0.010207</td>\n",
       "      <td>0.005557</td>\n",
       "      <td>-0.027174</td>\n",
       "      <td>0.128167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per:dates</th>\n",
       "      <td>0.063102</td>\n",
       "      <td>-0.115819</td>\n",
       "      <td>-0.115819</td>\n",
       "      <td>0.058844</td>\n",
       "      <td>-0.058975</td>\n",
       "      <td>0.043607</td>\n",
       "      <td>0.538054</td>\n",
       "      <td>0.506325</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.538054</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020943</td>\n",
       "      <td>-0.107310</td>\n",
       "      <td>-0.059057</td>\n",
       "      <td>-0.059057</td>\n",
       "      <td>0.027903</td>\n",
       "      <td>0.027903</td>\n",
       "      <td>-0.011747</td>\n",
       "      <td>0.053030</td>\n",
       "      <td>-0.031275</td>\n",
       "      <td>0.087760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per:ex-boyfriend</th>\n",
       "      <td>0.069229</td>\n",
       "      <td>-0.128090</td>\n",
       "      <td>-0.128090</td>\n",
       "      <td>-0.022164</td>\n",
       "      <td>-0.045087</td>\n",
       "      <td>-0.048390</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.777210</td>\n",
       "      <td>0.538054</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005680</td>\n",
       "      <td>-0.064143</td>\n",
       "      <td>-0.031815</td>\n",
       "      <td>-0.031815</td>\n",
       "      <td>0.134502</td>\n",
       "      <td>0.134502</td>\n",
       "      <td>-0.008981</td>\n",
       "      <td>0.045175</td>\n",
       "      <td>-0.023910</td>\n",
       "      <td>0.112771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per:boyfriend</th>\n",
       "      <td>0.078680</td>\n",
       "      <td>-0.150463</td>\n",
       "      <td>-0.150463</td>\n",
       "      <td>-0.013124</td>\n",
       "      <td>-0.051243</td>\n",
       "      <td>-0.034804</td>\n",
       "      <td>0.777210</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.506325</td>\n",
       "      <td>0.777210</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.054955</td>\n",
       "      <td>-0.097220</td>\n",
       "      <td>-0.069105</td>\n",
       "      <td>-0.069105</td>\n",
       "      <td>0.041021</td>\n",
       "      <td>0.041021</td>\n",
       "      <td>-0.010207</td>\n",
       "      <td>0.005557</td>\n",
       "      <td>-0.027174</td>\n",
       "      <td>0.128167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per:friends</th>\n",
       "      <td>0.149174</td>\n",
       "      <td>-0.027609</td>\n",
       "      <td>-0.027609</td>\n",
       "      <td>0.343989</td>\n",
       "      <td>-0.048954</td>\n",
       "      <td>0.341840</td>\n",
       "      <td>0.064143</td>\n",
       "      <td>0.017628</td>\n",
       "      <td>0.019524</td>\n",
       "      <td>0.064143</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.067863</td>\n",
       "      <td>-0.037405</td>\n",
       "      <td>0.027079</td>\n",
       "      <td>0.027079</td>\n",
       "      <td>-0.080418</td>\n",
       "      <td>-0.080418</td>\n",
       "      <td>0.056280</td>\n",
       "      <td>-0.010731</td>\n",
       "      <td>0.114386</td>\n",
       "      <td>0.149084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per:nickname</th>\n",
       "      <td>0.022688</td>\n",
       "      <td>-0.033879</td>\n",
       "      <td>-0.033879</td>\n",
       "      <td>-0.027271</td>\n",
       "      <td>-0.014776</td>\n",
       "      <td>-0.026161</td>\n",
       "      <td>-0.012714</td>\n",
       "      <td>-0.014449</td>\n",
       "      <td>0.116963</td>\n",
       "      <td>-0.012714</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035721</td>\n",
       "      <td>-0.079675</td>\n",
       "      <td>-0.054129</td>\n",
       "      <td>-0.054129</td>\n",
       "      <td>-0.008904</td>\n",
       "      <td>-0.008904</td>\n",
       "      <td>-0.002943</td>\n",
       "      <td>-0.045928</td>\n",
       "      <td>-0.007836</td>\n",
       "      <td>0.036959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per:neighbor</th>\n",
       "      <td>0.118955</td>\n",
       "      <td>-0.156351</td>\n",
       "      <td>-0.156351</td>\n",
       "      <td>-0.080485</td>\n",
       "      <td>0.095753</td>\n",
       "      <td>0.402099</td>\n",
       "      <td>0.082387</td>\n",
       "      <td>0.061985</td>\n",
       "      <td>0.014677</td>\n",
       "      <td>0.082387</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.102951</td>\n",
       "      <td>-0.104395</td>\n",
       "      <td>-0.119707</td>\n",
       "      <td>-0.119707</td>\n",
       "      <td>-0.058595</td>\n",
       "      <td>-0.058595</td>\n",
       "      <td>0.068497</td>\n",
       "      <td>-0.045159</td>\n",
       "      <td>0.144770</td>\n",
       "      <td>0.151657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per:nurse</th>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.061686</td>\n",
       "      <td>0.061686</td>\n",
       "      <td>-0.098869</td>\n",
       "      <td>-0.027491</td>\n",
       "      <td>-0.167636</td>\n",
       "      <td>0.143795</td>\n",
       "      <td>0.157671</td>\n",
       "      <td>0.111904</td>\n",
       "      <td>0.143795</td>\n",
       "      <td>...</td>\n",
       "      <td>0.218647</td>\n",
       "      <td>0.005574</td>\n",
       "      <td>0.158635</td>\n",
       "      <td>0.158635</td>\n",
       "      <td>-0.021665</td>\n",
       "      <td>-0.021665</td>\n",
       "      <td>-0.020645</td>\n",
       "      <td>0.297366</td>\n",
       "      <td>-0.054964</td>\n",
       "      <td>0.233627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per:parents-in-law</th>\n",
       "      <td>0.097436</td>\n",
       "      <td>0.571590</td>\n",
       "      <td>0.571590</td>\n",
       "      <td>0.023380</td>\n",
       "      <td>-0.060897</td>\n",
       "      <td>0.023424</td>\n",
       "      <td>-0.057957</td>\n",
       "      <td>-0.070265</td>\n",
       "      <td>-0.046716</td>\n",
       "      <td>-0.057957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.312749</td>\n",
       "      <td>0.513330</td>\n",
       "      <td>0.571698</td>\n",
       "      <td>0.571698</td>\n",
       "      <td>0.021717</td>\n",
       "      <td>0.021717</td>\n",
       "      <td>0.038072</td>\n",
       "      <td>0.308420</td>\n",
       "      <td>0.066112</td>\n",
       "      <td>0.118493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per:children-in-law</th>\n",
       "      <td>0.097436</td>\n",
       "      <td>0.571590</td>\n",
       "      <td>0.571590</td>\n",
       "      <td>0.023380</td>\n",
       "      <td>-0.060897</td>\n",
       "      <td>0.023424</td>\n",
       "      <td>-0.057957</td>\n",
       "      <td>-0.070265</td>\n",
       "      <td>-0.046716</td>\n",
       "      <td>-0.057957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.312749</td>\n",
       "      <td>0.513330</td>\n",
       "      <td>0.571698</td>\n",
       "      <td>0.571698</td>\n",
       "      <td>0.021717</td>\n",
       "      <td>0.021717</td>\n",
       "      <td>0.038072</td>\n",
       "      <td>0.308420</td>\n",
       "      <td>0.066112</td>\n",
       "      <td>0.118493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per:positive impression</th>\n",
       "      <td>0.099860</td>\n",
       "      <td>0.046968</td>\n",
       "      <td>0.046968</td>\n",
       "      <td>0.056086</td>\n",
       "      <td>-0.028755</td>\n",
       "      <td>-0.069801</td>\n",
       "      <td>0.027288</td>\n",
       "      <td>-0.026576</td>\n",
       "      <td>0.090137</td>\n",
       "      <td>0.027288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103577</td>\n",
       "      <td>0.020420</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>0.427219</td>\n",
       "      <td>0.427219</td>\n",
       "      <td>-0.012954</td>\n",
       "      <td>0.165405</td>\n",
       "      <td>-0.034489</td>\n",
       "      <td>0.126064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per:classmate</th>\n",
       "      <td>0.042768</td>\n",
       "      <td>-0.021674</td>\n",
       "      <td>-0.021674</td>\n",
       "      <td>-0.068701</td>\n",
       "      <td>-0.062059</td>\n",
       "      <td>-0.062672</td>\n",
       "      <td>0.076589</td>\n",
       "      <td>0.054930</td>\n",
       "      <td>0.032170</td>\n",
       "      <td>0.076589</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024501</td>\n",
       "      <td>-0.049098</td>\n",
       "      <td>0.022952</td>\n",
       "      <td>0.022952</td>\n",
       "      <td>0.205363</td>\n",
       "      <td>0.205363</td>\n",
       "      <td>0.168187</td>\n",
       "      <td>-0.001588</td>\n",
       "      <td>-0.032911</td>\n",
       "      <td>0.079014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per:negative impression</th>\n",
       "      <td>0.112791</td>\n",
       "      <td>0.097344</td>\n",
       "      <td>0.097344</td>\n",
       "      <td>0.083241</td>\n",
       "      <td>0.057678</td>\n",
       "      <td>0.054316</td>\n",
       "      <td>0.162457</td>\n",
       "      <td>0.095430</td>\n",
       "      <td>0.153463</td>\n",
       "      <td>0.162457</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009254</td>\n",
       "      <td>0.085026</td>\n",
       "      <td>0.078519</td>\n",
       "      <td>0.078519</td>\n",
       "      <td>0.113776</td>\n",
       "      <td>0.113776</td>\n",
       "      <td>-0.014632</td>\n",
       "      <td>0.133987</td>\n",
       "      <td>-0.038955</td>\n",
       "      <td>0.150657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per:subordinate</th>\n",
       "      <td>0.041692</td>\n",
       "      <td>0.032876</td>\n",
       "      <td>0.032876</td>\n",
       "      <td>-0.082080</td>\n",
       "      <td>-0.034529</td>\n",
       "      <td>-0.107662</td>\n",
       "      <td>0.178520</td>\n",
       "      <td>0.168067</td>\n",
       "      <td>0.099419</td>\n",
       "      <td>0.178520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.283327</td>\n",
       "      <td>-0.003014</td>\n",
       "      <td>0.125390</td>\n",
       "      <td>0.125390</td>\n",
       "      <td>-0.009589</td>\n",
       "      <td>-0.009589</td>\n",
       "      <td>-0.018002</td>\n",
       "      <td>0.387729</td>\n",
       "      <td>-0.047928</td>\n",
       "      <td>0.197880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per:boss</th>\n",
       "      <td>0.041692</td>\n",
       "      <td>0.032876</td>\n",
       "      <td>0.032876</td>\n",
       "      <td>-0.082080</td>\n",
       "      <td>-0.034529</td>\n",
       "      <td>-0.107662</td>\n",
       "      <td>0.178520</td>\n",
       "      <td>0.168067</td>\n",
       "      <td>0.099419</td>\n",
       "      <td>0.178520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.283327</td>\n",
       "      <td>-0.003014</td>\n",
       "      <td>0.125390</td>\n",
       "      <td>0.125390</td>\n",
       "      <td>-0.009589</td>\n",
       "      <td>-0.009589</td>\n",
       "      <td>-0.018002</td>\n",
       "      <td>0.387729</td>\n",
       "      <td>-0.047928</td>\n",
       "      <td>0.197880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per:siblings</th>\n",
       "      <td>0.069274</td>\n",
       "      <td>0.268160</td>\n",
       "      <td>0.268160</td>\n",
       "      <td>0.039423</td>\n",
       "      <td>-0.081649</td>\n",
       "      <td>-0.139865</td>\n",
       "      <td>-0.005680</td>\n",
       "      <td>-0.054955</td>\n",
       "      <td>-0.020943</td>\n",
       "      <td>-0.005680</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.338194</td>\n",
       "      <td>0.222272</td>\n",
       "      <td>0.222272</td>\n",
       "      <td>0.140733</td>\n",
       "      <td>0.140733</td>\n",
       "      <td>0.082395</td>\n",
       "      <td>0.757022</td>\n",
       "      <td>-0.026243</td>\n",
       "      <td>0.089702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per:spouse</th>\n",
       "      <td>0.108441</td>\n",
       "      <td>0.516230</td>\n",
       "      <td>0.516230</td>\n",
       "      <td>0.093797</td>\n",
       "      <td>-0.087550</td>\n",
       "      <td>-0.025027</td>\n",
       "      <td>-0.064143</td>\n",
       "      <td>-0.097220</td>\n",
       "      <td>-0.107310</td>\n",
       "      <td>-0.064143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.338194</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.360604</td>\n",
       "      <td>0.360604</td>\n",
       "      <td>-0.013587</td>\n",
       "      <td>-0.013587</td>\n",
       "      <td>0.036940</td>\n",
       "      <td>0.163382</td>\n",
       "      <td>0.062894</td>\n",
       "      <td>0.106675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per:grandparents</th>\n",
       "      <td>0.092696</td>\n",
       "      <td>0.402224</td>\n",
       "      <td>0.402224</td>\n",
       "      <td>0.092402</td>\n",
       "      <td>-0.056349</td>\n",
       "      <td>-0.025115</td>\n",
       "      <td>-0.031815</td>\n",
       "      <td>-0.069105</td>\n",
       "      <td>-0.059057</td>\n",
       "      <td>-0.031815</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222272</td>\n",
       "      <td>0.360604</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.022282</td>\n",
       "      <td>-0.022282</td>\n",
       "      <td>0.054374</td>\n",
       "      <td>0.170528</td>\n",
       "      <td>0.003873</td>\n",
       "      <td>0.147863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per:grandchildren</th>\n",
       "      <td>0.092696</td>\n",
       "      <td>0.402224</td>\n",
       "      <td>0.402224</td>\n",
       "      <td>0.092402</td>\n",
       "      <td>-0.056349</td>\n",
       "      <td>-0.025115</td>\n",
       "      <td>-0.031815</td>\n",
       "      <td>-0.069105</td>\n",
       "      <td>-0.059057</td>\n",
       "      <td>-0.031815</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222272</td>\n",
       "      <td>0.360604</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.022282</td>\n",
       "      <td>-0.022282</td>\n",
       "      <td>0.054374</td>\n",
       "      <td>0.170528</td>\n",
       "      <td>0.003873</td>\n",
       "      <td>0.147863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per:teacher</th>\n",
       "      <td>0.048484</td>\n",
       "      <td>-0.020470</td>\n",
       "      <td>-0.020470</td>\n",
       "      <td>0.069985</td>\n",
       "      <td>-0.031576</td>\n",
       "      <td>-0.055904</td>\n",
       "      <td>0.134502</td>\n",
       "      <td>0.041021</td>\n",
       "      <td>0.027903</td>\n",
       "      <td>0.134502</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140733</td>\n",
       "      <td>-0.013587</td>\n",
       "      <td>-0.022282</td>\n",
       "      <td>-0.022282</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.006290</td>\n",
       "      <td>0.064084</td>\n",
       "      <td>-0.016745</td>\n",
       "      <td>0.078979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per:student</th>\n",
       "      <td>0.048484</td>\n",
       "      <td>-0.020470</td>\n",
       "      <td>-0.020470</td>\n",
       "      <td>0.069985</td>\n",
       "      <td>-0.031576</td>\n",
       "      <td>-0.055904</td>\n",
       "      <td>0.134502</td>\n",
       "      <td>0.041021</td>\n",
       "      <td>0.027903</td>\n",
       "      <td>0.134502</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140733</td>\n",
       "      <td>-0.013587</td>\n",
       "      <td>-0.022282</td>\n",
       "      <td>-0.022282</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.006290</td>\n",
       "      <td>0.064084</td>\n",
       "      <td>-0.016745</td>\n",
       "      <td>0.078979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per:roommate</th>\n",
       "      <td>0.016026</td>\n",
       "      <td>0.027564</td>\n",
       "      <td>0.027564</td>\n",
       "      <td>-0.019263</td>\n",
       "      <td>-0.010438</td>\n",
       "      <td>-0.018479</td>\n",
       "      <td>-0.008981</td>\n",
       "      <td>-0.010207</td>\n",
       "      <td>-0.011747</td>\n",
       "      <td>-0.008981</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082395</td>\n",
       "      <td>0.036940</td>\n",
       "      <td>0.054374</td>\n",
       "      <td>0.054374</td>\n",
       "      <td>-0.006290</td>\n",
       "      <td>-0.006290</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.064083</td>\n",
       "      <td>-0.005535</td>\n",
       "      <td>0.026106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per:relative</th>\n",
       "      <td>0.095654</td>\n",
       "      <td>0.271393</td>\n",
       "      <td>0.271393</td>\n",
       "      <td>-0.043313</td>\n",
       "      <td>-0.102300</td>\n",
       "      <td>-0.099105</td>\n",
       "      <td>0.045175</td>\n",
       "      <td>0.005557</td>\n",
       "      <td>0.053030</td>\n",
       "      <td>0.045175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.757022</td>\n",
       "      <td>0.163382</td>\n",
       "      <td>0.170528</td>\n",
       "      <td>0.170528</td>\n",
       "      <td>0.064084</td>\n",
       "      <td>0.064084</td>\n",
       "      <td>0.064083</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.133903</td>\n",
       "      <td>0.122185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per:siblings-in-law</th>\n",
       "      <td>0.042669</td>\n",
       "      <td>0.034214</td>\n",
       "      <td>0.034214</td>\n",
       "      <td>-0.051286</td>\n",
       "      <td>-0.027789</td>\n",
       "      <td>0.249716</td>\n",
       "      <td>-0.023910</td>\n",
       "      <td>-0.027174</td>\n",
       "      <td>-0.031275</td>\n",
       "      <td>-0.023910</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026243</td>\n",
       "      <td>0.062894</td>\n",
       "      <td>0.003873</td>\n",
       "      <td>0.003873</td>\n",
       "      <td>-0.016745</td>\n",
       "      <td>-0.016745</td>\n",
       "      <td>-0.005535</td>\n",
       "      <td>0.133903</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unanswerable</th>\n",
       "      <td>0.090971</td>\n",
       "      <td>0.099455</td>\n",
       "      <td>0.099455</td>\n",
       "      <td>0.027149</td>\n",
       "      <td>0.131067</td>\n",
       "      <td>0.149115</td>\n",
       "      <td>0.112771</td>\n",
       "      <td>0.128167</td>\n",
       "      <td>0.087760</td>\n",
       "      <td>0.112771</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089702</td>\n",
       "      <td>0.106675</td>\n",
       "      <td>0.147863</td>\n",
       "      <td>0.147863</td>\n",
       "      <td>0.078979</td>\n",
       "      <td>0.078979</td>\n",
       "      <td>0.026106</td>\n",
       "      <td>0.122185</td>\n",
       "      <td>0.069506</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32 rows  32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         per:alternate_name  per:children  per:parents  \\\n",
       "per:alternate_name                 1.000000      0.117070     0.117070   \n",
       "per:children                       0.117070      1.000000     1.000000   \n",
       "per:parents                        0.117070      1.000000     1.000000   \n",
       "per:acquaintance                   0.055997     -0.006048    -0.006048   \n",
       "per:client                         0.080460     -0.033970    -0.033970   \n",
       "per:colleague                      0.085296     -0.037705    -0.037705   \n",
       "per:ex-girlfriend                  0.069229     -0.128090    -0.128090   \n",
       "per:girlfriend                     0.078680     -0.150463    -0.150463   \n",
       "per:dates                          0.063102     -0.115819    -0.115819   \n",
       "per:ex-boyfriend                   0.069229     -0.128090    -0.128090   \n",
       "per:boyfriend                      0.078680     -0.150463    -0.150463   \n",
       "per:friends                        0.149174     -0.027609    -0.027609   \n",
       "per:nickname                       0.022688     -0.033879    -0.033879   \n",
       "per:neighbor                       0.118955     -0.156351    -0.156351   \n",
       "per:nurse                          0.000293      0.061686     0.061686   \n",
       "per:parents-in-law                 0.097436      0.571590     0.571590   \n",
       "per:children-in-law                0.097436      0.571590     0.571590   \n",
       "per:positive impression            0.099860      0.046968     0.046968   \n",
       "per:classmate                      0.042768     -0.021674    -0.021674   \n",
       "per:negative impression            0.112791      0.097344     0.097344   \n",
       "per:subordinate                    0.041692      0.032876     0.032876   \n",
       "per:boss                           0.041692      0.032876     0.032876   \n",
       "per:siblings                       0.069274      0.268160     0.268160   \n",
       "per:spouse                         0.108441      0.516230     0.516230   \n",
       "per:grandparents                   0.092696      0.402224     0.402224   \n",
       "per:grandchildren                  0.092696      0.402224     0.402224   \n",
       "per:teacher                        0.048484     -0.020470    -0.020470   \n",
       "per:student                        0.048484     -0.020470    -0.020470   \n",
       "per:roommate                       0.016026      0.027564     0.027564   \n",
       "per:relative                       0.095654      0.271393     0.271393   \n",
       "per:siblings-in-law                0.042669      0.034214     0.034214   \n",
       "unanswerable                       0.090971      0.099455     0.099455   \n",
       "\n",
       "                         per:acquaintance  per:client  per:colleague  \\\n",
       "per:alternate_name               0.055997    0.080460       0.085296   \n",
       "per:children                    -0.006048   -0.033970      -0.037705   \n",
       "per:parents                     -0.006048   -0.033970      -0.037705   \n",
       "per:acquaintance                 1.000000   -0.043498      -0.021592   \n",
       "per:client                      -0.043498    1.000000       0.099027   \n",
       "per:colleague                   -0.021592    0.099027       1.000000   \n",
       "per:ex-girlfriend               -0.022164   -0.045087      -0.048390   \n",
       "per:girlfriend                  -0.013124   -0.051243      -0.034804   \n",
       "per:dates                        0.058844   -0.058975       0.043607   \n",
       "per:ex-boyfriend                -0.022164   -0.045087      -0.048390   \n",
       "per:boyfriend                   -0.013124   -0.051243      -0.034804   \n",
       "per:friends                      0.343989   -0.048954       0.341840   \n",
       "per:nickname                    -0.027271   -0.014776      -0.026161   \n",
       "per:neighbor                    -0.080485    0.095753       0.402099   \n",
       "per:nurse                       -0.098869   -0.027491      -0.167636   \n",
       "per:parents-in-law               0.023380   -0.060897       0.023424   \n",
       "per:children-in-law              0.023380   -0.060897       0.023424   \n",
       "per:positive impression          0.056086   -0.028755      -0.069801   \n",
       "per:classmate                   -0.068701   -0.062059      -0.062672   \n",
       "per:negative impression          0.083241    0.057678       0.054316   \n",
       "per:subordinate                 -0.082080   -0.034529      -0.107662   \n",
       "per:boss                        -0.082080   -0.034529      -0.107662   \n",
       "per:siblings                     0.039423   -0.081649      -0.139865   \n",
       "per:spouse                       0.093797   -0.087550      -0.025027   \n",
       "per:grandparents                 0.092402   -0.056349      -0.025115   \n",
       "per:grandchildren                0.092402   -0.056349      -0.025115   \n",
       "per:teacher                      0.069985   -0.031576      -0.055904   \n",
       "per:student                      0.069985   -0.031576      -0.055904   \n",
       "per:roommate                    -0.019263   -0.010438      -0.018479   \n",
       "per:relative                    -0.043313   -0.102300      -0.099105   \n",
       "per:siblings-in-law             -0.051286   -0.027789       0.249716   \n",
       "unanswerable                     0.027149    0.131067       0.149115   \n",
       "\n",
       "                         per:ex-girlfriend  per:girlfriend  per:dates  \\\n",
       "per:alternate_name                0.069229        0.078680   0.063102   \n",
       "per:children                     -0.128090       -0.150463  -0.115819   \n",
       "per:parents                      -0.128090       -0.150463  -0.115819   \n",
       "per:acquaintance                 -0.022164       -0.013124   0.058844   \n",
       "per:client                       -0.045087       -0.051243  -0.058975   \n",
       "per:colleague                    -0.048390       -0.034804   0.043607   \n",
       "per:ex-girlfriend                 1.000000        0.777210   0.538054   \n",
       "per:girlfriend                    0.777210        1.000000   0.506325   \n",
       "per:dates                         0.538054        0.506325   1.000000   \n",
       "per:ex-boyfriend                  1.000000        0.777210   0.538054   \n",
       "per:boyfriend                     0.777210        1.000000   0.506325   \n",
       "per:friends                       0.064143        0.017628   0.019524   \n",
       "per:nickname                     -0.012714       -0.014449   0.116963   \n",
       "per:neighbor                      0.082387        0.061985   0.014677   \n",
       "per:nurse                         0.143795        0.157671   0.111904   \n",
       "per:parents-in-law               -0.057957       -0.070265  -0.046716   \n",
       "per:children-in-law              -0.057957       -0.070265  -0.046716   \n",
       "per:positive impression           0.027288       -0.026576   0.090137   \n",
       "per:classmate                     0.076589        0.054930   0.032170   \n",
       "per:negative impression           0.162457        0.095430   0.153463   \n",
       "per:subordinate                   0.178520        0.168067   0.099419   \n",
       "per:boss                          0.178520        0.168067   0.099419   \n",
       "per:siblings                     -0.005680       -0.054955  -0.020943   \n",
       "per:spouse                       -0.064143       -0.097220  -0.107310   \n",
       "per:grandparents                 -0.031815       -0.069105  -0.059057   \n",
       "per:grandchildren                -0.031815       -0.069105  -0.059057   \n",
       "per:teacher                       0.134502        0.041021   0.027903   \n",
       "per:student                       0.134502        0.041021   0.027903   \n",
       "per:roommate                     -0.008981       -0.010207  -0.011747   \n",
       "per:relative                      0.045175        0.005557   0.053030   \n",
       "per:siblings-in-law              -0.023910       -0.027174  -0.031275   \n",
       "unanswerable                      0.112771        0.128167   0.087760   \n",
       "\n",
       "                         per:ex-boyfriend  ...  per:siblings  per:spouse  \\\n",
       "per:alternate_name               0.069229  ...      0.069274    0.108441   \n",
       "per:children                    -0.128090  ...      0.268160    0.516230   \n",
       "per:parents                     -0.128090  ...      0.268160    0.516230   \n",
       "per:acquaintance                -0.022164  ...      0.039423    0.093797   \n",
       "per:client                      -0.045087  ...     -0.081649   -0.087550   \n",
       "per:colleague                   -0.048390  ...     -0.139865   -0.025027   \n",
       "per:ex-girlfriend                1.000000  ...     -0.005680   -0.064143   \n",
       "per:girlfriend                   0.777210  ...     -0.054955   -0.097220   \n",
       "per:dates                        0.538054  ...     -0.020943   -0.107310   \n",
       "per:ex-boyfriend                 1.000000  ...     -0.005680   -0.064143   \n",
       "per:boyfriend                    0.777210  ...     -0.054955   -0.097220   \n",
       "per:friends                      0.064143  ...     -0.067863   -0.037405   \n",
       "per:nickname                    -0.012714  ...     -0.035721   -0.079675   \n",
       "per:neighbor                     0.082387  ...     -0.102951   -0.104395   \n",
       "per:nurse                        0.143795  ...      0.218647    0.005574   \n",
       "per:parents-in-law              -0.057957  ...      0.312749    0.513330   \n",
       "per:children-in-law             -0.057957  ...      0.312749    0.513330   \n",
       "per:positive impression          0.027288  ...      0.103577    0.020420   \n",
       "per:classmate                    0.076589  ...      0.024501   -0.049098   \n",
       "per:negative impression          0.162457  ...     -0.009254    0.085026   \n",
       "per:subordinate                  0.178520  ...      0.283327   -0.003014   \n",
       "per:boss                         0.178520  ...      0.283327   -0.003014   \n",
       "per:siblings                    -0.005680  ...      1.000000    0.338194   \n",
       "per:spouse                      -0.064143  ...      0.338194    1.000000   \n",
       "per:grandparents                -0.031815  ...      0.222272    0.360604   \n",
       "per:grandchildren               -0.031815  ...      0.222272    0.360604   \n",
       "per:teacher                      0.134502  ...      0.140733   -0.013587   \n",
       "per:student                      0.134502  ...      0.140733   -0.013587   \n",
       "per:roommate                    -0.008981  ...      0.082395    0.036940   \n",
       "per:relative                     0.045175  ...      0.757022    0.163382   \n",
       "per:siblings-in-law             -0.023910  ...     -0.026243    0.062894   \n",
       "unanswerable                     0.112771  ...      0.089702    0.106675   \n",
       "\n",
       "                         per:grandparents  per:grandchildren  per:teacher  \\\n",
       "per:alternate_name               0.092696           0.092696     0.048484   \n",
       "per:children                     0.402224           0.402224    -0.020470   \n",
       "per:parents                      0.402224           0.402224    -0.020470   \n",
       "per:acquaintance                 0.092402           0.092402     0.069985   \n",
       "per:client                      -0.056349          -0.056349    -0.031576   \n",
       "per:colleague                   -0.025115          -0.025115    -0.055904   \n",
       "per:ex-girlfriend               -0.031815          -0.031815     0.134502   \n",
       "per:girlfriend                  -0.069105          -0.069105     0.041021   \n",
       "per:dates                       -0.059057          -0.059057     0.027903   \n",
       "per:ex-boyfriend                -0.031815          -0.031815     0.134502   \n",
       "per:boyfriend                   -0.069105          -0.069105     0.041021   \n",
       "per:friends                      0.027079           0.027079    -0.080418   \n",
       "per:nickname                    -0.054129          -0.054129    -0.008904   \n",
       "per:neighbor                    -0.119707          -0.119707    -0.058595   \n",
       "per:nurse                        0.158635           0.158635    -0.021665   \n",
       "per:parents-in-law               0.571698           0.571698     0.021717   \n",
       "per:children-in-law              0.571698           0.571698     0.021717   \n",
       "per:positive impression          0.002195           0.002195     0.427219   \n",
       "per:classmate                    0.022952           0.022952     0.205363   \n",
       "per:negative impression          0.078519           0.078519     0.113776   \n",
       "per:subordinate                  0.125390           0.125390    -0.009589   \n",
       "per:boss                         0.125390           0.125390    -0.009589   \n",
       "per:siblings                     0.222272           0.222272     0.140733   \n",
       "per:spouse                       0.360604           0.360604    -0.013587   \n",
       "per:grandparents                 1.000000           1.000000    -0.022282   \n",
       "per:grandchildren                1.000000           1.000000    -0.022282   \n",
       "per:teacher                     -0.022282          -0.022282     1.000000   \n",
       "per:student                     -0.022282          -0.022282     1.000000   \n",
       "per:roommate                     0.054374           0.054374    -0.006290   \n",
       "per:relative                     0.170528           0.170528     0.064084   \n",
       "per:siblings-in-law              0.003873           0.003873    -0.016745   \n",
       "unanswerable                     0.147863           0.147863     0.078979   \n",
       "\n",
       "                         per:student  per:roommate  per:relative  \\\n",
       "per:alternate_name          0.048484      0.016026      0.095654   \n",
       "per:children               -0.020470      0.027564      0.271393   \n",
       "per:parents                -0.020470      0.027564      0.271393   \n",
       "per:acquaintance            0.069985     -0.019263     -0.043313   \n",
       "per:client                 -0.031576     -0.010438     -0.102300   \n",
       "per:colleague              -0.055904     -0.018479     -0.099105   \n",
       "per:ex-girlfriend           0.134502     -0.008981      0.045175   \n",
       "per:girlfriend              0.041021     -0.010207      0.005557   \n",
       "per:dates                   0.027903     -0.011747      0.053030   \n",
       "per:ex-boyfriend            0.134502     -0.008981      0.045175   \n",
       "per:boyfriend               0.041021     -0.010207      0.005557   \n",
       "per:friends                -0.080418      0.056280     -0.010731   \n",
       "per:nickname               -0.008904     -0.002943     -0.045928   \n",
       "per:neighbor               -0.058595      0.068497     -0.045159   \n",
       "per:nurse                  -0.021665     -0.020645      0.297366   \n",
       "per:parents-in-law          0.021717      0.038072      0.308420   \n",
       "per:children-in-law         0.021717      0.038072      0.308420   \n",
       "per:positive impression     0.427219     -0.012954      0.165405   \n",
       "per:classmate               0.205363      0.168187     -0.001588   \n",
       "per:negative impression     0.113776     -0.014632      0.133987   \n",
       "per:subordinate            -0.009589     -0.018002      0.387729   \n",
       "per:boss                   -0.009589     -0.018002      0.387729   \n",
       "per:siblings                0.140733      0.082395      0.757022   \n",
       "per:spouse                 -0.013587      0.036940      0.163382   \n",
       "per:grandparents           -0.022282      0.054374      0.170528   \n",
       "per:grandchildren          -0.022282      0.054374      0.170528   \n",
       "per:teacher                 1.000000     -0.006290      0.064084   \n",
       "per:student                 1.000000     -0.006290      0.064084   \n",
       "per:roommate               -0.006290      1.000000      0.064083   \n",
       "per:relative                0.064084      0.064083      1.000000   \n",
       "per:siblings-in-law        -0.016745     -0.005535      0.133903   \n",
       "unanswerable                0.078979      0.026106      0.122185   \n",
       "\n",
       "                         per:siblings-in-law  unanswerable  \n",
       "per:alternate_name                  0.042669      0.090971  \n",
       "per:children                        0.034214      0.099455  \n",
       "per:parents                         0.034214      0.099455  \n",
       "per:acquaintance                   -0.051286      0.027149  \n",
       "per:client                         -0.027789      0.131067  \n",
       "per:colleague                       0.249716      0.149115  \n",
       "per:ex-girlfriend                  -0.023910      0.112771  \n",
       "per:girlfriend                     -0.027174      0.128167  \n",
       "per:dates                          -0.031275      0.087760  \n",
       "per:ex-boyfriend                   -0.023910      0.112771  \n",
       "per:boyfriend                      -0.027174      0.128167  \n",
       "per:friends                         0.114386      0.149084  \n",
       "per:nickname                       -0.007836      0.036959  \n",
       "per:neighbor                        0.144770      0.151657  \n",
       "per:nurse                          -0.054964      0.233627  \n",
       "per:parents-in-law                  0.066112      0.118493  \n",
       "per:children-in-law                 0.066112      0.118493  \n",
       "per:positive impression            -0.034489      0.126064  \n",
       "per:classmate                      -0.032911      0.079014  \n",
       "per:negative impression            -0.038955      0.150657  \n",
       "per:subordinate                    -0.047928      0.197880  \n",
       "per:boss                           -0.047928      0.197880  \n",
       "per:siblings                       -0.026243      0.089702  \n",
       "per:spouse                          0.062894      0.106675  \n",
       "per:grandparents                    0.003873      0.147863  \n",
       "per:grandchildren                   0.003873      0.147863  \n",
       "per:teacher                        -0.016745      0.078979  \n",
       "per:student                        -0.016745      0.078979  \n",
       "per:roommate                       -0.005535      0.026106  \n",
       "per:relative                        0.133903      0.122185  \n",
       "per:siblings-in-law                 1.000000      0.069506  \n",
       "unanswerable                        0.069506      1.000000  \n",
       "\n",
       "[32 rows x 32 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ab273c8f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('per:acquaintance', -0.08208033022655042),\n",
       " ('per:alternate_name', 0.04169164806752479),\n",
       " ('per:boss', 1.0),\n",
       " ('per:boyfriend', 0.168066785272256),\n",
       " ('per:children', 0.0328757046813823),\n",
       " ('per:children-in-law', 0.132118874953544),\n",
       " ('per:classmate', 0.03727483722089884),\n",
       " ('per:client', -0.034528935855916675),\n",
       " ('per:colleague', -0.10766179874679062),\n",
       " ('per:dates', 0.09941876083041462),\n",
       " ('per:ex-boyfriend', 0.17851966356077914),\n",
       " ('per:ex-girlfriend', 0.17851966356077914),\n",
       " ('per:friends', -0.09633133550269961),\n",
       " ('per:girlfriend', 0.168066785272256),\n",
       " ('per:grandchildren', 0.1253900217410204),\n",
       " ('per:grandparents', 0.1253900217410204),\n",
       " ('per:negative impression', 0.10295738431118671),\n",
       " ('per:neighbor', -0.025789516339307476),\n",
       " ('per:nickname', -0.0254849056436838),\n",
       " ('per:nurse', 0.7588329056007194),\n",
       " ('per:parents', 0.0328757046813823),\n",
       " ('per:parents-in-law', 0.132118874953544),\n",
       " ('per:positive impression', -0.019749396565728463),\n",
       " ('per:relative', 0.38772870409144783),\n",
       " ('per:roommate', -0.018001807472209863),\n",
       " ('per:siblings', 0.2833269416709497),\n",
       " ('per:siblings-in-law', -0.04792817209821917),\n",
       " ('per:spouse', -0.003014379848573352),\n",
       " ('per:student', -0.009588721254496252),\n",
       " ('per:subordinate', 1.0),\n",
       " ('per:teacher', -0.009588721254496252),\n",
       " ('unanswerable', 0.19787973257977945)]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort(corr_matrix['per:boss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedb7493",
   "metadata": {},
   "source": [
    "Here's a show-specific variable: dialogue-size. I wonder if the rarer relation labels aren't more common only in larger group settings than smaller?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "61d5d828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_num_speakers(train_df[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0df86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy code from prev work. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37f3647",
   "metadata": {},
   "source": [
    "Main deliberation: these sets of y-variables are co-dependent. Some are very likely to occur together, but it seems harder to model a scenario where a model predicts 5 out of 10 relations, than individually asking: is this relation present or not? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd65e374",
   "metadata": {},
   "source": [
    "I'm going to start with the latter problem because I know how to set it up, and then I'm going to research and brainstorm how to set up the first problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724af12f",
   "metadata": {},
   "source": [
    "Short term goal: set up a model that can make predictions based on basic features, and be able to run the evaluation script on it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c2c13e",
   "metadata": {},
   "source": [
    "**Step 1**: make a gt data frame with present relations for each dialogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "714fc39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_data = np.zeros(shape=(len(train_df),len(rid_to_rel))) #change length\n",
    "train_gt = pd.DataFrame(zero_data, columns=rid_to_rel.values())\n",
    "\n",
    "for i in range(0,len(train_df)):\n",
    "    for rel_item in train_df[i][1]:\n",
    "        for j in rel_item['rid']:\n",
    "            train_gt.iat[i,j] = 1\n",
    "\n",
    "zero_data = np.zeros(shape=(len(dev_df),len(rid_to_rel)))\n",
    "dev_gt = pd.DataFrame(zero_data, columns=rid_to_rel.values())\n",
    "\n",
    "for i in range(0,len(dev_df)):\n",
    "    for rel_item in dev_df[i][1]:\n",
    "        for j in rel_item['rid']:\n",
    "            dev_gt.iat[i,j] = 1\n",
    "\n",
    "zero_data = np.zeros(shape=(len(test_df),len(rid_to_rel)))\n",
    "test_gt = pd.DataFrame(zero_data, columns=rid_to_rel.values())\n",
    "\n",
    "for i in range(0,len(test_df)):\n",
    "    for rel_item in test_df[i][1]:\n",
    "        for j in rel_item['rid']:\n",
    "            test_gt.iat[i,j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8dabaa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_array = []\n",
    "for i in range(0,len(train_df)):\n",
    "    \n",
    "    temp = \"\"\n",
    "    for row in train_df[i][0]:\n",
    "        temp += row + '\\n'\n",
    "    train_array.append(temp)\n",
    "\n",
    "dev_array = []\n",
    "for i in range(0,len(dev_df)):\n",
    "    \n",
    "    temp = \"\"\n",
    "    for row in dev_df[i][0]:\n",
    "        temp += row + '\\n'\n",
    "    dev_array.append(temp)\n",
    "    \n",
    "test_array = []\n",
    "for i in range(0,len(test_df)):\n",
    "    \n",
    "    temp = \"\"\n",
    "    for row in test_df[i][0]:\n",
    "        temp += row + '\\n'\n",
    "    test_array.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e9b12f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.459 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(tokenizer=ch_tokenizer,ngram_range=(1,3),min_df=2,max_df=0.55)\n",
    "#train_array,\n",
    "count_vector=cv.fit_transform(train_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb892b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b10011",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a33b052a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = count_vector.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8084efd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename for consistency\n",
    "y_train = train_gt\n",
    "y_test = test_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "09fc0ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f49e6fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature matrix\n",
    "\n",
    "#split data if needed\n",
    "y = train_gt\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aafbaaf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['per:alternate_name', 'per:children', 'per:parents', 'per:acquaintance',\n",
       "       'per:client', 'per:colleague', 'per:ex-girlfriend', 'per:girlfriend',\n",
       "       'per:dates', 'per:ex-boyfriend', 'per:boyfriend', 'per:friends',\n",
       "       'per:nickname', 'per:neighbor', 'per:nurse', 'per:parents-in-law',\n",
       "       'per:children-in-law', 'per:positive impression', 'per:classmate',\n",
       "       'per:negative impression', 'per:subordinate', 'per:boss',\n",
       "       'per:siblings', 'per:spouse', 'per:grandparents', 'per:grandchildren',\n",
       "       'per:teacher', 'per:student', 'per:roommate', 'per:relative',\n",
       "       'per:siblings-in-law', 'unanswerable'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b45b69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()\n",
    "y_pred = mnb.fit(X_train, y_train['per:roommate']).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de67e9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 71 points : 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({0.0: 71})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of mislabeled points out of a total %d points : %d\"% (X_test.shape[0], (y_test['per:roommate'] != y_pred).sum()))\n",
    "Counter(y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7535efe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#fit\n",
    "SVM = SVC(kernel = 'linear')\n",
    "SVM.fit(X_train,y_train['per:roommate'])\n",
    "y_pred=SVM.predict(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "314273ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 116 points : 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({0.0: 116})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of mislabeled points out of a total %d points : %d\"% (X_dev.shape[0], (dev_gt['per:roommate'] != y_pred).sum()))\n",
    "Counter(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e282ba6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/elyeb/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[71]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate\n",
    "print(accuracy_score(y_test['per:roommate'],y_pred))\n",
    "print(f1_score(y_test['per:roommate'],y_pred))\n",
    "confusion_matrix(y_test['per:roommate'], y_pred) #even more the case than the Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dfebf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "neg_class_prob_sorted = clf.feature_log_prob_[0, :].argsort()[::-1]\n",
    "pos_class_prob_sorted = clf.feature_log_prob_[1, :].argsort()[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2711e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\"\"\"\n",
    "clf.classes_  gives array(['tu', 'vous'], dtype='<U4')\n",
    "so the second one, 1, is vous, and that's what's getting shown in the \n",
    "pos_class\n",
    "\"\"\"\n",
    "print(clf.classes_)\n",
    "print(np.take(count.get_feature_names(), neg_class_prob_sorted[:10]))\n",
    "print(np.take(count.get_feature_names(), pos_class_prob_sorted[:10])) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202b648f",
   "metadata": {},
   "source": [
    "Jul 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "689b34e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'children_parents': 115,\n",
       "         'parents_children': 117,\n",
       "         'relative_relative': 36,\n",
       "         'siblings_siblings': 10,\n",
       "         'spouse_spouse': 454,\n",
       "         'grandparents_grandchildren': 77,\n",
       "         'grandchildren_grandparents': 73,\n",
       "         'parents-in-law_children-in-law': 229,\n",
       "         'children-in-law_parents-in-law': 235})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make ground truth of 9 labels \n",
    "y = []\n",
    "X = []\n",
    "for scene in partition1:\n",
    "    for line in scene:\n",
    "        y.append(line['rel_pair'])\n",
    "        #remove non-characters\n",
    "        no_punct = [word for word in line['tokenized'] if bool(re.search(r'[\\u4e00-\\u9fff]',word))] \n",
    "        X.append(no_punct)\n",
    "Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69d0653f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b0d8567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'children_parents': 27,\n",
       "         'spouse_spouse': 86,\n",
       "         'parents_children': 25,\n",
       "         'parents-in-law_children-in-law': 49,\n",
       "         'children-in-law_parents-in-law': 39,\n",
       "         'siblings_siblings': 2,\n",
       "         'grandparents_grandchildren': 20,\n",
       "         'grandchildren_grandparents': 15,\n",
       "         'relative_relative': 7})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50dd1a71",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dummy_tokenize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1549244/3636415336.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdummy_tokenize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlowercase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#,ngram_range=(1,3),min_df=2,max_df=0.55\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcount_vector\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_vector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dummy_tokenize' is not defined"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(tokenizer=dummy_tokenize,lowercase=False) #,ngram_range=(1,3),min_df=2,max_df=0.55\n",
    "\n",
    "count_vector=cv.fit_transform(X_train)\n",
    "\n",
    "X_train = count_vector.toarray()\n",
    "\n",
    "X_test = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2363899c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/elyeb/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "SVM_feature_names = cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "016daed9",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BP',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2aabb1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit\n",
    "SVM = SVC(kernel = 'linear')\n",
    "SVM.fit(count_vector,y_train)\n",
    "y_pred=SVM.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "94a3b0e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1076, 3602)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2548bf1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270, 3602)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f08e42dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 3602)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM.coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0c02d9d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<36x3602 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 23685 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37265929",
   "metadata": {},
   "source": [
    "Question: why does this have 36 rows?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1239bbc",
   "metadata": {},
   "source": [
    "Note from stackoverflow: \"If you do multi-class classification scikit-learn employs a one-vs-one scheme. This means you get one separate classifier (or one set of weights) for each combination of classes. If C is the number of classes there is a total of C * (C-1) / 2 combinations.\" <br/> <br/> This checks out for my data (9*8/2 = 36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f62af27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['children-in-law_parents-in-law', 'children_parents',\n",
       "       'grandchildren_grandparents', 'grandparents_grandchildren',\n",
       "       'parents-in-law_children-in-law', 'parents_children',\n",
       "       'relative_relative', 'siblings_siblings', 'spouse_spouse'],\n",
       "      dtype='<U30')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b63be2",
   "metadata": {},
   "source": [
    "From the [documentation](https://scikit-learn.org/stable/modules/svm.html#multi-class-classification), \"The order for classes 0 to n is 0 vs 1, 0 vs 2 ,  0 vs n, 1 vs 2, 1 vs 3, 1 vs n, . . . n-1 vs n.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcbb7ae",
   "metadata": {},
   "source": [
    "So, using the order of the SVM.classes_ I see the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab007e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : children-in-law_parents-in-law vs children_parents\n",
      "1 : children-in-law_parents-in-law vs grandchildren_grandparents\n",
      "2 : children-in-law_parents-in-law vs grandparents_grandchildren\n",
      "3 : children-in-law_parents-in-law vs parents-in-law_children-in-law\n",
      "4 : children-in-law_parents-in-law vs parents_children\n",
      "5 : children-in-law_parents-in-law vs relative_relative\n",
      "6 : children-in-law_parents-in-law vs siblings_siblings\n",
      "7 : children-in-law_parents-in-law vs spouse_spouse\n",
      "8 : children_parents vs grandchildren_grandparents\n",
      "9 : children_parents vs grandparents_grandchildren\n",
      "10 : children_parents vs parents-in-law_children-in-law\n",
      "11 : children_parents vs parents_children\n",
      "12 : children_parents vs relative_relative\n",
      "13 : children_parents vs siblings_siblings\n",
      "14 : children_parents vs spouse_spouse\n",
      "15 : grandchildren_grandparents vs grandparents_grandchildren\n",
      "16 : grandchildren_grandparents vs parents-in-law_children-in-law\n",
      "17 : grandchildren_grandparents vs parents_children\n",
      "18 : grandchildren_grandparents vs relative_relative\n",
      "19 : grandchildren_grandparents vs siblings_siblings\n",
      "20 : grandchildren_grandparents vs spouse_spouse\n",
      "21 : grandparents_grandchildren vs parents-in-law_children-in-law\n",
      "22 : grandparents_grandchildren vs parents_children\n",
      "23 : grandparents_grandchildren vs relative_relative\n",
      "24 : grandparents_grandchildren vs siblings_siblings\n",
      "25 : grandparents_grandchildren vs spouse_spouse\n",
      "26 : parents-in-law_children-in-law vs parents_children\n",
      "27 : parents-in-law_children-in-law vs relative_relative\n",
      "28 : parents-in-law_children-in-law vs siblings_siblings\n",
      "29 : parents-in-law_children-in-law vs spouse_spouse\n",
      "30 : parents_children vs relative_relative\n",
      "31 : parents_children vs siblings_siblings\n",
      "32 : parents_children vs spouse_spouse\n",
      "33 : relative_relative vs siblings_siblings\n",
      "34 : relative_relative vs spouse_spouse\n",
      "35 : siblings_siblings vs spouse_spouse\n"
     ]
    }
   ],
   "source": [
    "row = 0\n",
    "row_names = []\n",
    "for i in range(0,len(SVM.classes_)-1):\n",
    "    for j in range(i+1,len(SVM.classes_)):\n",
    "        print(f'{row} : {SVM.classes_[i]} vs {SVM.classes_[j]}')\n",
    "        row_names.append(SVM.classes_[i]+' vs '+SVM.classes_[j])\n",
    "        row +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8efb52a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df = pd.DataFrame(SVM.coef_.todense(),columns=SVM_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b51e2180",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "i = 0\n",
    "label = row_names[i]\n",
    "\n",
    "full_array = coef_df.iloc[i,]\n",
    "top_n = sorted(sorted(list(zip(SVM_feature_names,full_array)), key=lambda x: x[1],reverse=True)[0:n],key=lambda x: x[1])\n",
    "bottom_n = sorted(list(zip(SVM_feature_names,full_array)), key=lambda x: x[1])[0:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "adac356c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 0.6416969087372876),\n",
       " ('', 0.6439453681938341),\n",
       " ('', 0.6580559036552821),\n",
       " ('', 0.6841286418464124),\n",
       " ('', 0.6841328650392957),\n",
       " ('', 0.6841543905866336),\n",
       " ('', 0.6841555540870627),\n",
       " ('', 0.6841669115966372),\n",
       " ('', 0.6842125827741787),\n",
       " ('', 0.9656798881660905)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e7589ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', -0.840915333509046),\n",
       " ('', -0.8448081948939732),\n",
       " ('', -0.9092278315671167),\n",
       " ('', -0.9210273215716112),\n",
       " ('', -0.9726740848232749),\n",
       " ('', -0.984200251195382),\n",
       " ('', -1.0),\n",
       " ('', -1.0),\n",
       " ('', -1.1991786048555315),\n",
       " ('', -1.315835586886018)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottom_n #this is clearly the second class. So bottom_n is stronger to second class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2d06466d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text(0.5, 1.0, 'tata')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "\n",
    "plt.barh([item[0] for item in bottom_n],[item[1] for item in bottom_n])\n",
    "plt.barh([item[0] for item in top_n],[item[1] for item in top_n])\n",
    "print(plt.title(\"tata\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d55c2ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_features(n,i,coef_df,feature_names,label):\n",
    "    \n",
    "    plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "\n",
    "    full_array = coef_df.iloc[i,]\n",
    "    top_n = sorted(sorted(list(zip(feature_names,full_array)), key=lambda x: x[1],reverse=True)[0:n],key=lambda x: x[1])\n",
    "    bottom_n = sorted(list(zip(feature_names,full_array)), key=lambda x: x[1])[0:n] \n",
    "\n",
    "    plt.barh([item[0] for item in bottom_n],[item[1] for item in bottom_n])\n",
    "    plt.barh([item[0] for item in top_n],[item[1] for item in top_n])\n",
    "    print(plt.title(label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "357d8bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text(0.5, 1.0, 'children-in-law_parents-in-law vs children_parents')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_top_features(10,0,coef_df,SVM_feature_names,row_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "308cbf05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text(0.5, 1.0, 'children-in-law_parents-in-law vs grandchildren_grandparents')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_top_features(10,1,coef_df,SVM_feature_names,row_names[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "20cfc8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text(0.5, 1.0, 'children-in-law_parents-in-law vs grandparents_grandchildren')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_top_features(10,2,coef_df,SVM_feature_names,row_names[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "5fe334cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a dictionary of above results\n",
    "\n",
    "top_10s = dict()\n",
    "cross_cutting = dict()\n",
    "\n",
    "for i in range(0,len(row_names)):\n",
    "    \n",
    "    label = row_names[i]\n",
    "\n",
    "    full_array = coef_df.iloc[i,]\n",
    "    top_n = sorted(list(zip(SVM_feature_names,full_array)), key=lambda x: x[1],reverse=True)[0:n]\n",
    "    bottom_n = sorted(list(zip(SVM_feature_names,full_array)), key=lambda x: x[1])[0:n]\n",
    "    \n",
    "    x = label.split(' vs ')[0]\n",
    "    y = label.split(' vs ')[0]\n",
    "    \n",
    "    top_10s[label] = dict()\n",
    "    top_10s[label]['top_n'] = top_n\n",
    "    top_10s[label]['bottom_n'] = bottom_n\n",
    "    \n",
    "    if x not in cross_cutting:\n",
    "        cross_cutting[x] = []\n",
    "    cross_cutting[x].append([item[0] for item in top_n])\n",
    "    \n",
    "    if y not in cross_cutting:\n",
    "        cross_cutting[y] = []\n",
    "    cross_cutting[y].append([item[0] for item in bottom_n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e4c4d890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['', '', '', '', '', '', '', '', '', ''],\n",
       " ['', '', '', '', '', '', '', '', '', ''],\n",
       " ['', '', '', '', '', '', '', '', '', ''],\n",
       " ['', '', '', '', '', '', '', '', '', ''],\n",
       " ['', '', '', '', '', '', '', '', '', ''],\n",
       " ['', '', '', '', '', '', '', '', '', ''],\n",
       " ['', '', '', '', '', '', '', '', '', ''],\n",
       " ['', '', '', '', '', '', '', '', '', ''],\n",
       " ['', '', '', '', '', '', '', '', '', ''],\n",
       " ['', '', '', '', '', '', '', '', '', ''],\n",
       " ['', '', '', '', '', '', '', '', '', ''],\n",
       " ['', '', '', '', '', '', '', '', '', ''],\n",
       " ['', '', '', '', '', '', '', '', '', ''],\n",
       " ['', '', '', '', '', '', '', '', '', ''],\n",
       " ['', '', '', '', '', '', '', '', '', ''],\n",
       " ['', '', '', '', '', '', '', '', '', '']]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_cutting['children-in-law_parents-in-law']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e8ba16a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['children-in-law_parents-in-law', 'grandparents_grandchildren']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = 'children-in-law_parents-in-law vs grandparents_grandchildren'\n",
    "test.split(' vs ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "de4a2e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 3602)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM.coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83ead70a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'children-in-law_parents-in-law': 30,\n",
       "         'parents_children': 14,\n",
       "         'parents-in-law_children-in-law': 72,\n",
       "         'spouse_spouse': 100,\n",
       "         'relative_relative': 5,\n",
       "         'children_parents': 24,\n",
       "         'grandchildren_grandparents': 11,\n",
       "         'grandparents_grandchildren': 14})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55555d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'children_parents': 27,\n",
       "         'spouse_spouse': 86,\n",
       "         'parents_children': 25,\n",
       "         'parents-in-law_children-in-law': 49,\n",
       "         'children-in-law_parents-in-law': 39,\n",
       "         'siblings_siblings': 2,\n",
       "         'grandparents_grandchildren': 20,\n",
       "         'grandchildren_grandparents': 15,\n",
       "         'relative_relative': 7})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12e38814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 270 points : 171\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of mislabeled points out of a total %d points : %d\"% (X_test.shape[0], (y_test != y_pred).sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2bef8dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34814814814814815\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[17,  5,  2,  2,  7,  0,  0,  0,  6],\n",
       "       [ 4,  6,  2,  1,  4,  1,  1,  1,  7],\n",
       "       [ 3,  3,  4,  1,  3,  0,  0,  0,  1],\n",
       "       [ 4,  1,  2,  2,  5,  3,  0,  0,  3],\n",
       "       [ 3,  1,  2,  4, 21,  3,  0,  0, 15],\n",
       "       [ 1,  1,  1,  2,  9,  1,  0,  0, 10],\n",
       "       [ 0,  1,  0,  0,  3,  0,  1,  0,  2],\n",
       "       [ 1,  0,  0,  0,  0,  0,  0,  0,  1],\n",
       "       [ 7,  5,  4,  7, 16,  4,  1,  0, 42]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "#print(f1_score(y_test,y_pred))\n",
    "confusion_matrix(y_test, y_pred) #even more the case than the Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "47181bed",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy = 0.36666666666666664\n",
      "children-in-law_parents-in-law: 39 total\n",
      "   F1=0.4057971014492754\n",
      "   Precision=0.4666666666666667\n",
      "   Recall=0.358974358974359\n",
      "children_parents: 27 total\n",
      "   F1=0.3137254901960784\n",
      "   Precision=0.3333333333333333\n",
      "   Recall=0.2962962962962963\n",
      "grandchildren_grandparents: 15 total\n",
      "   F1=0.46153846153846156\n",
      "   Precision=0.5454545454545454\n",
      "   Recall=0.4\n",
      "grandparents_grandchildren: 20 total\n",
      "   F1=0.11764705882352941\n",
      "   Precision=0.14285714285714285\n",
      "   Recall=0.1\n",
      "parents-in-law_children-in-law: 49 total\n",
      "   F1=0.38016528925619836\n",
      "   Precision=0.3194444444444444\n",
      "   Recall=0.46938775510204084\n",
      "parents_children: 25 total\n",
      "   F1=0.05128205128205128\n",
      "   Precision=0.07142857142857142\n",
      "   Recall=0.04\n",
      "relative_relative: 7 total\n",
      "   F1=0.0\n",
      "   Precision=0.0\n",
      "   Recall=0.0\n",
      "siblings_siblings: 2 total\n",
      "   F1=0\n",
      "   Precision=0\n",
      "   Recall=0\n",
      "spouse_spouse: 86 total\n",
      "   F1=0.4838709677419355\n",
      "   Precision=0.45\n",
      "   Recall=0.5232558139534884\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>children-in-law_parents-in-law</th>\n",
       "      <th>children_parents</th>\n",
       "      <th>grandchildren_grandparents</th>\n",
       "      <th>grandparents_grandchildren</th>\n",
       "      <th>parents-in-law_children-in-law</th>\n",
       "      <th>parents_children</th>\n",
       "      <th>relative_relative</th>\n",
       "      <th>siblings_siblings</th>\n",
       "      <th>spouse_spouse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>children-in-law_parents-in-law</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>children_parents</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>grandchildren_grandparents</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>grandparents_grandchildren</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>parents-in-law_children-in-law</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>parents_children</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>relative_relative</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>siblings_siblings</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spouse_spouse</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             pred  children-in-law_parents-in-law  \\\n",
       "0  children-in-law_parents-in-law                            14.0   \n",
       "1                children_parents                             5.0   \n",
       "2      grandchildren_grandparents                             2.0   \n",
       "3      grandparents_grandchildren                             2.0   \n",
       "4  parents-in-law_children-in-law                             5.0   \n",
       "5                parents_children                             1.0   \n",
       "6               relative_relative                             2.0   \n",
       "7               siblings_siblings                             0.0   \n",
       "8                   spouse_spouse                             8.0   \n",
       "\n",
       "   children_parents  grandchildren_grandparents  grandparents_grandchildren  \\\n",
       "0               2.0                         3.0                         2.0   \n",
       "1               8.0                         2.0                         1.0   \n",
       "2               1.0                         6.0                         1.0   \n",
       "3               0.0                         0.0                         2.0   \n",
       "4               3.0                         2.0                         6.0   \n",
       "5               3.0                         0.0                         1.0   \n",
       "6               1.0                         0.0                         0.0   \n",
       "7               0.0                         0.0                         0.0   \n",
       "8               9.0                         2.0                         7.0   \n",
       "\n",
       "   parents-in-law_children-in-law  parents_children  relative_relative  \\\n",
       "0                             2.0               1.0                1.0   \n",
       "1                             1.0               2.0                1.0   \n",
       "2                             0.0               0.0                0.0   \n",
       "3                             4.0               2.0                0.0   \n",
       "4                            23.0              11.0                2.0   \n",
       "5                             2.0               1.0                0.0   \n",
       "6                             0.0               1.0                0.0   \n",
       "7                             0.0               0.0                0.0   \n",
       "8                            17.0               7.0                3.0   \n",
       "\n",
       "   siblings_siblings  spouse_spouse  \n",
       "0                0.0            5.0  \n",
       "1                0.0            4.0  \n",
       "2                0.0            1.0  \n",
       "3                0.0            4.0  \n",
       "4                0.0           20.0  \n",
       "5                0.0            6.0  \n",
       "6                0.0            1.0  \n",
       "7                0.0            0.0  \n",
       "8                2.0           45.0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resuls_cm = results(y_test,y_pred)\n",
    "resuls_cm.metric()\n",
    "test_cm = resuls_cm.cm\n",
    "test_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ab2df8",
   "metadata": {},
   "source": [
    "Despite the poor results, there are 3 pairs that it seems to pick up on pretty well (unknown because CM isn't labelled). The others are all scattered. Note: I also didn't do any CV or anything to fine-tune feature-selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7db47c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X, y = diabetes.data, diabetes.target\n",
    "clf=RandomForestClassifier(n_estimators =50) #, random_state = 42, class_weight=\"balanced\"\n",
    "output = cross_validate(clf, X_train, y_train, cv=2, scoring = 'accuracy', return_estimator =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9d82bf25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.18427181, 0.18705082]),\n",
       " 'score_time': array([0.01380229, 0.01344109]),\n",
       " 'estimator': [RandomForestClassifier(n_estimators=50),\n",
       "  RandomForestClassifier(n_estimators=50)],\n",
       " 'test_score': array([0.44981413, 0.45724907])}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2625d546",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their score for estimator 0:\n",
      "      importance\n",
      "1704    0.037014\n",
      "461     0.022532\n",
      "2110    0.015081\n",
      "3290    0.014815\n",
      "2480    0.013002\n",
      "...          ...\n",
      "1590    0.000000\n",
      "1592    0.000000\n",
      "1593    0.000000\n",
      "1595    0.000000\n",
      "3601    0.000000\n",
      "\n",
      "[3602 rows x 1 columns]\n",
      "Features sorted by their score for estimator 1:\n",
      "      importance\n",
      "461     0.027471\n",
      "1704    0.025952\n",
      "1762    0.019465\n",
      "2587    0.010419\n",
      "2480    0.010198\n",
      "...          ...\n",
      "1614    0.000000\n",
      "1615    0.000000\n",
      "1616    0.000000\n",
      "1617    0.000000\n",
      "3601    0.000000\n",
      "\n",
      "[3602 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "for idx,estimator in enumerate(output['estimator']):\n",
    "    print(\"Features sorted by their score for estimator {}:\".format(idx))\n",
    "    feature_importances = pd.DataFrame(estimator.feature_importances_,\n",
    "                                       #index = diabetes.feature_names,\n",
    "                                        columns=['importance']).sort_values('importance', ascending=False)\n",
    "    print(feature_importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa683ed",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "How well can a baseline model do on the actual shared task, using fasttext embeddings instead of CountVectorizer and a SVM linear classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76791afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'x': 'S 1', 'y': 'S 2', 'r': ['per:spouse'], 'rid': [23]},\n",
       " {'x': 'S 1', 'y': 'S 3', 'r': ['per:children-in-law'], 'rid': [16]},\n",
       " {'x': 'S 1', 'y': 'S 4', 'r': ['unanswerable'], 'rid': [31]},\n",
       " {'x': 'S 1', 'y': '', 'r': ['per:spouse'], 'rid': [23]},\n",
       " {'x': 'S 2', 'y': 'S 1', 'r': ['per:spouse'], 'rid': [23]},\n",
       " {'x': 'S 2', 'y': 'S 3', 'r': ['per:children'], 'rid': [1]},\n",
       " {'x': 'S 2', 'y': 'S 4', 'r': ['unanswerable'], 'rid': [31]},\n",
       " {'x': 'S 2', 'y': '', 'r': ['per:alternate_name'], 'rid': [0]},\n",
       " {'x': 'S 3', 'y': 'S 1', 'r': ['per:parents-in-law'], 'rid': [15]},\n",
       " {'x': 'S 3', 'y': 'S 2', 'r': ['per:parents'], 'rid': [2]},\n",
       " {'x': 'S 3', 'y': 'S 4', 'r': ['unanswerable'], 'rid': [31]},\n",
       " {'x': 'S 3', 'y': '', 'r': ['per:parents'], 'rid': [2]},\n",
       " {'x': 'S 4', 'y': 'S 1', 'r': ['unanswerable'], 'rid': [31]},\n",
       " {'x': 'S 4', 'y': 'S 2', 'r': ['unanswerable'], 'rid': [31]},\n",
       " {'x': 'S 4', 'y': 'S 3', 'r': ['unanswerable'], 'rid': [31]},\n",
       " {'x': 'S 4', 'y': '', 'r': ['unanswerable'], 'rid': [31]},\n",
       " {'x': '', 'y': 'S 1', 'r': ['per:spouse'], 'rid': [23]},\n",
       " {'x': '', 'y': 'S 2', 'r': ['per:alternate_name'], 'rid': [0]},\n",
       " {'x': '', 'y': 'S 3', 'r': ['per:children'], 'rid': [1]},\n",
       " {'x': '', 'y': 'S 4', 'r': ['unanswerable'], 'rid': [31]}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533aac88",
   "metadata": {},
   "source": [
    "**Rules for finding the relevant training data for a relation**:\n",
    "- retrieve lines from speaker and from addressee\n",
    "- if y is a character, retrieve lines from speaker and lines with character mentionned\n",
    "- character mentions seem pretty unlikely to co-occur from the actual speaker themselves\n",
    "\n",
    "None of these predictions are independent of each other. If I predict S1 child of S2, then S2 has to be parent of S1. If I predict S1 alternate name X, the X is also child of S2. I think I need to learn joint prediction models somehow. Joint inference? Viterbi algorithm? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0fef1e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('S 1', '    '),\n",
       " ('S 3', '   '),\n",
       " ('S 3', '                       ')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_mentions('',train_df[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ad088eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'x': 'S 1', 'y': 'S 2', 'r': ['per:spouse'], 'rid': [23]},\n",
       " {'x': 'S 1', 'y': 'S 3', 'r': ['per:children-in-law'], 'rid': [16]},\n",
       " {'x': 'S 1', 'y': 'S 4', 'r': ['unanswerable'], 'rid': [31]},\n",
       " {'x': 'S 1', 'y': '', 'r': ['per:spouse'], 'rid': [23]},\n",
       " {'x': 'S 2', 'y': 'S 1', 'r': ['per:spouse'], 'rid': [23]},\n",
       " {'x': 'S 2', 'y': 'S 3', 'r': ['per:children'], 'rid': [1]},\n",
       " {'x': 'S 2', 'y': 'S 4', 'r': ['unanswerable'], 'rid': [31]},\n",
       " {'x': 'S 2', 'y': '', 'r': ['per:alternate_name'], 'rid': [0]},\n",
       " {'x': 'S 3', 'y': 'S 1', 'r': ['per:parents-in-law'], 'rid': [15]},\n",
       " {'x': 'S 3', 'y': 'S 2', 'r': ['per:parents'], 'rid': [2]},\n",
       " {'x': 'S 3', 'y': 'S 4', 'r': ['unanswerable'], 'rid': [31]},\n",
       " {'x': 'S 3', 'y': '', 'r': ['per:parents'], 'rid': [2]},\n",
       " {'x': 'S 4', 'y': 'S 1', 'r': ['unanswerable'], 'rid': [31]},\n",
       " {'x': 'S 4', 'y': 'S 2', 'r': ['unanswerable'], 'rid': [31]},\n",
       " {'x': 'S 4', 'y': 'S 3', 'r': ['unanswerable'], 'rid': [31]},\n",
       " {'x': 'S 4', 'y': '', 'r': ['unanswerable'], 'rid': [31]},\n",
       " {'x': '', 'y': 'S 1', 'r': ['per:spouse'], 'rid': [23]},\n",
       " {'x': '', 'y': 'S 2', 'r': ['per:alternate_name'], 'rid': [0]},\n",
       " {'x': '', 'y': 'S 3', 'r': ['per:children'], 'rid': [1]},\n",
       " {'x': '', 'y': 'S 4', 'r': ['unanswerable'], 'rid': [31]}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "739b3090",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'x': 'S 1', 'y': 'S 2', 'r': ['per:spouse'], 'rid': [23]},\n",
       " {'x': 'S 1', 'y': 'S 3', 'r': ['per:children-in-law'], 'rid': [16]},\n",
       " {'x': 'S 1', 'y': 'S 4', 'r': ['unanswerable'], 'rid': [31]},\n",
       " {'x': 'S 1', 'y': '', 'r': ['per:spouse'], 'rid': [23]},\n",
       " {'x': 'S 2', 'y': 'S 1', 'r': ['per:spouse'], 'rid': [23]},\n",
       " {'x': 'S 2', 'y': 'S 3', 'r': ['per:children'], 'rid': [1]},\n",
       " {'x': 'S 2', 'y': 'S 4', 'r': ['unanswerable'], 'rid': [31]},\n",
       " {'x': 'S 2', 'y': '', 'r': ['per:alternate_name'], 'rid': [0]},\n",
       " {'x': 'S 3', 'y': 'S 1', 'r': ['per:parents-in-law'], 'rid': [15]},\n",
       " {'x': 'S 3', 'y': 'S 2', 'r': ['per:parents'], 'rid': [2]},\n",
       " {'x': 'S 3', 'y': 'S 4', 'r': ['unanswerable'], 'rid': [31]},\n",
       " {'x': 'S 3', 'y': '', 'r': ['per:parents'], 'rid': [2]},\n",
       " {'x': 'S 4', 'y': 'S 1', 'r': ['unanswerable'], 'rid': [31]},\n",
       " {'x': 'S 4', 'y': 'S 2', 'r': ['unanswerable'], 'rid': [31]},\n",
       " {'x': 'S 4', 'y': 'S 3', 'r': ['unanswerable'], 'rid': [31]},\n",
       " {'x': 'S 4', 'y': '', 'r': ['unanswerable'], 'rid': [31]},\n",
       " {'x': '', 'y': 'S 1', 'r': ['per:spouse'], 'rid': [23]},\n",
       " {'x': '', 'y': 'S 2', 'r': ['per:alternate_name'], 'rid': [0]},\n",
       " {'x': '', 'y': 'S 3', 'r': ['per:children'], 'rid': [1]},\n",
       " {'x': '', 'y': 'S 4', 'r': ['unanswerable'], 'rid': [31]}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb97a84",
   "metadata": {},
   "source": [
    "Actually first start with my own partition because it's set up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecbdde6",
   "metadata": {},
   "source": [
    "Training links: <br/>\n",
    "[train_supervised parameters](https://fasttext.cc/docs/en/python-module.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c73b7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method get_sentence_vector in module fasttext.FastText:\n",
      "\n",
      "get_sentence_vector(text) method of fasttext.FastText._FastText instance\n",
      "    Given a string, get a single vector represenation. This function\n",
      "    assumes to be given a single line of text. We split words on\n",
      "    whitespace (space, newline, tab, vertical tab) and the control\n",
      "    characters carriage return, formfeed and the null character.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ft.get_sentence_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5600d31d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.97993517e-02, -5.67923635e-02,  1.63474202e-01,  9.01721939e-02,\n",
       "        3.19148824e-02,  7.40451887e-02, -5.59923016e-02, -4.94981855e-02,\n",
       "       -1.14988983e-02,  6.69984613e-03,  2.19345912e-02, -6.52322918e-03,\n",
       "        3.92103456e-02,  7.74987042e-04, -2.25003064e-02,  9.03124660e-02,\n",
       "        7.26490766e-02, -3.12981196e-02,  3.88168097e-02, -9.45579261e-03,\n",
       "        2.03982349e-02, -3.16782780e-02, -2.34110635e-02, -1.85007099e-02,\n",
       "        6.67112917e-02,  1.58710703e-02,  1.52449589e-02, -2.24385653e-02,\n",
       "        2.27755457e-02,  5.18159233e-02,  1.70826949e-02, -2.06123665e-03,\n",
       "       -6.62850402e-03,  5.72325662e-05, -6.87277736e-03,  4.49230373e-02,\n",
       "       -4.27571833e-02, -4.46582735e-02, -2.49844007e-02, -3.69873829e-03,\n",
       "        3.34399231e-02,  1.82844233e-02,  2.11279728e-02,  1.83091988e-03,\n",
       "       -3.46763339e-03,  3.51379253e-02, -4.53777611e-02,  1.53266434e-02,\n",
       "       -7.81879760e-04, -5.64751774e-02, -3.09978500e-02,  3.27530541e-02,\n",
       "       -4.27101851e-02,  2.81461142e-03, -1.15074785e-02, -5.65747637e-03,\n",
       "        5.52908257e-02,  2.64605172e-02,  8.86957347e-03, -4.23556492e-02,\n",
       "        3.65803987e-02,  3.32034640e-02, -6.17960542e-02, -3.25720534e-02,\n",
       "       -6.37999848e-02,  2.07409821e-02, -6.92741275e-02,  4.34383824e-02,\n",
       "        1.96292493e-02, -4.05191816e-03, -4.94675860e-02, -1.26838043e-01,\n",
       "        8.65893625e-03,  1.25623029e-02,  1.62634775e-02,  2.85922699e-02,\n",
       "        1.04429059e-01,  3.64055000e-02,  7.58962706e-04,  3.74450162e-02,\n",
       "       -9.13899392e-03, -2.32066009e-02, -2.23883037e-02,  5.87266199e-02,\n",
       "       -1.17021222e-02, -2.13132538e-02,  4.80303094e-02, -8.50894749e-02,\n",
       "        1.14834398e-01,  5.86446077e-02, -3.57721671e-02, -1.03585795e-02,\n",
       "        1.99319702e-02, -1.24698495e-02,  4.39331643e-02,  1.12666160e-01,\n",
       "        5.57891726e-02,  1.89518370e-02,  2.97533236e-02,  2.11663861e-02,\n",
       "        4.45613340e-02,  3.04608122e-02,  1.52538409e-02,  1.12170409e-02,\n",
       "       -6.28475379e-03, -1.23710800e-02, -4.89389747e-02, -7.45015889e-02,\n",
       "        7.71860592e-03,  1.11512290e-02, -8.21027756e-02, -1.56533513e-02,\n",
       "       -4.19188291e-04, -1.89934149e-02,  8.78175441e-03, -1.47131989e-02,\n",
       "       -1.17318518e-02,  1.42132239e-02,  2.23683249e-02, -1.47142634e-02,\n",
       "       -1.83785539e-02,  2.66390629e-02,  2.70976126e-03, -5.65321743e-03,\n",
       "        3.71137746e-02,  3.76462564e-02, -2.30082609e-02, -5.82341403e-02,\n",
       "        9.67286248e-03, -3.05655189e-02,  2.39031054e-02, -6.30650967e-02,\n",
       "        6.11794665e-02, -4.17093653e-03, -6.67612702e-02,  2.10689679e-02,\n",
       "       -6.32687286e-02, -1.39526501e-02, -4.53685783e-03, -1.64617971e-03,\n",
       "        2.39585340e-02, -2.90261004e-02,  5.47982790e-02,  2.35498697e-02,\n",
       "       -1.11519694e-01, -1.11983130e-02, -4.79132459e-02,  2.42075082e-02,\n",
       "        2.99885124e-03,  4.24763858e-02,  2.77848188e-02, -5.98049909e-02,\n",
       "        2.54991837e-02, -4.36969958e-02, -5.17308293e-03,  3.19233127e-02,\n",
       "        3.59031819e-02, -2.99313962e-02,  9.75482725e-03,  1.57416090e-02,\n",
       "       -2.52648406e-02,  3.32824551e-02,  3.71812545e-02, -1.02417246e-02,\n",
       "       -2.88663767e-02, -2.46516056e-02, -7.40623847e-03, -3.02463621e-02,\n",
       "       -3.44113000e-02,  7.94706866e-03,  8.84458609e-03, -5.15631214e-02,\n",
       "       -6.58018440e-02,  9.05830786e-03, -4.06950526e-03,  4.13594097e-02,\n",
       "       -3.40355858e-02, -9.93005931e-03,  2.76475083e-02,  2.42615715e-02,\n",
       "       -4.73762862e-02, -5.56501113e-02,  7.65422061e-02,  2.31276825e-02,\n",
       "        8.07191432e-03,  6.99109733e-02,  5.20416722e-02, -2.60587931e-02,\n",
       "        4.53589261e-02,  2.52507813e-02, -4.88873944e-03, -9.11151618e-02,\n",
       "        5.96370995e-02, -3.10012829e-02,  3.01207192e-02,  2.66883429e-02,\n",
       "       -6.28919303e-02, -5.64179569e-02,  2.01110318e-02,  5.24177924e-02,\n",
       "        1.94523949e-02, -2.71229558e-02, -1.23984111e-03, -4.90371585e-02,\n",
       "       -4.42505032e-02,  5.46251908e-02,  2.10906062e-02, -3.65266018e-02,\n",
       "       -6.44939616e-02, -8.29686150e-02, -1.71243120e-03,  5.13759963e-02,\n",
       "        2.76180468e-02,  1.26830451e-02,  2.57916115e-02,  1.68398395e-02,\n",
       "       -2.23287679e-02, -2.13874020e-02,  1.70282498e-02, -1.41317919e-02,\n",
       "        4.39833617e-03,  4.67145033e-02,  2.05141995e-02,  5.86182848e-02,\n",
       "        4.58700806e-02, -1.48672443e-02, -5.77721298e-02, -3.56404372e-02,\n",
       "       -5.59900552e-02, -2.68256105e-02, -3.98690440e-02,  1.58344328e-01,\n",
       "        3.58779989e-02,  4.17821575e-03,  6.86629675e-03,  3.66662443e-02,\n",
       "        2.91265659e-02, -9.73174348e-04, -2.23096870e-02, -1.63330510e-02,\n",
       "       -9.11294669e-03,  2.38017123e-02,  8.73467550e-02, -3.48584130e-02,\n",
       "       -1.13172960e-02, -4.54864725e-02, -1.70437805e-03, -3.73020321e-02,\n",
       "       -1.94498003e-02,  1.51656512e-02,  2.86318082e-02, -2.15122290e-02,\n",
       "       -3.74438800e-03,  4.59270924e-02, -2.87287086e-02,  1.13593359e-02,\n",
       "        2.07949039e-02, -2.66616624e-02,  4.45637070e-02, -1.91387329e-02,\n",
       "       -1.50583228e-02, -1.36784697e-02, -3.89499292e-02, -1.45275947e-02,\n",
       "       -3.98802720e-02,  5.04820095e-03, -7.20128184e-03, -3.87129337e-02,\n",
       "        6.53511845e-03, -2.16917638e-02, -2.31031608e-02, -2.31756866e-02,\n",
       "        1.96921341e-02,  3.65980044e-02,  7.66739622e-02, -7.55966455e-02,\n",
       "       -6.54130057e-02,  1.93623677e-02, -3.34088616e-02, -9.07494314e-03,\n",
       "       -1.88522756e-01, -1.56432092e-02, -1.32406605e-02, -7.91307613e-02,\n",
       "        1.38889905e-03, -3.22806537e-02,  5.73995523e-03, -4.88286652e-03,\n",
       "       -6.27538860e-02, -1.39576904e-02, -2.64512189e-03,  7.86507875e-02,\n",
       "       -6.59447210e-03, -2.42414512e-03, -1.91883743e-03, -7.74029791e-02,\n",
       "       -1.54363737e-02,  5.27791679e-03,  1.10626854e-02, -3.82392481e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.get_sentence_vector(train_df[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42eb1014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My_home.json  \u001b[0m\u001b[38;5;33mrelation\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "%ls ../CRECIL/Orginal_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c258e494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'S   1 :       '"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(list(jieba.cut((train_df[0][0][0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d72c9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.462 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "for ep in train_df:\n",
    "    \n",
    "    space_separated = []\n",
    "    for line in ep[0]:\n",
    "        zh = re.findall('(?<=: ).*',line)[0]\n",
    "        speaker = re.findall('S [0-9]{1,2}',line)[0]\n",
    "        spaced = \" \".join(list(jieba.cut((zh))))\n",
    "        \n",
    "        space_separated.append((speaker,spaced))\n",
    "    ep.append(space_separated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8f8a6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.482 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "for ep in dev_df:\n",
    "    \n",
    "    space_separated = []\n",
    "    for line in ep[0]:\n",
    "        zh = re.findall('(?<=: ).*',line)[0]\n",
    "        speaker = re.findall('S [0-9]{1,2}',line)[0]\n",
    "        spaced = \" \".join(list(jieba.cut((zh))))\n",
    "        \n",
    "        space_separated.append((speaker,spaced))\n",
    "    ep.append(space_separated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d0694d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ep in test_df:\n",
    "    \n",
    "    space_separated = []\n",
    "    for line in ep[0]:\n",
    "        zh = re.findall('(?<=: ).*',line)[0]\n",
    "        speaker = re.findall('S [0-9]{1,2}',line)[0]\n",
    "        spaced = \" \".join(list(jieba.cut((zh))))\n",
    "        \n",
    "        space_separated.append((speaker,spaced))\n",
    "    ep.append(space_separated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daf98950",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'find'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-288b792fae3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sentence_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python368env/lib/python3.6/site-packages/fasttext/FastText.py\u001b[0m in \u001b[0;36mget_sentence_vector\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mcharacters\u001b[0m \u001b[0mcarriage\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformfeed\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mnull\u001b[0m \u001b[0mcharacter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \"\"\"\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m             raise ValueError(\n\u001b[1;32m    136\u001b[0m                 \u001b[0;34m\"predict processes one line at a time (remove \\'\\\\n\\')\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'find'"
     ]
    }
   ],
   "source": [
    "ft.get_sentence_vector(train_df[0][2][0]).size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b6e3d2",
   "metadata": {},
   "source": [
    "Step 3: Make a CRF <br/>\n",
    "- start with a model that embeds avg sentences of speakers and addressee, and concats two averages together, prepare a bit for possible disappointing results\n",
    "- concats rather than adds, because speaker and addressee are different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a7935ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26 s, sys: 14 s, total: 40 s\n",
      "Wall time: 42 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ed0a553",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentembedding = ft.get_sentence_vector(train_df[0][0][0])\n",
    "features = {}\n",
    "for iv,value in enumerate(sentembedding):\n",
    "    features['v{}'.format(iv)]=value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa5acec9",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'v0': 0.01106627,\n",
       " 'v1': 0.027206058,\n",
       " 'v2': 0.19847792,\n",
       " 'v3': 0.0024579961,\n",
       " 'v4': -0.023818873,\n",
       " 'v5': 0.015646469,\n",
       " 'v6': -0.00043350353,\n",
       " 'v7': -0.003766069,\n",
       " 'v8': 0.051558167,\n",
       " 'v9': -0.0015952874,\n",
       " 'v10': 0.0061212024,\n",
       " 'v11': -0.009077391,\n",
       " 'v12': 0.022217534,\n",
       " 'v13': 0.022401534,\n",
       " 'v14': 0.012786963,\n",
       " 'v15': 0.0058338256,\n",
       " 'v16': 0.0064654355,\n",
       " 'v17': -0.02994701,\n",
       " 'v18': -0.038112,\n",
       " 'v19': 0.0070583285,\n",
       " 'v20': 0.007241482,\n",
       " 'v21': 0.01436195,\n",
       " 'v22': -0.030545846,\n",
       " 'v23': 0.018104177,\n",
       " 'v24': 0.017776167,\n",
       " 'v25': 0.021293368,\n",
       " 'v26': 0.04400748,\n",
       " 'v27': 0.004081951,\n",
       " 'v28': 0.0036035774,\n",
       " 'v29': -0.0031443946,\n",
       " 'v30': -0.010697305,\n",
       " 'v31': -0.0389605,\n",
       " 'v32': -0.009899231,\n",
       " 'v33': -0.019908195,\n",
       " 'v34': -0.0007293793,\n",
       " 'v35': 0.0044721947,\n",
       " 'v36': 0.024639366,\n",
       " 'v37': -0.10570488,\n",
       " 'v38': 0.01728139,\n",
       " 'v39': -0.018320313,\n",
       " 'v40': -0.030422416,\n",
       " 'v41': -0.014750596,\n",
       " 'v42': 0.053793084,\n",
       " 'v43': 0.051949926,\n",
       " 'v44': 0.010822419,\n",
       " 'v45': -0.045076042,\n",
       " 'v46': 0.04065757,\n",
       " 'v47': -0.03777003,\n",
       " 'v48': 0.009021201,\n",
       " 'v49': 0.0003780831,\n",
       " 'v50': 0.007383788,\n",
       " 'v51': -0.022868423,\n",
       " 'v52': -0.010869572,\n",
       " 'v53': -0.18826905,\n",
       " 'v54': 0.034369145,\n",
       " 'v55': 0.0047161505,\n",
       " 'v56': 0.037641965,\n",
       " 'v57': -0.012825532,\n",
       " 'v58': 0.008504652,\n",
       " 'v59': -0.0013656172,\n",
       " 'v60': 0.047366068,\n",
       " 'v61': 0.0127432225,\n",
       " 'v62': 0.032633834,\n",
       " 'v63': -0.0011313865,\n",
       " 'v64': 0.020697676,\n",
       " 'v65': 0.015774174,\n",
       " 'v66': 0.016236657,\n",
       " 'v67': -0.022166438,\n",
       " 'v68': 0.04349698,\n",
       " 'v69': -0.031241307,\n",
       " 'v70': -0.019639283,\n",
       " 'v71': 0.07501606,\n",
       " 'v72': 0.013779028,\n",
       " 'v73': -0.020449668,\n",
       " 'v74': 0.023760207,\n",
       " 'v75': -0.0051167826,\n",
       " 'v76': 0.013336736,\n",
       " 'v77': -0.0574288,\n",
       " 'v78': 0.0053519495,\n",
       " 'v79': -0.018845687,\n",
       " 'v80': -0.04308303,\n",
       " 'v81': 0.0011175347,\n",
       " 'v82': -0.00383893,\n",
       " 'v83': -0.04101741,\n",
       " 'v84': -0.02082253,\n",
       " 'v85': 0.0071678637,\n",
       " 'v86': -0.07301283,\n",
       " 'v87': -0.028079186,\n",
       " 'v88': 0.060322072,\n",
       " 'v89': 0.049945533,\n",
       " 'v90': 0.03254228,\n",
       " 'v91': 0.003255859,\n",
       " 'v92': -0.014593355,\n",
       " 'v93': -0.035581905,\n",
       " 'v94': 0.008654743,\n",
       " 'v95': -0.0063921507,\n",
       " 'v96': 0.000203354,\n",
       " 'v97': -0.019447416,\n",
       " 'v98': 0.0031287048,\n",
       " 'v99': -0.018694218,\n",
       " 'v100': -0.12233233,\n",
       " 'v101': -0.04246852,\n",
       " 'v102': -0.015390894,\n",
       " 'v103': 0.05476297,\n",
       " 'v104': 0.048875958,\n",
       " 'v105': -0.00029985944,\n",
       " 'v106': 0.017570289,\n",
       " 'v107': -0.02560258,\n",
       " 'v108': 0.004154817,\n",
       " 'v109': -0.011520769,\n",
       " 'v110': -0.0057787844,\n",
       " 'v111': 0.015372657,\n",
       " 'v112': 0.087454915,\n",
       " 'v113': -0.021843523,\n",
       " 'v114': -0.013768395,\n",
       " 'v115': -0.008763535,\n",
       " 'v116': 0.0236032,\n",
       " 'v117': 0.0260779,\n",
       " 'v118': 0.009125572,\n",
       " 'v119': 0.0145411305,\n",
       " 'v120': -0.0009800905,\n",
       " 'v121': 0.020572567,\n",
       " 'v122': -0.0048858775,\n",
       " 'v123': 0.027538909,\n",
       " 'v124': 0.0029278367,\n",
       " 'v125': 0.020108406,\n",
       " 'v126': -0.014916269,\n",
       " 'v127': 0.015697597,\n",
       " 'v128': -0.016059939,\n",
       " 'v129': -0.023370551,\n",
       " 'v130': 0.0071471143,\n",
       " 'v131': -0.012947845,\n",
       " 'v132': -0.012154775,\n",
       " 'v133': 0.010401782,\n",
       " 'v134': -0.0063763624,\n",
       " 'v135': 0.021088652,\n",
       " 'v136': 0.10291715,\n",
       " 'v137': -0.0037178798,\n",
       " 'v138': -0.02850523,\n",
       " 'v139': -0.014551677,\n",
       " 'v140': 0.014180928,\n",
       " 'v141': 0.04500001,\n",
       " 'v142': -0.026478028,\n",
       " 'v143': -0.0027616199,\n",
       " 'v144': 0.0205128,\n",
       " 'v145': -0.0049573695,\n",
       " 'v146': 0.04028123,\n",
       " 'v147': 0.023971798,\n",
       " 'v148': 0.014112962,\n",
       " 'v149': -0.0019941,\n",
       " 'v150': 0.02068698,\n",
       " 'v151': 0.00923271,\n",
       " 'v152': -0.01185354,\n",
       " 'v153': 0.010544569,\n",
       " 'v154': -0.028276965,\n",
       " 'v155': 0.0040288386,\n",
       " 'v156': -0.0028535859,\n",
       " 'v157': -0.02501518,\n",
       " 'v158': 0.011435438,\n",
       " 'v159': 0.050445687,\n",
       " 'v160': 0.003941956,\n",
       " 'v161': 0.010775369,\n",
       " 'v162': 0.005613546,\n",
       " 'v163': 0.015640702,\n",
       " 'v164': 0.009434488,\n",
       " 'v165': -0.031745605,\n",
       " 'v166': 0.007853645,\n",
       " 'v167': 0.005438999,\n",
       " 'v168': 0.03628672,\n",
       " 'v169': -0.0038714376,\n",
       " 'v170': 0.02817309,\n",
       " 'v171': -0.015746338,\n",
       " 'v172': -0.074302,\n",
       " 'v173': 0.04876616,\n",
       " 'v174': 0.020036852,\n",
       " 'v175': 0.030430773,\n",
       " 'v176': 0.04011162,\n",
       " 'v177': 0.020971771,\n",
       " 'v178': -0.018465798,\n",
       " 'v179': -0.03974268,\n",
       " 'v180': -0.019780543,\n",
       " 'v181': -0.11895424,\n",
       " 'v182': 0.003027016,\n",
       " 'v183': 0.007975237,\n",
       " 'v184': -0.0075144484,\n",
       " 'v185': -0.0023936117,\n",
       " 'v186': 0.017596988,\n",
       " 'v187': 0.04889432,\n",
       " 'v188': -0.02545025,\n",
       " 'v189': 0.10234486,\n",
       " 'v190': 0.015772767,\n",
       " 'v191': 0.06713538,\n",
       " 'v192': 0.00022782316,\n",
       " 'v193': 0.02073452,\n",
       " 'v194': 0.0009887666,\n",
       " 'v195': 0.01569178,\n",
       " 'v196': 0.013523988,\n",
       " 'v197': 0.040649306,\n",
       " 'v198': 0.05653148,\n",
       " 'v199': 0.046051305,\n",
       " 'v200': 0.0052573234,\n",
       " 'v201': 0.03978596,\n",
       " 'v202': -0.0027491534,\n",
       " 'v203': 0.00019843015,\n",
       " 'v204': -0.008563957,\n",
       " 'v205': -0.0060810214,\n",
       " 'v206': 0.009425208,\n",
       " 'v207': 0.013673816,\n",
       " 'v208': 0.023669565,\n",
       " 'v209': 0.023892721,\n",
       " 'v210': 0.018193342,\n",
       " 'v211': 0.02143851,\n",
       " 'v212': 0.0021963352,\n",
       " 'v213': 0.036887005,\n",
       " 'v214': 0.018579228,\n",
       " 'v215': -0.0045479094,\n",
       " 'v216': -0.018378122,\n",
       " 'v217': -0.06970121,\n",
       " 'v218': -0.06991776,\n",
       " 'v219': -0.017898945,\n",
       " 'v220': -0.012899554,\n",
       " 'v221': -0.0524379,\n",
       " 'v222': 0.016609997,\n",
       " 'v223': -0.0048925276,\n",
       " 'v224': -0.018564926,\n",
       " 'v225': -0.0054252427,\n",
       " 'v226': -0.0023854189,\n",
       " 'v227': -0.004105012,\n",
       " 'v228': 0.05357019,\n",
       " 'v229': 0.042378888,\n",
       " 'v230': 0.0062602586,\n",
       " 'v231': 0.2843705,\n",
       " 'v232': -0.0013938347,\n",
       " 'v233': 0.04504556,\n",
       " 'v234': 0.009233792,\n",
       " 'v235': 0.022164024,\n",
       " 'v236': -0.007814399,\n",
       " 'v237': -0.0051056417,\n",
       " 'v238': 0.0145802,\n",
       " 'v239': -0.009484633,\n",
       " 'v240': 0.0061196964,\n",
       " 'v241': 0.0043201474,\n",
       " 'v242': 0.024185563,\n",
       " 'v243': 0.02002877,\n",
       " 'v244': -0.026859548,\n",
       " 'v245': -0.0075120353,\n",
       " 'v246': -0.044858266,\n",
       " 'v247': -0.00554341,\n",
       " 'v248': 0.011374473,\n",
       " 'v249': -0.11010513,\n",
       " 'v250': -0.039714053,\n",
       " 'v251': 0.0009850499,\n",
       " 'v252': -0.020802317,\n",
       " 'v253': -0.014681465,\n",
       " 'v254': -0.018762037,\n",
       " 'v255': -0.01348844,\n",
       " 'v256': 0.010880327,\n",
       " 'v257': 0.0048403204,\n",
       " 'v258': -0.004927769,\n",
       " 'v259': -0.00014560134,\n",
       " 'v260': 0.03397423,\n",
       " 'v261': -0.006780569,\n",
       " 'v262': 1.461315e-05,\n",
       " 'v263': -0.009123964,\n",
       " 'v264': 0.01230651,\n",
       " 'v265': 0.0067749796,\n",
       " 'v266': -0.007268046,\n",
       " 'v267': -0.0048086396,\n",
       " 'v268': 0.019533059,\n",
       " 'v269': -0.04199955,\n",
       " 'v270': 0.00687579,\n",
       " 'v271': -0.020200448,\n",
       " 'v272': -0.0022533056,\n",
       " 'v273': 0.01293199,\n",
       " 'v274': -0.036823742,\n",
       " 'v275': 0.0087176915,\n",
       " 'v276': -0.021996759,\n",
       " 'v277': 0.025148427,\n",
       " 'v278': 0.005838717,\n",
       " 'v279': -0.021466915,\n",
       " 'v280': -0.18343987,\n",
       " 'v281': 0.007854986,\n",
       " 'v282': -0.013728962,\n",
       " 'v283': 0.015254756,\n",
       " 'v284': 0.009485616,\n",
       " 'v285': -0.021664253,\n",
       " 'v286': 0.028323673,\n",
       " 'v287': 0.0057889586,\n",
       " 'v288': -0.0055654617,\n",
       " 'v289': 0.0013830283,\n",
       " 'v290': -0.02125762,\n",
       " 'v291': -0.006038819,\n",
       " 'v292': -0.009600657,\n",
       " 'v293': -0.0051889466,\n",
       " 'v294': -0.082615614,\n",
       " 'v295': 0.0011826161,\n",
       " 'v296': -0.022272868,\n",
       " 'v297': -0.011201483,\n",
       " 'v298': 0.001002791,\n",
       " 'v299': -0.0029103863}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_avg_embeddings(retrieve_s_lines('S 1',train_df[0][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bee6fd07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 482/482 [00:07<00:00, 66.58it/s]\n"
     ]
    }
   ],
   "source": [
    "# create train data for CRF\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_train_array = []\n",
    "y_train_flat = []\n",
    "\n",
    "for i in tqdm(range(0,len(train_df))): #20\n",
    "    \n",
    "    #list of tuples containing speakers and tokenized sentences\n",
    "    dialog = train_df[i][2]\n",
    "    \n",
    "    #get relations and labels:\n",
    "    for j in range(0,len(train_df[i][1])):\n",
    "        \n",
    "        rel_triplet = train_df[i][1][j]\n",
    "        x = rel_triplet['x']\n",
    "        y = rel_triplet['y']\n",
    "        r = rel_triplet['r'] #note that this is a list that can have len>1\n",
    "        \n",
    "        for rel in r:\n",
    "            y_train.append([rel])\n",
    "            y_train_flat.append(rel)\n",
    "            \n",
    "            # retrieve lines by speakers or entity mentionned:\n",
    "            if bool(re.search('S',x)):\n",
    "                x_lines = retrieve_s_lines(x,dialog)\n",
    "            else:\n",
    "                x_lines = retrieve_mentions(x,dialog)\n",
    "\n",
    "            if bool(re.search('S',y)):\n",
    "                y_lines = retrieve_s_lines(y,dialog)\n",
    "            else:\n",
    "                y_lines = retrieve_mentions(y,dialog)\n",
    "            \n",
    "            # Get the average embeddings of the lines\n",
    "            if len(x_lines)>0:\n",
    "                x_embed = get_avg_embeddings(x_lines)\n",
    "            else:  #note: there could be no lines from the speaker or entity, (did not talk)\n",
    "                x_embed = np.zeros(100)\n",
    "            if len(y_lines)>0:\n",
    "                y_embed = get_avg_embeddings(y_lines)\n",
    "            else:\n",
    "                y_embed = np.zeros(100)\n",
    "            \n",
    "            x_y_embed = np.concatenate((x_embed,y_embed)) # 1x600 np array \n",
    "            \n",
    "            X_train.append([embeddings_to_features(x_y_embed)])\n",
    "            X_train_array.append(x_y_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2794886f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 116/116 [00:01<00:00, 80.68it/s]\n"
     ]
    }
   ],
   "source": [
    "# create dev data for CRF\n",
    "X_dev = []\n",
    "y_dev = []\n",
    "X_dev_array = []\n",
    "y_dev_flat = []\n",
    "\n",
    "for i in tqdm(range(0,len(dev_df))): #20\n",
    "    \n",
    "    #list of tuples containing speakers and tokenized sentences\n",
    "    dialog = dev_df[i][2]\n",
    "    \n",
    "    #get relations and labels:\n",
    "    for j in range(0,len(dev_df[i][1])):\n",
    "        \n",
    "        rel_triplet = dev_df[i][1][j]\n",
    "        x = rel_triplet['x']\n",
    "        y = rel_triplet['y']\n",
    "        r = rel_triplet['r'] #note that this is a list that can have len>1\n",
    "        \n",
    "        for rel in r:\n",
    "            y_dev.append([rel])\n",
    "            y_dev_flat.append(rel)\n",
    "            \n",
    "            # retrieve lines by speakers or entity mentionned:\n",
    "            if bool(re.search('S',x)):\n",
    "                x_lines = retrieve_s_lines(x,dialog)\n",
    "            else:\n",
    "                x_lines = retrieve_mentions(x,dialog)\n",
    "\n",
    "            if bool(re.search('S',y)):\n",
    "                y_lines = retrieve_s_lines(y,dialog)\n",
    "            else:\n",
    "                y_lines = retrieve_mentions(y,dialog)\n",
    "            \n",
    "            # Get the average embeddings of the lines\n",
    "            if len(x_lines)>0:\n",
    "                x_embed = get_avg_embeddings(x_lines)\n",
    "            else:  #note: there could be no lines from the speaker or entity, (did not talk)\n",
    "                x_embed = np.zeros(100)\n",
    "            if len(y_lines)>0:\n",
    "                y_embed = get_avg_embeddings(y_lines)\n",
    "            else:\n",
    "                y_embed = np.zeros(100)\n",
    "            \n",
    "            x_y_embed = np.concatenate((x_embed,y_embed)) # 1x600 np array \n",
    "            \n",
    "            X_dev.append([embeddings_to_features(x_y_embed)])\n",
    "            X_dev_array.append(x_y_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c25c8472",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 71/71 [00:00<00:00, 76.09it/s] \n"
     ]
    }
   ],
   "source": [
    "# create test data for CRF\n",
    "X_test = []\n",
    "y_test = []\n",
    "X_test_array = []\n",
    "y_test_flat = []\n",
    "\n",
    "\n",
    "for i in tqdm(range(0,len(test_df))): #20\n",
    "    \n",
    "    #list of tuples containing speakers and tokenized sentences\n",
    "    dialog = test_df[i][2]\n",
    "    \n",
    "    #get relations and labels:\n",
    "    for j in range(0,len(test_df[i][1])):\n",
    "        \n",
    "        rel_triplet = test_df[i][1][j]\n",
    "        x = rel_triplet['x']\n",
    "        y = rel_triplet['y']\n",
    "        r = rel_triplet['r'] #note that this is a list that can have len>1\n",
    "        \n",
    "        for rel in r:\n",
    "            y_test.append([rel])\n",
    "            y_test_flat.append(rel)\n",
    "            \n",
    "            # retrieve lines by speakers or entity mentionned:\n",
    "            if bool(re.search('S',x)):\n",
    "                x_lines = retrieve_s_lines(x,dialog)\n",
    "            else:\n",
    "                x_lines = retrieve_mentions(x,dialog)\n",
    "\n",
    "            if bool(re.search('S',y)):\n",
    "                y_lines = retrieve_s_lines(y,dialog)\n",
    "            else:\n",
    "                y_lines = retrieve_mentions(y,dialog)\n",
    "            \n",
    "            # Get the average embeddings of the lines\n",
    "            if len(x_lines)>0:\n",
    "                x_embed = get_avg_embeddings(x_lines)\n",
    "            else:  #note: there could be no lines from the speaker or entity, (did not talk)\n",
    "                x_embed = np.zeros(100)\n",
    "            if len(y_lines)>0:\n",
    "                y_embed = get_avg_embeddings(y_lines)\n",
    "            else:\n",
    "                y_embed = np.zeros(100)\n",
    "            \n",
    "            x_y_embed = np.concatenate((x_embed,y_embed)) # 1x600 np array \n",
    "            \n",
    "            X_test.append([embeddings_to_features(x_y_embed)])\n",
    "            X_test_array.append(x_y_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7fd6cbe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/elyeb/anaconda3/envs/python368env/lib/python3.6/site-packages/sklearn/base.py:213: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_transitions=True, c1=0.1, c2=0.1,\n",
       "    keep_tempfiles=None, max_iterations=100)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b24d4618",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dev_predict = crf.predict(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4ba3989e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predict = crf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cbc41108",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/elyeb/anaconda3/envs/python368env/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1465: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.18733202933298904"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(crf.classes_)\n",
    "metrics.flat_f1_score(y_test, y_test_predict,\n",
    "                      average='weighted', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9e321a52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16068029756658578"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(crf.classes_)\n",
    "metrics.flat_f1_score(y_dev, y_dev_predict,\n",
    "                      average='weighted', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "21907b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict = crf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "743b70f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17828860143311312"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.flat_f1_score(y_train, y_train_predict,\n",
    "                      average='weighted', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "41e098a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "       per:acquaintance      0.000     0.000     0.000       181\n",
      "     per:alternate_name      0.092     0.031     0.046       547\n",
      "               per:boss      0.000     0.000     0.000        78\n",
      "          per:boyfriend      0.000     0.000     0.000        46\n",
      "           per:children      0.168     0.057     0.085       335\n",
      "    per:children-in-law      0.000     0.000     0.000        86\n",
      "          per:classmate      0.000     0.000     0.000        34\n",
      "             per:client      0.000     0.000     0.000        19\n",
      "          per:colleague      0.000     0.000     0.000        30\n",
      "              per:dates      0.000     0.000     0.000        28\n",
      "       per:ex-boyfriend      0.000     0.000     0.000        22\n",
      "      per:ex-girlfriend      0.000     0.000     0.000        22\n",
      "            per:friends      0.300     0.014     0.026       218\n",
      "         per:girlfriend      0.000     0.000     0.000        46\n",
      "      per:grandchildren      0.000     0.000     0.000        83\n",
      "       per:grandparents      0.000     0.000     0.000        83\n",
      "per:negative impression      0.000     0.000     0.000        39\n",
      "           per:neighbor      0.247     0.135     0.174       416\n",
      "           per:nickname      0.000     0.000     0.000         0\n",
      "              per:nurse      0.409     0.043     0.078       210\n",
      "            per:parents      0.209     0.054     0.086       335\n",
      "     per:parents-in-law      0.000     0.000     0.000        86\n",
      "per:positive impression      0.000     0.000     0.000        27\n",
      "           per:relative      0.234     0.063     0.099       350\n",
      "           per:roommate      0.000     0.000     0.000         0\n",
      "           per:siblings      0.000     0.000     0.000       144\n",
      "    per:siblings-in-law      0.000     0.000     0.000         4\n",
      "             per:spouse      0.015     0.011     0.013       174\n",
      "            per:student      0.000     0.000     0.000         6\n",
      "        per:subordinate      0.000     0.000     0.000        78\n",
      "            per:teacher      0.000     0.000     0.000         6\n",
      "           unanswerable      0.328     0.889     0.479      1662\n",
      "\n",
      "              micro avg      0.301     0.301     0.301      5395\n",
      "              macro avg      0.063     0.040     0.034      5395\n",
      "           weighted avg      0.197     0.301     0.187      5395\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/elyeb/anaconda3/envs/python368env/lib/python3.6/site-packages/sklearn/utils/validation.py:71: FutureWarning: Pass labels=['per:acquaintance', 'per:alternate_name', 'per:boss', 'per:boyfriend', 'per:children', 'per:children-in-law', 'per:classmate', 'per:client', 'per:colleague', 'per:dates', 'per:ex-boyfriend', 'per:ex-girlfriend', 'per:friends', 'per:girlfriend', 'per:grandchildren', 'per:grandparents', 'per:negative impression', 'per:neighbor', 'per:nickname', 'per:nurse', 'per:parents', 'per:parents-in-law', 'per:positive impression', 'per:relative', 'per:roommate', 'per:siblings', 'per:siblings-in-law', 'per:spouse', 'per:student', 'per:subordinate', 'per:teacher', 'unanswerable'] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n",
      "/home2/elyeb/anaconda3/envs/python368env/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home2/elyeb/anaconda3/envs/python368env/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_test_predict, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "55766cc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit\n",
    "#X_train_array = pd.DataFrame(X_train_array)\n",
    "SVM = SVC(kernel = 'linear')\n",
    "SVM.fit(X_train_array,y_train_flat)\n",
    "#y_pred=SVM.predict(X_dev)\n",
    "y_pred=SVM.predict(X_test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e5f0ad69",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev_array = pd.DataFrame(X_dev_array)\n",
    "X_test_array = pd.DataFrame(X_test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "25b8171e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=SVM.predict(X_test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "53a2b2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_unlist = [item[0] for item in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "eb18fb89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'unanswerable': 5395})"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ad2b9a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38684, 200)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a183f432",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [5395, 64740]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-b09801bd7a86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m metrics.flat_f1_score(y_test, y_pred,\n\u001b[0;32m----> 2\u001b[0;31m                       average='weighted', labels=labels)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python368env/lib/python3.6/site-packages/sklearn_crfsuite/metrics.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(y_true, y_pred, *args, **kwargs)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0my_true_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0my_pred_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python368env/lib/python3.6/site-packages/sklearn_crfsuite/metrics.py\u001b[0m in \u001b[0;36mflat_f1_score\u001b[0;34m(y_true, y_pred, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \"\"\"\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python368env/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python368env/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1045\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m                        \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m                        zero_division=zero_division)\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python368env/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python368env/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1173\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f-score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m                                                  \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m                                                  zero_division=zero_division)\n\u001b[0m\u001b[1;32m   1176\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python368env/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python368env/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1432\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0;32m-> 1434\u001b[0;31m                                     pos_label)\n\u001b[0m\u001b[1;32m   1435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1436\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python368env/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1248\u001b[0m                          str(average_options))\n\u001b[1;32m   1249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1250\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1251\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1252\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'binary'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python368env/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \"\"\"\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python368env/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 257\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [5395, 64740]"
     ]
    }
   ],
   "source": [
    "metrics.flat_f1_score(y_test, y_pred,\n",
    "                      average='weighted', labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48a599c",
   "metadata": {},
   "source": [
    "Testing full (actually only pairwise, but still better than sequence) CRF: pystruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d899ee09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pystruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d2ea33f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn.externals.joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-30efbd8c7198>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexternals\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mextjoblib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpystruct\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pystruct/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStructuredModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcrf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCRF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgrid_crf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGridCRF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDirectionalGridCRF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgraph_crf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGraphCRF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mchain_crf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChainCRF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pystruct/models/crf.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStructuredModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minference_dispatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_installed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mloss_augment_unaries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pystruct/inference/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m from .inference_methods import (inference_qpbo, inference_lp,\n\u001b[0m\u001b[1;32m      2\u001b[0m                                 \u001b[0minference_ad3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference_ogm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                 \u001b[0minference_dispatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_installed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                 inference_ad3plus, InferenceException)\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompute_energy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pystruct/inference/inference_methods.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlinear_programming\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlp_general_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmaxprod\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minference_max_product\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_validate_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pystruct/inference/maxprod.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_validate_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_functions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_forest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pystruct/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m from .inference import (unwrap_pairwise, find_constraint,\n\u001b[0m\u001b[1;32m      2\u001b[0m                         \u001b[0mfind_constraint_latent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                         \u001b[0mloss_augmented_inference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobjective_primal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                         \u001b[0mexhaustive_loss_augmented_inference\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                         exhaustive_inference, compress_sym, expand_sym)\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pystruct/utils/inference.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexternals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoblib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelayed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.externals.joblib'"
     ]
    }
   ],
   "source": [
    "import sklearn.externals as extjoblib\n",
    "from pystruct import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb957008",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sys' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-6118d87700fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sklearn.externals.joblib'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sys' is not defined"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "sys.modules['sklearn.externals.joblib'] = joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3487ec73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sklearn.externals.joblib = joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cba34696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pkg_resources\n",
    "from subprocess import call\n",
    "\n",
    "packages = [dist.project_name for dist in pkg_resources.working_set]\n",
    "call(\"pip3 install --upgrade \" + ' '.join(packages), shell=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc05c870",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn.externals.joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-e12f937b4cad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpystruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGraphCRF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pystruct/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStructuredModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcrf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCRF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgrid_crf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGridCRF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDirectionalGridCRF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgraph_crf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGraphCRF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mchain_crf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChainCRF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pystruct/models/crf.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStructuredModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minference_dispatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_installed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mloss_augment_unaries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pystruct/inference/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m from .inference_methods import (inference_qpbo, inference_lp,\n\u001b[0m\u001b[1;32m      2\u001b[0m                                 \u001b[0minference_ad3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference_ogm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                 \u001b[0minference_dispatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_installed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                 inference_ad3plus, InferenceException)\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompute_energy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pystruct/inference/inference_methods.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlinear_programming\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlp_general_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmaxprod\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minference_max_product\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_validate_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pystruct/inference/maxprod.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_validate_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_functions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_forest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pystruct/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m from .inference import (unwrap_pairwise, find_constraint,\n\u001b[0m\u001b[1;32m      2\u001b[0m                         \u001b[0mfind_constraint_latent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                         \u001b[0mloss_augmented_inference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobjective_primal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                         \u001b[0mexhaustive_loss_augmented_inference\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                         exhaustive_inference, compress_sym, expand_sym)\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pystruct/utils/inference.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexternals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoblib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelayed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.externals.joblib'"
     ]
    }
   ],
   "source": [
    "from pystruct.models import GraphCRF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fdb510",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(GraphCRF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff88069",
   "metadata": {},
   "source": [
    "TRYING TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f41e875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: predict subset of relation pairs over balanced data\n",
    "with open('ref_files/id_label.pickle','rb') as infile:\n",
    "    id_label = pickle.load(infile)\n",
    "\n",
    "with open('ref_files/label_id.pickle','rb') as infile:\n",
    "    label_id = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73eee49c",
   "metadata": {},
   "source": [
    "**Reorganized labels**\n",
    "Mirrored relations (11):\n",
    "- per:friends, per:friends\n",
    "- per:spouse, per:spouse\n",
    "- per:classmate, per:classmate\n",
    "- per:neighbor, per:neighbor\n",
    "- per:acquaintance, per:acquaintance\n",
    "- per:dates, per:dates\n",
    "- per:relative, per:relative\n",
    "- per:siblings, per:siblings\n",
    "- per:colleague, per:colleague\n",
    "- per:siblings-in-law, per:siblings-in-law\n",
    "- per:roommate, per:roommate\n",
    "\n",
    "\n",
    "Unmirrored relations (9):\n",
    "- per:children-in-law, per:parents-in-law\n",
    "- per:children, per:parents\n",
    "- per:grandchildren, per:grandparents\n",
    "- per:ex-girlfriend, per:ex-boyfriend\n",
    "- per:girlfriend, per:boyfriend\n",
    "- per:subordinate, per:boss\n",
    "- per:student, per:teacher\n",
    "- unanswerable, unanswerable\n",
    "- per:alternate_name, per:alternate_name\n",
    "\n",
    "Other (7):\n",
    "- per:nurse\n",
    "- per:negative impression\n",
    "- per:positive impression\n",
    "- per:client\n",
    "- per:nickname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20aeb9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_rels = dict()\n",
    "y_train = dict()\n",
    "\n",
    "y_train['per:friends-per:friends']=dict()\n",
    "y_train['per:friends-per:friends']['col_num'] = 0\n",
    "y_train['per:friends-per:friends']['y'] = []\n",
    "y_train['per:friends-per:friends']['y_index'] = []\n",
    "\n",
    "y_train['per:spouse-per:spouse']=dict()\n",
    "y_train['per:spouse-per:spouse']['col_num'] =1\n",
    "y_train['per:spouse-per:spouse']['y'] = []\n",
    "y_train['per:spouse-per:spouse']['y_index'] = []\n",
    "\n",
    "y_train['per:classmate-per:classmate']=dict()\n",
    "y_train['per:classmate-per:classmate']['col_num'] =2\n",
    "y_train['per:classmate-per:classmate']['y'] = []\n",
    "y_train['per:classmate-per:classmate']['y_index'] = []\n",
    "\n",
    "y_train['per:neighbor-per:neighbor']=dict()\n",
    "y_train['per:neighbor-per:neighbor']['col_num'] =3\n",
    "y_train['per:neighbor-per:neighbor']['y'] = []\n",
    "y_train['per:neighbor-per:neighbor']['y_index'] = []\n",
    "\n",
    "y_train['per:acquaintance-per:acquaintance']=dict()\n",
    "y_train['per:acquaintance-per:acquaintance']['col_num'] =4\n",
    "y_train['per:acquaintance-per:acquaintance']['y'] = []\n",
    "y_train['per:acquaintance-per:acquaintance']['y_index'] = []\n",
    "\n",
    "y_train['per:dates-per:dates']=dict()\n",
    "y_train['per:dates-per:dates']['col_num'] =5\n",
    "y_train['per:dates-per:dates']['y'] = []\n",
    "y_train['per:dates-per:dates']['y_index'] = []\n",
    "\n",
    "y_train['per:relative-per:relative']=dict()\n",
    "y_train['per:relative-per:relative']['col_num'] =6\n",
    "y_train['per:relative-per:relative']['y'] = []\n",
    "y_train['per:relative-per:relative']['y_index'] = []\n",
    "\n",
    "y_train['per:siblings-per:siblings']=dict()\n",
    "y_train['per:siblings-per:siblings']['col_num'] =7\n",
    "y_train['per:siblings-per:siblings']['y'] = []\n",
    "y_train['per:siblings-per:siblings']['y_index'] = []\n",
    "\n",
    "y_train['per:colleague-per:colleague']=dict()\n",
    "y_train['per:colleague-per:colleague']['col_num'] =8\n",
    "y_train['per:colleague-per:colleague']['y'] = []\n",
    "y_train['per:colleague-per:colleague']['y_index'] = []\n",
    "\n",
    "y_train['per:siblings-in-law-per:siblings-in-law']=dict()\n",
    "y_train['per:siblings-in-law-per:siblings-in-law']['col_num']=9\n",
    "y_train['per:siblings-in-law-per:siblings-in-law']['y'] = []\n",
    "y_train['per:siblings-in-law-per:siblings-in-law']['y_index'] = []\n",
    "\n",
    "y_train['per:roommate-per:per:roommate']=dict()\n",
    "y_train['per:roommate-per:per:roommate']['col_num'] =10\n",
    "y_train['per:roommate-per:per:roommate']['y'] = []\n",
    "y_train['per:roommate-per:per:roommate']['y_index'] = []\n",
    "\n",
    "y_train['unanswerable-unanswerable']=dict()\n",
    "y_train['unanswerable-unanswerable']['col_num'] = 11\n",
    "y_train['unanswerable-unanswerable']['y'] = []\n",
    "y_train['unanswerable-unanswerable']['y_index'] = []\n",
    "\n",
    "y_train['per:alternate_name:per:alternate_name']=dict()\n",
    "y_train['per:alternate_name:per:alternate_name']['col_num'] = 12\n",
    "y_train['per:alternate_name:per:alternate_name']['y'] = []\n",
    "y_train['per:alternate_name:per:alternate_name']['y_index'] = []\n",
    "\n",
    "y_train['per:children-in-law-per:parents-in-law']=dict()\n",
    "y_train['per:children-in-law-per:parents-in-law']['col_num'] = 13\n",
    "y_train['per:children-in-law-per:parents-in-law']['y'] = []\n",
    "y_train['per:children-in-law-per:parents-in-law']['y_index'] = []\n",
    "\n",
    "y_train['per:children-per:parents']=dict()\n",
    "y_train['per:children-per:parents']['col_num'] = 14\n",
    "y_train['per:children-per:parents']['y'] = []\n",
    "y_train['per:children-per:parents']['y_index'] = []\n",
    "\n",
    "y_train['per:grandchildren-per:grandparents']=dict()\n",
    "y_train['per:grandchildren-per:grandparents']['col_num'] = 15\n",
    "y_train['per:grandchildren-per:grandparents']['y'] = []\n",
    "y_train['per:grandchildren-per:grandparents']['y_index'] = []\n",
    "\n",
    "y_train['per:ex-girlfriend-per:ex-boyfriend']=dict()\n",
    "y_train['per:ex-girlfriend-per:ex-boyfriend']['col_num'] = 16\n",
    "y_train['per:ex-girlfriend-per:ex-boyfriend']['y'] = []\n",
    "y_train['per:ex-girlfriend-per:ex-boyfriend']['y_index'] = []\n",
    "\n",
    "y_train['per:girlfriend-per:boyfriend']=dict()\n",
    "y_train['per:girlfriend-per:boyfriend']['col_num'] = 17\n",
    "y_train['per:girlfriend-per:boyfriend']['y'] = []\n",
    "y_train['per:girlfriend-per:boyfriend']['y_index'] = []\n",
    "\n",
    "y_train['per:subordinate-per:boss']=dict()\n",
    "y_train['per:subordinate-per:boss']['col_num'] = 18\n",
    "y_train['per:subordinate-per:boss']['y'] = []\n",
    "y_train['per:subordinate-per:boss']['y_index'] = []\n",
    "\n",
    "y_train['per:student-per:teacher']=dict()\n",
    "y_train['per:student-per:teacher']['col_num'] = 19\n",
    "y_train['per:student-per:teacher']['y'] = []\n",
    "y_train['per:student-per:teacher']['y_index'] = []\n",
    "\n",
    "y_train['per:nurse']=dict()\n",
    "y_train['per:nurse']['col_num'] = 20\n",
    "y_train['per:nurse']['y'] = []\n",
    "y_train['per:nurse']['y_index'] = []\n",
    "\n",
    "y_train['per:negative impression']=dict()\n",
    "y_train['per:negative impression']['col_num'] = 21\n",
    "y_train['per:negative impression']['y'] = []\n",
    "y_train['per:negative impression']['y_index'] = []\n",
    "\n",
    "y_train['per:positive impression']=dict()\n",
    "y_train['per:positive impression']['col_num'] = 22\n",
    "y_train['per:positive impression']['y'] = []\n",
    "y_train['per:positive impression']['y_index'] = []\n",
    "\n",
    "y_train['per:client']=dict()\n",
    "y_train['per:client']['col_num'] = 23\n",
    "y_train['per:client']['y'] = []\n",
    "y_train['per:client']['y_index'] = []\n",
    "\n",
    "y_train['per:nickname']=dict()\n",
    "y_train['per:nickname']['col_num'] = 24\n",
    "y_train['per:nickname']['y'] = []\n",
    "y_train['per:nickname']['y_index'] = []\n",
    "\n",
    "grp_rels['per:friends'] = dict()\n",
    "grp_rels['per:friends']['set'] = ['per:friends', 'per:friends']\n",
    "grp_rels['per:friends']['group'] = 'per:friends-per:friends'\n",
    "grp_rels['per:friends']['col_num'] = 0\n",
    "\n",
    "grp_rels['per:spouse'] = dict()\n",
    "grp_rels['per:spouse']['set'] = ['per:spouse', 'per:spouse']\n",
    "grp_rels['per:spouse']['group'] = 'per:spouse-per:spouse'\n",
    "grp_rels['per:spouse']['col_num'] = 1\n",
    "\n",
    "grp_rels['per:classmate'] = dict()\n",
    "grp_rels['per:classmate']['set'] = ['per:classmate', 'per:classmate']\n",
    "grp_rels['per:classmate']['group'] = 'per:classmate-per:classmate'\n",
    "grp_rels['per:classmate']['col_num'] = 2\n",
    "\n",
    "grp_rels['per:neighbor'] = dict()\n",
    "grp_rels['per:neighbor']['set'] = ['per:neighbor', 'per:neighbor']\n",
    "grp_rels['per:neighbor']['group'] = 'per:neighbor-per:neighbor'\n",
    "grp_rels['per:neighbor']['col_num'] = 3\n",
    "\n",
    "grp_rels['per:acquaintance'] = dict()\n",
    "grp_rels['per:acquaintance']['set'] = ['per:acquaintance', 'per:acquaintance']\n",
    "grp_rels['per:acquaintance']['group'] = 'per:acquaintance-per:acquaintance'\n",
    "grp_rels['per:acquaintance']['col_num'] = 4\n",
    "\n",
    "grp_rels['per:dates'] = dict()\n",
    "grp_rels['per:dates']['set'] = ['per:dates', 'per:dates']\n",
    "grp_rels['per:dates']['group'] = 'per:dates-per:dates'\n",
    "grp_rels['per:dates']['col_num'] = 5\n",
    "\n",
    "grp_rels['per:relative'] = dict()\n",
    "grp_rels['per:relative']['set'] = ['per:relative', 'per:relative']\n",
    "grp_rels['per:relative']['group'] = 'per:relative-per:relative'\n",
    "grp_rels['per:relative']['col_num'] = 6\n",
    "\n",
    "grp_rels['per:siblings'] = dict()\n",
    "grp_rels['per:siblings']['set'] = ['per:siblings', 'per:siblings']\n",
    "grp_rels['per:siblings']['group'] = 'per:siblings-per:siblings'\n",
    "grp_rels['per:siblings']['col_num'] = 7\n",
    "\n",
    "grp_rels['per:colleague'] = dict()\n",
    "grp_rels['per:colleague']['set'] = ['per:colleague', 'per:colleague']\n",
    "grp_rels['per:colleague']['group'] = 'per:colleague-per:colleague'\n",
    "grp_rels['per:colleague']['col_num'] = 8\n",
    "\n",
    "grp_rels['per:siblings-in-law'] = dict()\n",
    "grp_rels['per:siblings-in-law']['set'] = ['per:siblings-in-law', 'per:siblings-in-law']\n",
    "grp_rels['per:siblings-in-law']['group'] = 'per:siblings-in-law-per:siblings-in-law'\n",
    "grp_rels['per:siblings-in-law']['col_num'] = 9\n",
    "\n",
    "grp_rels['per:roommate'] = dict()\n",
    "grp_rels['per:roommate']['set'] = ['per:roommate', 'per:roommate']\n",
    "grp_rels['per:roommate']['group'] = 'per:roommate-per:per:roommate'\n",
    "grp_rels['per:roommate']['col_num'] = 10\n",
    "\n",
    "grp_rels['unanswerable'] = dict()\n",
    "grp_rels['unanswerable']['set'] = ['unanswerable', 'unanswerable']\n",
    "grp_rels['unanswerable']['group'] = 'unanswerable-unanswerable'\n",
    "grp_rels['unanswerable']['col_num'] = 11\n",
    "\n",
    "grp_rels['per:alternate_name'] = dict()\n",
    "grp_rels['per:alternate_name']['set'] = ['per:alternate_name', 'per:alternate_name']\n",
    "grp_rels['per:alternate_name']['group'] = 'per:alternate_name:per:alternate_name'\n",
    "grp_rels['per:alternate_name']['col_num'] = 12\n",
    "\n",
    "grp_rels['per:parents-in-law'] = dict()\n",
    "grp_rels['per:parents-in-law']['set'] = ['per:children-in-law', 'per:parents-in-law']\n",
    "grp_rels['per:parents-in-law']['group'] = 'per:children-in-law-per:parents-in-law'\n",
    "grp_rels['per:parents-in-law']['col_num'] = 13\n",
    "\n",
    "grp_rels['per:children-in-law'] = dict()\n",
    "grp_rels['per:children-in-law']['set'] = ['per:children-in-law', 'per:parents-in-law']\n",
    "grp_rels['per:children-in-law']['group'] = 'per:children-in-law-per:parents-in-law'\n",
    "grp_rels['per:children-in-law']['col_num'] = 13\n",
    "\n",
    "grp_rels['per:parents'] = dict()\n",
    "grp_rels['per:parents']['set'] = ['per:children', 'per:parents']\n",
    "grp_rels['per:parents']['group'] = 'per:children-per:parents'\n",
    "grp_rels['per:parents']['col_num'] = 14\n",
    "\n",
    "grp_rels['per:children'] = dict()\n",
    "grp_rels['per:children']['set'] = ['per:children', 'per:parents']\n",
    "grp_rels['per:children']['group'] = 'per:children-per:parents'\n",
    "grp_rels['per:children']['col_num'] = 14\n",
    "\n",
    "grp_rels['per:grandparents'] = dict()\n",
    "grp_rels['per:grandparents']['set'] = ['per:grandchildren', 'per:grandparents']\n",
    "grp_rels['per:grandparents']['group'] = 'per:grandchildren-per:grandparents'\n",
    "grp_rels['per:grandparents']['col_num'] = 15\n",
    "\n",
    "grp_rels['per:grandchildren'] = dict()\n",
    "grp_rels['per:grandchildren']['set'] = ['per:grandchildren', 'per:grandparents']\n",
    "grp_rels['per:grandchildren']['group'] = 'per:grandchildren-per:grandparents'\n",
    "grp_rels['per:grandchildren']['col_num'] = 15\n",
    "\n",
    "grp_rels['per:ex-boyfriend'] = dict()\n",
    "grp_rels['per:ex-boyfriend']['set'] = ['per:ex-girlfriend', 'per:ex-boyfriend']\n",
    "grp_rels['per:ex-boyfriend']['group'] = 'per:ex-girlfriend-per:ex-boyfriend'\n",
    "grp_rels['per:ex-boyfriend']['col_num'] = 16\n",
    "\n",
    "grp_rels['per:ex-girlfriend'] = dict()\n",
    "grp_rels['per:ex-girlfriend']['set'] = ['per:ex-girlfriend', 'per:ex-boyfriend']\n",
    "grp_rels['per:ex-girlfriend']['group'] = 'per:ex-girlfriend-per:ex-boyfriend'\n",
    "grp_rels['per:ex-girlfriend']['col_num'] = 16\n",
    "\n",
    "grp_rels['per:boyfriend'] = dict()\n",
    "grp_rels['per:boyfriend']['set'] = ['per:girlfriend', 'per:boyfriend']\n",
    "grp_rels['per:boyfriend']['group'] = 'per:girlfriend-per:boyfriend'\n",
    "grp_rels['per:boyfriend']['col_num'] = 17\n",
    "\n",
    "grp_rels['per:girlfriend'] = dict()\n",
    "grp_rels['per:girlfriend']['set'] = ['per:girlfriend', 'per:boyfriend']\n",
    "grp_rels['per:girlfriend']['group'] = 'per:girlfriend-per:boyfriend'\n",
    "grp_rels['per:girlfriend']['col_num'] = 17\n",
    "\n",
    "grp_rels['per:boss'] = dict()\n",
    "grp_rels['per:boss']['set'] = ['per:subordinate', 'per:boss']\n",
    "grp_rels['per:boss']['group'] = 'per:subordinate-per:boss'\n",
    "grp_rels['per:boss']['col_num'] = 18\n",
    "\n",
    "grp_rels['per:subordinate'] = dict()\n",
    "grp_rels['per:subordinate']['set'] = ['per:subordinate', 'per:boss']\n",
    "grp_rels['per:subordinate']['group'] = 'per:subordinate-per:boss'\n",
    "grp_rels['per:subordinate']['col_num'] = 18\n",
    "\n",
    "grp_rels['per:teacher'] = dict()\n",
    "grp_rels['per:teacher']['set'] = ['per:student', 'per:teacher']\n",
    "grp_rels['per:teacher']['group'] = 'per:student-per:teacher'\n",
    "grp_rels['per:teacher']['col_num'] = 19\n",
    "\n",
    "grp_rels['per:student'] = dict()\n",
    "grp_rels['per:student']['set'] = ['per:student', 'per:teacher']\n",
    "grp_rels['per:student']['group'] = 'per:student-per:teacher'\n",
    "grp_rels['per:student']['col_num'] = 19\n",
    "\n",
    "grp_rels['per:nurse'] = dict()\n",
    "grp_rels['per:nurse']['set'] = ['per:nurse']\n",
    "grp_rels['per:nurse']['group'] = 'per:nurse'\n",
    "grp_rels['per:nurse']['col_num'] = 20\n",
    "\n",
    "grp_rels['per:negative impression'] = dict()\n",
    "grp_rels['per:negative impression']['set'] = ['per:negative impression']\n",
    "grp_rels['per:negative impression']['group'] = 'per:negative impression'\n",
    "grp_rels['per:negative impression']['col_num'] = 21\n",
    "\n",
    "grp_rels['per:positive impression'] = dict()\n",
    "grp_rels['per:positive impression']['set'] = ['per:positive impression']\n",
    "grp_rels['per:positive impression']['group'] = 'per:positive impression'\n",
    "grp_rels['per:positive impression']['col_num'] = 22\n",
    "\n",
    "grp_rels['per:client'] = dict()\n",
    "grp_rels['per:client']['set'] = ['per:client']\n",
    "grp_rels['per:client']['group'] = 'per:client'\n",
    "grp_rels['per:client']['col_num'] = 23\n",
    "\n",
    "grp_rels['per:nickname'] = dict()\n",
    "grp_rels['per:nickname']['set'] = ['per:nickname']\n",
    "grp_rels['per:nickname']['group'] = 'per:nickname'\n",
    "grp_rels['per:nickname']['col_num'] = 24\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9421ef28",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dev = dict()\n",
    "\n",
    "y_dev['per:friends-per:friends']=dict()\n",
    "y_dev['per:friends-per:friends']['col_num'] = 0\n",
    "y_dev['per:friends-per:friends']['y'] = []\n",
    "y_dev['per:friends-per:friends']['y_index'] = []\n",
    "\n",
    "y_dev['per:spouse-per:spouse']=dict()\n",
    "y_dev['per:spouse-per:spouse']['col_num'] =1\n",
    "y_dev['per:spouse-per:spouse']['y'] = []\n",
    "y_dev['per:spouse-per:spouse']['y_index'] = []\n",
    "\n",
    "y_dev['per:classmate-per:classmate']=dict()\n",
    "y_dev['per:classmate-per:classmate']['col_num'] =2\n",
    "y_dev['per:classmate-per:classmate']['y'] = []\n",
    "y_dev['per:classmate-per:classmate']['y_index'] = []\n",
    "\n",
    "y_dev['per:neighbor-per:neighbor']=dict()\n",
    "y_dev['per:neighbor-per:neighbor']['col_num'] =3\n",
    "y_dev['per:neighbor-per:neighbor']['y'] = []\n",
    "y_dev['per:neighbor-per:neighbor']['y_index'] = []\n",
    "\n",
    "y_dev['per:acquaintance-per:acquaintance']=dict()\n",
    "y_dev['per:acquaintance-per:acquaintance']['col_num'] =4\n",
    "y_dev['per:acquaintance-per:acquaintance']['y'] = []\n",
    "y_dev['per:acquaintance-per:acquaintance']['y_index'] = []\n",
    "\n",
    "y_dev['per:dates-per:dates']=dict()\n",
    "y_dev['per:dates-per:dates']['col_num'] =5\n",
    "y_dev['per:dates-per:dates']['y'] = []\n",
    "y_dev['per:dates-per:dates']['y_index'] = []\n",
    "\n",
    "y_dev['per:relative-per:relative']=dict()\n",
    "y_dev['per:relative-per:relative']['col_num'] =6\n",
    "y_dev['per:relative-per:relative']['y'] = []\n",
    "y_dev['per:relative-per:relative']['y_index'] = []\n",
    "\n",
    "y_dev['per:siblings-per:siblings']=dict()\n",
    "y_dev['per:siblings-per:siblings']['col_num'] =7\n",
    "y_dev['per:siblings-per:siblings']['y'] = []\n",
    "y_dev['per:siblings-per:siblings']['y_index'] = []\n",
    "\n",
    "y_dev['per:colleague-per:colleague']=dict()\n",
    "y_dev['per:colleague-per:colleague']['col_num'] =8\n",
    "y_dev['per:colleague-per:colleague']['y'] = []\n",
    "y_dev['per:colleague-per:colleague']['y_index'] = []\n",
    "\n",
    "y_dev['per:siblings-in-law-per:siblings-in-law']=dict()\n",
    "y_dev['per:siblings-in-law-per:siblings-in-law']['col_num']=9\n",
    "y_dev['per:siblings-in-law-per:siblings-in-law']['y'] = []\n",
    "y_dev['per:siblings-in-law-per:siblings-in-law']['y_index'] = []\n",
    "\n",
    "y_dev['per:roommate-per:per:roommate']=dict()\n",
    "y_dev['per:roommate-per:per:roommate']['col_num'] =10\n",
    "y_dev['per:roommate-per:per:roommate']['y'] = []\n",
    "y_dev['per:roommate-per:per:roommate']['y_index'] = []\n",
    "\n",
    "y_dev['unanswerable-unanswerable']=dict()\n",
    "y_dev['unanswerable-unanswerable']['col_num'] = 11\n",
    "y_dev['unanswerable-unanswerable']['y'] = []\n",
    "y_dev['unanswerable-unanswerable']['y_index'] = []\n",
    "\n",
    "y_dev['per:alternate_name:per:alternate_name']=dict()\n",
    "y_dev['per:alternate_name:per:alternate_name']['col_num'] = 12\n",
    "y_dev['per:alternate_name:per:alternate_name']['y'] = []\n",
    "y_dev['per:alternate_name:per:alternate_name']['y_index'] = []\n",
    "\n",
    "y_dev['per:children-in-law-per:parents-in-law']=dict()\n",
    "y_dev['per:children-in-law-per:parents-in-law']['col_num'] = 13\n",
    "y_dev['per:children-in-law-per:parents-in-law']['y'] = []\n",
    "y_dev['per:children-in-law-per:parents-in-law']['y_index'] = []\n",
    "\n",
    "y_dev['per:children-per:parents']=dict()\n",
    "y_dev['per:children-per:parents']['col_num'] = 14\n",
    "y_dev['per:children-per:parents']['y'] = []\n",
    "y_dev['per:children-per:parents']['y_index'] = []\n",
    "\n",
    "y_dev['per:grandchildren-per:grandparents']=dict()\n",
    "y_dev['per:grandchildren-per:grandparents']['col_num'] = 15\n",
    "y_dev['per:grandchildren-per:grandparents']['y'] = []\n",
    "y_dev['per:grandchildren-per:grandparents']['y_index'] = []\n",
    "\n",
    "y_dev['per:ex-girlfriend-per:ex-boyfriend']=dict()\n",
    "y_dev['per:ex-girlfriend-per:ex-boyfriend']['col_num'] = 16\n",
    "y_dev['per:ex-girlfriend-per:ex-boyfriend']['y'] = []\n",
    "y_dev['per:ex-girlfriend-per:ex-boyfriend']['y_index'] = []\n",
    "\n",
    "y_dev['per:girlfriend-per:boyfriend']=dict()\n",
    "y_dev['per:girlfriend-per:boyfriend']['col_num'] = 17\n",
    "y_dev['per:girlfriend-per:boyfriend']['y'] = []\n",
    "y_dev['per:girlfriend-per:boyfriend']['y_index'] = []\n",
    "\n",
    "y_dev['per:subordinate-per:boss']=dict()\n",
    "y_dev['per:subordinate-per:boss']['col_num'] = 18\n",
    "y_dev['per:subordinate-per:boss']['y'] = []\n",
    "y_dev['per:subordinate-per:boss']['y_index'] = []\n",
    "\n",
    "y_dev['per:student-per:teacher']=dict()\n",
    "y_dev['per:student-per:teacher']['col_num'] = 19\n",
    "y_dev['per:student-per:teacher']['y'] = []\n",
    "y_dev['per:student-per:teacher']['y_index'] = []\n",
    "\n",
    "y_dev['per:nurse']=dict()\n",
    "y_dev['per:nurse']['col_num'] = 20\n",
    "y_dev['per:nurse']['y'] = []\n",
    "y_dev['per:nurse']['y_index'] = []\n",
    "\n",
    "y_dev['per:negative impression']=dict()\n",
    "y_dev['per:negative impression']['col_num'] = 21\n",
    "y_dev['per:negative impression']['y'] = []\n",
    "y_dev['per:negative impression']['y_index'] = []\n",
    "\n",
    "y_dev['per:positive impression']=dict()\n",
    "y_dev['per:positive impression']['col_num'] = 22\n",
    "y_dev['per:positive impression']['y'] = []\n",
    "y_dev['per:positive impression']['y_index'] = []\n",
    "\n",
    "y_dev['per:client']=dict()\n",
    "y_dev['per:client']['col_num'] = 23\n",
    "y_dev['per:client']['y'] = []\n",
    "y_dev['per:client']['y_index'] = []\n",
    "\n",
    "y_dev['per:nickname']=dict()\n",
    "y_dev['per:nickname']['col_num'] = 24\n",
    "y_dev['per:nickname']['y'] = []\n",
    "y_dev['per:nickname']['y_index'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aab8c709",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = list(label_id.keys())\n",
    "all_groups = [grp_rels[item]['group'] for item in grp_rels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db7be193",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 482/482 [00:01<00:00, 428.71it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create lines data for train_df\n",
    "\n",
    "X_train = []\n",
    "\n",
    "index= 0\n",
    "\n",
    "for i in tqdm(range(0,len(train_df))): \n",
    "    \n",
    "    #list of tuples containing speakers and tokenized sentences\n",
    "    dialog = train_df[i][2]\n",
    "    \n",
    "    #get relations and labels:\n",
    "    for j in range(0,len(train_df[i][1])):\n",
    "        \n",
    "        rel_triplet = train_df[i][1][j]\n",
    "        x = rel_triplet['x']\n",
    "        y = rel_triplet['y']\n",
    "        r = rel_triplet['r'] #note that this is a list that can have len>1\n",
    "\n",
    "        # retrieve lines by speakers or entity mentionned:\n",
    "        if bool(re.search('S',x)):\n",
    "            x_lines = retrieve_s_lines(x,dialog)\n",
    "        else:\n",
    "            x_lines = retrieve_mentions(x,dialog)\n",
    "\n",
    "        if bool(re.search('S',y)):\n",
    "            y_lines = retrieve_s_lines(y,dialog)\n",
    "        else:\n",
    "            y_lines = retrieve_mentions(y,dialog)\n",
    "\n",
    "        X_train.append(' '.join([line for line in x_lines])+' '.join([line for line in y_lines]))\n",
    "        \n",
    "        # Currently mapping to broader class group\n",
    "        current_grps = []\n",
    "        for rel in r:\n",
    "            current_grps.append(grp_rels[rel]['group'])\n",
    "        \n",
    "        current_grps = list(set(current_grps))\n",
    "        for rel in current_grps:\n",
    "            y_train[rel]['y'].append(1)\n",
    "            y_train[rel]['y_index'].append(index)\n",
    "            \n",
    "        counter_examples_rels = list(set(all_groups).difference(set(current_grps)))\n",
    "        for rel in counter_examples_rels:\n",
    "            y_train[rel]['y'].append(0) \n",
    "            y_train[rel]['y_index'].append(index)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a4e6385",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 116/116 [00:00<00:00, 585.87it/s]\n"
     ]
    }
   ],
   "source": [
    "X_dev = []\n",
    "\n",
    "index= 0\n",
    "\n",
    "for i in tqdm(range(0,len(dev_df))): \n",
    "    \n",
    "    #list of tuples containing speakers and tokenized sentences\n",
    "    dialog = dev_df[i][2]\n",
    "    \n",
    "    #get relations and labels:\n",
    "    for j in range(0,len(dev_df[i][1])):\n",
    "        \n",
    "        rel_triplet = dev_df[i][1][j]\n",
    "        x = rel_triplet['x']\n",
    "        y = rel_triplet['y']\n",
    "        r = rel_triplet['r'] #note that this is a list that can have len>1\n",
    "\n",
    "        # retrieve lines by speakers or entity mentionned:\n",
    "        if bool(re.search('S',x)):\n",
    "            x_lines = retrieve_s_lines(x,dialog)\n",
    "        else:\n",
    "            x_lines = retrieve_mentions(x,dialog)\n",
    "\n",
    "        if bool(re.search('S',y)):\n",
    "            y_lines = retrieve_s_lines(y,dialog)\n",
    "        else:\n",
    "            y_lines = retrieve_mentions(y,dialog)\n",
    "\n",
    "        X_dev.append(' '.join([line for line in x_lines])+' '.join([line for line in y_lines]))\n",
    "        \n",
    "        # Currently mapping to broader class group\n",
    "        current_grps = []\n",
    "        for rel in r:\n",
    "            current_grps.append(grp_rels[rel]['group'])\n",
    "        \n",
    "        current_grps = list(set(current_grps))\n",
    "        for rel in current_grps:\n",
    "            y_dev[rel]['y'].append(1)\n",
    "            y_dev[rel]['y_index'].append(index)\n",
    "            \n",
    "        counter_examples_rels = list(set(all_groups).difference(set(current_grps)))\n",
    "        for rel in counter_examples_rels:\n",
    "            y_dev[rel]['y'].append(0) \n",
    "            y_dev[rel]['y_index'].append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ab1263b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 33366, 1: 2084})\n",
      "Counter({0: 33786, 1: 1664})\n",
      "Counter({0: 35068, 1: 382})\n",
      "Counter({0: 31744, 1: 3706})\n",
      "Counter({0: 33728, 1: 1722})\n",
      "Counter({0: 35150, 1: 300})\n",
      "Counter({0: 33370, 1: 2080})\n",
      "Counter({0: 34592, 1: 858})\n",
      "Counter({0: 34949, 1: 501})\n",
      "Counter({0: 35384, 1: 66})\n",
      "Counter({0: 35448, 1: 2})\n",
      "Counter({0: 24411, 1: 11039})\n",
      "Counter({0: 31064, 1: 4386})\n",
      "Counter({0: 34084, 1: 1366})\n",
      "Counter({0: 30918, 1: 4532})\n",
      "Counter({0: 34530, 1: 920})\n",
      "Counter({0: 35232, 1: 218})\n",
      "Counter({0: 35178, 1: 272})\n",
      "Counter({0: 34948, 1: 502})\n",
      "Counter({0: 35350, 1: 100})\n",
      "Counter({0: 34532, 1: 918})\n",
      "Counter({0: 35147, 1: 303})\n",
      "Counter({0: 35263, 1: 187})\n",
      "Counter({0: 35301, 1: 149})\n",
      "Counter({0: 35445, 1: 5})\n"
     ]
    }
   ],
   "source": [
    "for rel in y_train:\n",
    "    print(Counter(y_train[rel]['y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "581d4a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf idf\n",
    "tf_idf = TfidfVectorizer()\n",
    "#applying tf idf to training data\n",
    "X_train_tf = tf_idf.fit_transform(X_train)\n",
    "#applying tf idf to training data\n",
    "X_train_tf = tf_idf.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15f4d2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples: 7422, n_features: 20603\n"
     ]
    }
   ],
   "source": [
    "#transforming test data into tf-idf matrix\n",
    "X_test_tf = tf_idf.transform(X_dev)\n",
    "print(\"n_samples: %d, n_features: %d\" % X_test_tf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b797aaf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#naive bayes classifier\n",
    "naive_bayes_classifier = MultinomialNB()\n",
    "naive_bayes_classifier.fit(X_train_tf, y_train['per:grandchildren-per:grandparents']['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5b12139e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted y\n",
    "y_pred = naive_bayes_classifier.predict(X_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "96a9687c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 7238, 1: 184})"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_dev['per:grandchildren-per:grandparents']['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "914a3631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 7422})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9098e410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 7238, 1: 184})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_dev['per:grandchildren-per:grandparents']['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92ed1023",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit\n",
    "#X_train_array = pd.DataFrame(X_train_array)\n",
    "SVM = SVC(kernel = 'linear')\n",
    "SVM.fit(X_train_tf,y_train['per:grandchildren-per:grandparents']['y'])\n",
    "#y_pred=SVM.predict(X_dev)\n",
    "y_pred=SVM.predict(X_test_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04a8595",
   "metadata": {},
   "source": [
    "TRYING COUNTVECTORIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0633dc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_groups = list(set(all_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af098811",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/elyeb/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.462 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples: 7422, n_features: 175345\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(tokenizer=ch_tokenizer,ngram_range=(1,3),min_df=2,max_df=0.55)\n",
    "#train_array,\n",
    "X_train_cv = cv.fit_transform(X_train)\n",
    "\n",
    "X_train_array = X_train_cv.toarray()\n",
    "\n",
    "X_dev_cv = cv.transform(X_dev)\n",
    "X_dev_array = X_dev_cv.toarray()\n",
    "\n",
    "print(\"n_samples: %d, n_features: %d\" % X_dev_array.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba7e307d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f061ef04",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes_classifier = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7bf6751b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_all = []\n",
    "y_pred_all = []\n",
    "\n",
    "for grp in all_groups:\n",
    "    naive_bayes_classifier.fit(X_train_array, y_train[grp]['y'])\n",
    "    y_pred = naive_bayes_classifier.predict(X_dev_array)\n",
    "    \n",
    "    y_test_all.append(y_dev[grp]['y'])\n",
    "    y_pred_all.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0bcd7d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_all_df = pd.DataFrame(y_test_all)\n",
    "y_test_all_df = y_test_all_df.transpose()\n",
    "y_test_all_df.columns = all_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e8a40b3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>per:friends-per:friends</th>\n",
       "      <th>per:neighbor-per:neighbor</th>\n",
       "      <th>per:siblings-in-law-per:siblings-in-law</th>\n",
       "      <th>per:alternate_name:per:alternate_name</th>\n",
       "      <th>per:positive impression</th>\n",
       "      <th>per:roommate-per:per:roommate</th>\n",
       "      <th>per:spouse-per:spouse</th>\n",
       "      <th>per:relative-per:relative</th>\n",
       "      <th>per:children-per:parents</th>\n",
       "      <th>per:ex-girlfriend-per:ex-boyfriend</th>\n",
       "      <th>...</th>\n",
       "      <th>per:classmate-per:classmate</th>\n",
       "      <th>per:student-per:teacher</th>\n",
       "      <th>per:client</th>\n",
       "      <th>per:nickname</th>\n",
       "      <th>per:colleague-per:colleague</th>\n",
       "      <th>unanswerable-unanswerable</th>\n",
       "      <th>per:girlfriend-per:boyfriend</th>\n",
       "      <th>per:acquaintance-per:acquaintance</th>\n",
       "      <th>per:dates-per:dates</th>\n",
       "      <th>per:grandchildren-per:grandparents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   per:friends-per:friends  per:neighbor-per:neighbor  \\\n",
       "0                        0                          0   \n",
       "1                        0                          0   \n",
       "2                        0                          0   \n",
       "3                        0                          0   \n",
       "4                        0                          0   \n",
       "\n",
       "   per:siblings-in-law-per:siblings-in-law  \\\n",
       "0                                        0   \n",
       "1                                        0   \n",
       "2                                        0   \n",
       "3                                        0   \n",
       "4                                        0   \n",
       "\n",
       "   per:alternate_name:per:alternate_name  per:positive impression  \\\n",
       "0                                      0                        0   \n",
       "1                                      1                        0   \n",
       "2                                      1                        0   \n",
       "3                                      1                        0   \n",
       "4                                      1                        0   \n",
       "\n",
       "   per:roommate-per:per:roommate  per:spouse-per:spouse  \\\n",
       "0                              0                      0   \n",
       "1                              0                      0   \n",
       "2                              0                      0   \n",
       "3                              0                      0   \n",
       "4                              0                      0   \n",
       "\n",
       "   per:relative-per:relative  per:children-per:parents  \\\n",
       "0                          0                         0   \n",
       "1                          0                         0   \n",
       "2                          0                         0   \n",
       "3                          0                         0   \n",
       "4                          0                         0   \n",
       "\n",
       "   per:ex-girlfriend-per:ex-boyfriend  ...  per:classmate-per:classmate  \\\n",
       "0                                   0  ...                            0   \n",
       "1                                   0  ...                            0   \n",
       "2                                   0  ...                            0   \n",
       "3                                   0  ...                            0   \n",
       "4                                   0  ...                            0   \n",
       "\n",
       "   per:student-per:teacher  per:client  per:nickname  \\\n",
       "0                        0           0             0   \n",
       "1                        0           0             0   \n",
       "2                        0           0             0   \n",
       "3                        0           0             0   \n",
       "4                        0           0             0   \n",
       "\n",
       "   per:colleague-per:colleague  unanswerable-unanswerable  \\\n",
       "0                            0                          0   \n",
       "1                            0                          0   \n",
       "2                            0                          0   \n",
       "3                            0                          0   \n",
       "4                            0                          0   \n",
       "\n",
       "   per:girlfriend-per:boyfriend  per:acquaintance-per:acquaintance  \\\n",
       "0                             0                                  0   \n",
       "1                             0                                  0   \n",
       "2                             0                                  0   \n",
       "3                             0                                  0   \n",
       "4                             0                                  0   \n",
       "\n",
       "   per:dates-per:dates  per:grandchildren-per:grandparents  \n",
       "0                    0                                   0  \n",
       "1                    0                                   0  \n",
       "2                    0                                   0  \n",
       "3                    0                                   0  \n",
       "4                    0                                   0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_all_df = pd.DataFrame(y_pred_all)\n",
    "y_pred_all_df = y_pred_all_df.transpose()\n",
    "y_pred_all_df.columns = all_groups\n",
    "y_pred_all_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d5fda9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ref_files/MultinomialNB_pred.pickle','wb') as outfile:\n",
    "    pickle.dump(y_pred_all_df,outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2aad8fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7c7631ac",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/elyeb/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home2/elyeb/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home2/elyeb/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home2/elyeb/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home2/elyeb/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "/home2/elyeb/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home2/elyeb/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home2/elyeb/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home2/elyeb/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home2/elyeb/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "true_labs = []\n",
    "f1s = []\n",
    "\n",
    "for item in all_groups:\n",
    "    labels.append(item)\n",
    "    precisions.append(sklearn.metrics.precision_score(y_test_all_df[item], y_pred_all_df[item], labels=all_groups,average='binary'))\n",
    "    recalls.append(sklearn.metrics.recall_score(y_test_all_df[item], y_pred_all_df[item], labels=all_groups,average='binary'))\n",
    "    f1s.append(sklearn.metrics.f1_score(y_test_all_df[item], y_pred_all_df[item], labels=all_groups,average='binary'))\n",
    "    true_labs.append(Counter(y_test_all_df[item])[1])\n",
    "    \n",
    "labels.append('Avg')\n",
    "precisions.append(np.mean(precisions))\n",
    "recalls.append(np.mean(recalls))\n",
    "f1s.append(np.mean(f1s))\n",
    "true_labs.append(np.mean(true_labs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dbadeb78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>precisions</th>\n",
       "      <th>recalls</th>\n",
       "      <th>f1s</th>\n",
       "      <th>true_labs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>per:friends-per:friends</td>\n",
       "      <td>0.165803</td>\n",
       "      <td>0.082051</td>\n",
       "      <td>0.109777</td>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>per:neighbor-per:neighbor</td>\n",
       "      <td>0.431304</td>\n",
       "      <td>0.309227</td>\n",
       "      <td>0.360203</td>\n",
       "      <td>802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>per:siblings-in-law-per:siblings-in-law</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>per:alternate_name:per:alternate_name</td>\n",
       "      <td>0.156958</td>\n",
       "      <td>0.107182</td>\n",
       "      <td>0.12738</td>\n",
       "      <td>905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>per:positive impression</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>per:roommate-per:per:roommate</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>per:spouse-per:spouse</td>\n",
       "      <td>0.137546</td>\n",
       "      <td>0.095855</td>\n",
       "      <td>0.112977</td>\n",
       "      <td>386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>per:relative-per:relative</td>\n",
       "      <td>0.242308</td>\n",
       "      <td>0.114545</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>per:children-per:parents</td>\n",
       "      <td>0.23536</td>\n",
       "      <td>0.24763</td>\n",
       "      <td>0.241339</td>\n",
       "      <td>844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>per:ex-girlfriend-per:ex-boyfriend</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>per:subordinate-per:boss</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.03252</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>per:nurse</td>\n",
       "      <td>0.112903</td>\n",
       "      <td>0.086066</td>\n",
       "      <td>0.097674</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>per:children-in-law-per:parents-in-law</td>\n",
       "      <td>0.120996</td>\n",
       "      <td>0.112583</td>\n",
       "      <td>0.116638</td>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>per:siblings-per:siblings</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>per:negative impression</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>per:classmate-per:classmate</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>per:student-per:teacher</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>per:client</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>per:nickname</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>per:colleague-per:colleague</td>\n",
       "      <td>0.173077</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.116883</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>unanswerable-unanswerable</td>\n",
       "      <td>0.516968</td>\n",
       "      <td>0.405142</td>\n",
       "      <td>0.454274</td>\n",
       "      <td>2256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>per:girlfriend-per:boyfriend</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>per:acquaintance-per:acquaintance</td>\n",
       "      <td>0.348624</td>\n",
       "      <td>0.137681</td>\n",
       "      <td>0.197403</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>per:dates-per:dates</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>per:grandchildren-per:grandparents</td>\n",
       "      <td>0.123077</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.101911</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Avg</td>\n",
       "      <td>0.137274</td>\n",
       "      <td>0.081187</td>\n",
       "      <td>0.097741</td>\n",
       "      <td>320.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     labels precisions   recalls       f1s  \\\n",
       "0                   per:friends-per:friends   0.165803  0.082051  0.109777   \n",
       "1                 per:neighbor-per:neighbor   0.431304  0.309227  0.360203   \n",
       "2   per:siblings-in-law-per:siblings-in-law        0.0       0.0       0.0   \n",
       "3     per:alternate_name:per:alternate_name   0.156958  0.107182   0.12738   \n",
       "4                   per:positive impression        0.0       0.0       0.0   \n",
       "5             per:roommate-per:per:roommate        0.0       0.0       0.0   \n",
       "6                     per:spouse-per:spouse   0.137546  0.095855  0.112977   \n",
       "7                 per:relative-per:relative   0.242308  0.114545  0.155556   \n",
       "8                  per:children-per:parents    0.23536   0.24763  0.241339   \n",
       "9        per:ex-girlfriend-per:ex-boyfriend        0.0       0.0       0.0   \n",
       "10                 per:subordinate-per:boss   0.074074  0.020833   0.03252   \n",
       "11                                per:nurse   0.112903  0.086066  0.097674   \n",
       "12   per:children-in-law-per:parents-in-law   0.120996  0.112583  0.116638   \n",
       "13                per:siblings-per:siblings       0.25  0.041667  0.071429   \n",
       "14                  per:negative impression        0.0       0.0       0.0   \n",
       "15              per:classmate-per:classmate        0.0       0.0       0.0   \n",
       "16                  per:student-per:teacher        0.0       0.0       0.0   \n",
       "17                               per:client        0.0       0.0       0.0   \n",
       "18                             per:nickname        0.0       0.0       0.0   \n",
       "19              per:colleague-per:colleague   0.173077  0.088235  0.116883   \n",
       "20                unanswerable-unanswerable   0.516968  0.405142  0.454274   \n",
       "21             per:girlfriend-per:boyfriend   0.142857  0.038462  0.060606   \n",
       "22        per:acquaintance-per:acquaintance   0.348624  0.137681  0.197403   \n",
       "23                      per:dates-per:dates        0.2  0.055556  0.086957   \n",
       "24       per:grandchildren-per:grandparents   0.123077  0.086957  0.101911   \n",
       "25                                      Avg   0.137274  0.081187  0.097741   \n",
       "\n",
       "   true_labs  \n",
       "0        390  \n",
       "1        802  \n",
       "2         30  \n",
       "3        905  \n",
       "4         52  \n",
       "5          0  \n",
       "6        386  \n",
       "7        550  \n",
       "8        844  \n",
       "9         20  \n",
       "10       192  \n",
       "11       244  \n",
       "12       302  \n",
       "13       216  \n",
       "14        92  \n",
       "15        32  \n",
       "16        54  \n",
       "17        27  \n",
       "18         0  \n",
       "19       102  \n",
       "20      2256  \n",
       "21        26  \n",
       "22       276  \n",
       "23        36  \n",
       "24       184  \n",
       "25    320.72  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df = pd.DataFrame([labels,precisions,recalls,f1s,true_labs])\n",
    "score_df = score_df.transpose()\n",
    "score_df.columns = ['labels','precisions','recalls','f1s','true_labs']\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d8072783",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ref_files/MultinomialNB_score_df.pickle','wb') as outfile:\n",
    "    pickle.dump(score_df,outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "107e1299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[7124  114]\n",
      " [ 168   16]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      7238\n",
      "           1       0.12      0.09      0.10       184\n",
      "\n",
      "    accuracy                           0.96      7422\n",
      "   macro avg       0.55      0.54      0.54      7422\n",
      "weighted avg       0.96      0.96      0.96      7422\n",
      "\n"
     ]
    }
   ],
   "source": [
    "naive_bayes_classifier = MultinomialNB()\n",
    "naive_bayes_classifier.fit(X_train_array, y_train['per:grandchildren-per:grandparents']['y'])\n",
    "\n",
    "y_pred = naive_bayes_classifier.predict(X_dev_array)\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_dev['per:grandchildren-per:grandparents']['y'], y_pred))\n",
    "print(metrics.classification_report(y_dev['per:grandchildren-per:grandparents']['y'], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bd10d7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs = naive_bayes_classifier.predict_proba(X_dev_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "45c56b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method predict_proba in module sklearn.naive_bayes:\n",
      "\n",
      "predict_proba(X) method of sklearn.naive_bayes.MultinomialNB instance\n",
      "    Return probability estimates for the test vector X.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    X : array-like of shape (n_samples, n_features)\n",
      "        The input samples.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    C : array-like of shape (n_samples, n_classes)\n",
      "        Returns the probability of the samples for each class in\n",
      "        the model. The columns correspond to the classes in sorted\n",
      "        order, as they appear in the attribute :term:`classes_`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(naive_bayes_classifier.predict_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ed472cec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_bayes_classifier.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "157a1956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using set_printoptions\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7f88ada2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.61286858, 0.38713142],\n",
       "       [0.99986027, 0.00013973]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probs[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3ec51cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "#fit\n",
    "NB = GaussianNB()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "268055ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35450, 175345)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8b3247fb",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 43.6 GiB for an array with shape (33366, 175345) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13337/447038869.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgrp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mNB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgrp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_dev_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1149\u001b[0m                 )\n\u001b[1;32m   1150\u001b[0m             ):\n\u001b[0;32m-> 1151\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \"\"\"\n\u001b[1;32m    262\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         return self._partial_fit(\n\u001b[0m\u001b[1;32m    264\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_refit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36m_partial_fit\u001b[0;34m(self, X, y, classes, _refit, sample_weight)\u001b[0m\n\u001b[1;32m    487\u001b[0m                 \u001b[0mN_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             new_theta, new_sigma = self._update_mean_variance(\n\u001b[0m\u001b[1;32m    490\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_count_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msw_i\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36m_update_mean_variance\u001b[0;34m(n_past, mu, var, X, sample_weight)\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mn_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m             \u001b[0mnew_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m             \u001b[0mnew_mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mvar\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mvar\u001b[0;34m(a, axis, dtype, out, ddof, keepdims, where)\u001b[0m\n\u001b[1;32m   3700\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mddof\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mddof\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3702\u001b[0;31m     return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n\u001b[0m\u001b[1;32m   3703\u001b[0m                          **kwargs)\n\u001b[1;32m   3704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_var\u001b[0;34m(a, axis, dtype, out, ddof, keepdims, where)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;31m# Note that x may not be inexact and that we need it to be an array,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;31m# not a scalar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0marrmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 43.6 GiB for an array with shape (33366, 175345) and data type float64"
     ]
    }
   ],
   "source": [
    "y_test_all = []\n",
    "y_pred_all = []\n",
    "\n",
    "for grp in all_groups:\n",
    "    NB.fit(X_train_array, y_train[grp]['y'])\n",
    "    y_pred = NB.predict(X_dev_array)\n",
    "    \n",
    "    y_test_all.append(y_dev[grp]['y'])\n",
    "    y_pred_all.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "60d8f8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "DT= DecisionTreeClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2490565e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_all = []\n",
    "y_pred_all = []\n",
    "\n",
    "for grp in all_groups:\n",
    "    DT.fit(X_train_array, y_train[grp]['y'])\n",
    "    y_pred = DT.predict(X_dev_array)\n",
    "    \n",
    "    y_test_all.append(y_dev[grp]['y'])\n",
    "    y_pred_all.append(y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
